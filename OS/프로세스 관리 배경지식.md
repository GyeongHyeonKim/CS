### 배경지식

#### 프로그램 실행(메모리 Load)

---

![](https://velog.velcdn.com/images/sujipark2009/post/2cf68b66-3afe-4605-a8c7-a8f2096254b4/image.png)

프로그램이 실행되는 단계를 보여주는 그림이다.

프로그램이라는것은, 파일시스템에 **실행파일**의 형태로 저장되어있다.

그리고 이 프로그램을 실행시키면, 프로그램이 메모리에 올라가서 `프로세스` 가 된다.

운영체제의 커널이 메모리에 기본적으로 올라가있고, 사용자 프로그램은 실행시킬 때 메모리에 올라가서 프로세스가 되는 것이다.

사실, 여기에 한 단계를 더 거치게 되는데 그게 바로 `Virtual Memory(가상 메모리)` 이다.

![](https://velog.velcdn.com/images/sujipark2009/post/9897a9b9-f930-44b3-ac87-86fb4e34ec20/image.png)

프로그램이 실행될때는, 그 프로그램만의 **독자적인 주소**가 생기는데, 그것을 `Virtual Memory` 라고 한다.

각각의 프로그램은, 자신만의 가상의 주소공간을 가지고있다(0번지부터 시작하는 주소공간)

프로그램에서 당장 필요한 부분은 물리적인 메모리에 올라가게 되고, 그렇지 않은 부분은 디스크의 `Swap area` 라는곳에 내려가있게 된다.

이 중 일부는 파일시스템에 `file` 형태로 존재하게 되어있다(Code같은 것)

그래서 Virtual Memory와 Physical Memory는 다르다.

논리적 주소라는 것과 실제 물리적 주소라는것이 있는데, 이 둘 사이에서 **주소변환**이라는게 일어나게 되는데..

좀 더 자세히 보면,

프로세스 각각의 주소공간에는 몇 가지 구성요소가 있다.

바로 `Code`,`Stack`,`Data` 이다.

`Code`는 실행파일에 있던 코드가 올라오는 부분으로, 실제로 CPU에서 실행할 기계어들이 위치하는 부분이다.

main() , 사용자 정의 함수.., 이런 것들이 컴파일이되면 기계어가 되는데 그런 기계어 코드들이 위치하는 부분이다.

`data` 는 말 그대로 data가 보관되는 영역인데, 프로그램이 실행되던 도중에 우리가 변수나 배열을 잡는 등 메모리 데이터를 잡는 행위를 하는데 그런것들이 위치하는 부분이다.

모든 데이터가 위치하는 건 아니고, 함수 안에있는 지역변수는 `stack`에 위치하게 된다. data에는 전역변수같은, 프로그램이 시작해서 종료될때까지 남아있는 데이터들이 위치하게 된다.

`Stack`에는 대부분의 프로그램이 어떤 언어로 작성했던간에 함수의 형태로 되어있는데 어떤 함수를 호출해서 그 함수가 끝나면 return되어서 돌아와야 한다.

그런 함수의 호출과 리턴에 관련된것을 stack이라는 곳에 쌓아놨다가 return 될때는 그 내용을 다시 읽어서 되돌아가는 그런것을 위한 영역이다.

Virtual Memory공간은, Code,Stack,Data 영역으로 구분이 된다~ 로 알아두면 된다.

OS의 커널도 사실은 하나의 프로그램이기때문에 함수 구조로 되어있다.
그렇기에 커널의 주소공간 또한 code,data,stack으로 구분되어있다.

![](https://velog.velcdn.com/images/sujipark2009/post/639d8066-c713-4f87-b723-cc174010648f/image.png)

이 그림은, 커널의 주소공간을 code,data,stack으로 본 것이다.

**code**

OS는 시스템의 자원을 효율적으로 관리하는데, 그럼 그것을 위한 코드가 OS 커널에 함수형태로 있어야한다.

또 OS는 사용자에게 편리한 인터페이스를 제공하는데 이것도 다 커널에 함수로 미리 프로그래밍 되어있는 것이다.

사용자 프로그램이 CPU에서 돌아가다가 인터럽트가 들어오면 어떻게 처리해야하는지 또한 OS커널에 다 정의되어있고, CPU에서 사용자 프로그램이 사용할 수 없는 특권명령을 실행하는 경우 OS에게 대신해달라고 부탁하게 된다.(I/O같은 것) 그럴 때 OS가 파일을 읽는 코드가 있어야하는데 그런 코드 또한 커널 code안에 있는 것이다.

**data**

OS는 하드웨어 자원도 관리하지만, 시스템 안에 돌아가는 모든 프로세스 또한 관리해야한다.

누구에게 CPU를 얼마나 줄 것인지.. 그런 것을 관리해야한다.

OS의 data영역에는 모든 하드웨어들을 관리하기 위한 그런 자료구조를 가지고 있고, 모든 프로세스들을 관리하기 위한 자료구조를 가지고 있다.

그런 자료구조를 `PCB(Process Control Block)` 이라고 한다.

어떤 프로세스를 관리하려면, 당연히 자료구조가 필요한데 그것이 PCB라는 형태로 관리되는 것이다.

CPU우선순위..사용하는 파일.. 메모리는 얼마나 줬는지.. 이런것들이 PCB를 통해 관리되고있다.

**stack**

OS stack은 조금 특이한 구조를 가지고있는데,

프로그램 A가 실행되다가 OS에게 뭔가 서비스를 요청할 수 있다.
또 프로그램 B가 실행되다가 OS에게 뭔가 시스템 콜을 해서 서비스를 요청할 수 있는데 그런 각각의 프로그램에 의해서 OS는 호출이 되기 때문에 지금 누구의 서비스를 수행하기 위해서 OS코드가 실행되느냐에 따라서, 커널의 stack이 각 프로세스별로 존재하게 된다.

프로그램 A가 실행되다가 OS에게 뭔가 요청을 해서 OS의 코드가 실행이 되겠지?
OS의 코드도 함수 형태로 되어있기에, 어떤 함수가 다른 함수를 호출하면 `stack`을 써야한다.

함수의 호출..리턴.. 이런 정보를 저장해야하기 때문이다.

그래서 만약 방금 A때문에 OS가 호출이 되었으면 커널 stack은 A의 커널stack을 사용하고, B를 실행하다가 넘어왔으면 B의 커널stack을 사용하게 된다.

이렇게 커널 stack은 각 프로세스마다 별도로 두고 있다.

stack이기때문에, 거기에 저장되는 내용은 지금 작업을 끝내면 어디로 되돌아갈지 같은 정보를 담고있게된다.

#### 사용자 프로그램이 사용하는 함수

---

![](https://velog.velcdn.com/images/sujipark2009/post/90af8e4c-2046-4a4d-b801-7649b66beb62/image.png)

누군가가 이미 만들어놓은 함수를, 우리는 `라이브러리 함수`라고 부른다.

내가 만든 함수는 아니지만, 그 코드를 들고와서 내 프로그램안에 넣는것이다.

내가 정의한 함수든,라이브러리 함수든, 내 프로그램 안에 코드가 들어가게 되는 것이다.

반면에, 커널함수는 OS안에 있는 함수이다. 내 프로그램 코드안에 들어있는 것이 아니고, 커널의 코드에 들어있는 함수이다.

커널의 함수를 호출하는것을 우리는 `시스템 콜` 이라고 불렀다.

![](https://velog.velcdn.com/images/sujipark2009/post/bbff153a-aa41-4d04-8d03-c5705eb407ae/image.png)

내가 프로그램을 만들어서 메인함수를 실행하다가 내가만든 A라는 함수를 쓰면, 여전히 내 코드가 실행되는 것이다.

또 내가 만든건 아니지만 라이브러리 함수를 가져다 쓰더라도 내 코드가 실행되는 것이다.

그런데 내 프로그램이 실행되다가 디스크에서 파일을 읽는다던지 그런 함수를 호출한다면 그런 I/O 관련은 커널에 정의된 함수이기 때문에 커널로 CPU제어권이 넘어가서 커널의 함수를 실행해야한다.

원래는 Program Counter만 변경하면 되는데,, OS커널의 함수를 호출하는 행위는 가상 메모리의 주소공간을 가로질러서 다른 메모리의 공간(커널공간)으로 넘어가는 것이므로, 이럴때는 CPU제어권을 OS에게 넘겨야한다.

![](https://velog.velcdn.com/images/sujipark2009/post/fa8981f4-bcf8-4594-8e53-56351bdcefe4/image.png)

저렇게 프로그램이 시작되고 그 프로그램의 일생을 살펴보면,

내가 정의한 함수를 호출할때도 있고, 라이브러리 함수를 호출할때도 있고, OS의 함수를 호출할 때도 있고,, 그렇다.

CPU의 제어권을 본다면 내 함수 or 라이브러리 함수의 경우에는 `User mode`에서 실행이 되는 것이고,

시스템 콜을 부르게 되면 CPU제어권이 OS에게 넘어가서 `kernel mode` 에서 OS의 주소공간에 있는 코드가 실행되는 것이다.

참고로 `User mode`,`Kernel mode`는 CPU옆에 붙어있는 `mode bit`에 의해 결정되는 것이라고 했다.

#### 프로세스의 개념

---

A Program in execution

말 그대로 실행중인 프로그램이다.

프로세스를 말할 때 같이 등장하는게 바로 프로세스의 `문맥(Context)`이다.

프로세스라는 것은, 어떻게 보면 생명력을 지는 하나의 생명체라고도 할 수 있다.
프로그램을 실행시키면 프로세스가 탄생해서 여러 일들을 하다가 종료되는 그런 일련의 생명주기가 있다.

프로세스가 어떤 상태에 있는지 그런것을 나타내는 개념이 바로 프로세스의 문맥이다.

프로세스의 문맥은, 시간에 따라서 바뀌는 개념이다.

어디까지 수행을 했고 과거에 나쁜일은 하지 않았는가.. 이런 것들
과거에 CPU는 얼마나 썼고 메모리는 얼마나 썼는지.. 그런 개념들

OS는 프로세스의 컨텍스트를 대단히 중요하게 생각하는데, 몇 가지로 나눠볼 수 있다.

1. CPU는 어디까지 수행했는가

- Program Counter
- 각종 register

A라는 프로그램이 실행되면서, 어떤 시점을 딱 잘라서 보면 주소공간 중 어딘가의 코드를 실행했을 것이다.

어디를 실행했었는가? 하는 정보는 PC(Program Counter)가 나타내고 있을 것이다.

그리고 각각의 기계어를 실행할때는, register의 값을 가지고 연산을 하며 메모리에 쓰고.. 그런 행동을 했을것이다.

현재 register에 어떤 값을 넣고 있었는가 하는 것들이 CPU context가 되는 것이고 이는 `하드웨어 문맥` 이라고 한다.

2. 자신의 메모리 공간에 무엇을 가지고 있는가

어떤 변수나 데이터의 값을 어떤것을 가지고 있고, 스택을 보면 어떤것을 수행하고 있고.. 이런 code,data,stack 또한 그 프로세스의 현재 상태를 나타내는 문맥의 중요한 요소가 된다.

3. PCB

각각의 프로세스를 관리하기 위해 OS가 가지고 있는 자료구조이다.
OS는 일개 프로그램으로서 자신의 주소공간 중 data 영역에 각 프로세스마다의 PCB를 가지고 있다.

PCB에는,

CPU를 얼마나 썼고, 메모리를 어떻게 썼고 이런 정보를 종합적으로 가지고 있다.

...

커널의 함수를 수행할때는 프로세스마다 별도의 커널스택을 쓴다고 했다.

위의 여러 요소들이 종합적으로 모여서 프로세스의 현재 상태를 나타내는 문맥이 된다.

#### 프로세스의 상태(Process State)

---

![](https://velog.velcdn.com/images/sujipark2009/post/245aa0ec-b82a-48d0-8b4f-6e918171d0fb/image.png)

CPU가 하나밖에 없기 때문에(여기서는 하나라고 가정), CPU에서 기계어를 수행하는 프로세스는 매 순간 하나이다.

그리고 그것을 `Running` 상태에 있다고 말한다.

CPU를 쓰고싶은데, 하나밖에 없으니까 기다려야 하는 프로세스들을 `Ready` 상태에 있다고 부른다.

실행에 필요한 모든 자원은 준비된 상태로, CPU만 있으면 되는 상태이다.

CPU를 당장 줘봐야 기계어 실행이 불가능한 상태인 프로세스들도 있는데,

예를들어 디스크에서 파일을 읽어야 한다거나가 있는데, 디스크에서 파일을 읽는게 오래걸리는 작업이기 때문에 CPU를 당장 얻어봐야 무의미하다.

이런 상태의 프로세스를 `Blocked` 상태에 있다고 부른다.

그래서 크게 3가지 상태 중 하나가 된다(Running,Ready,Blocked)

Blocked는 여러가지 상황이 있는데,

- 디스크에서 파일을 읽어와야 하는 경우
- 프로세스가 자신이 요청한 어떤 이벤트가 즉시 만족되지 않아 기다리는 상태

예를들어 내가 프로그램을 작성했는데 키보드 입력을 하나 받아서 입력 결과를 보고 다음 부분을 수행한다고 한다면, scanf or scanner를 통해 키보드 입력을 받게 될 것인데 그 입력이 들어오기 전 까지는 기다려야 하는 것

또 프로세스가 생성중인 상태, 수행이 끝난상태(New,Terminated)도 존재한다.

OS는 PCB를 통해 각 프로세스가 어떤 상태인지를 관리하고 있고,
그림처럼 Queue를 통해 줄을 세워놓고 처리를 하게 된다.

만약에 현재 실행중인 프로세스가 Disk에서 어떤 파일을 읽어오는 작업을 기다린다면 Disk I/O Queue에 현재 프로세스를 넣게 되고, OS가 다음에 CPU를 줄 때 Ready Queue에 있는 프로세스에게 주게 된다.

이런 하드웨어 작업때문에 오래걸리는 것만 있는건 아닌데,

예를들어 공유 데이터라는게 있을수도 있다.

프로세스들 끼리 같이 쓰는 데이터를 공유데이터라고 하는데, 이런것을 동시에 여러 프로세스가 쓰면 문제가 될 수 있어서 하나가 쓰는동안 다른 프로세스는 기다려야 하는 경우가 있다. 그런경우 다른 프로세스는 Blocked 상태가 될 수 있다.

결론적으로,

여러 큐를 둬서 프로세스의 상태가 어떻고 그런것을 OS가 PCB를 통해 관리를 하게 되는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/291fd62e-b44d-4177-ab11-d10dd4a68246/image.png)

#### Process Control Block(PCB)

---

![](https://velog.velcdn.com/images/sujipark2009/post/5008da56-1d01-4000-8893-be15a27eabf0/image.png)

OS가 프로세스를 관리하기 위한 자료구조인 PCB에는 어떤 내용이 들어있을까?

크게 4가지 정도가 있는데

1. OS가 관리하면서 필요한 프로세스의 상태,PID, CPU 스케쥴링을 위한 우선순위 정보

지금까지는 CPU를 쓰다가 큐에있는 다음 친구에게 넘어가고.. 이런식으로 이야기를 했었는데

현대의 OS는 이러한 프로세스들에게 Priority를 부여하고 그것이 가장 높은 친구에게 CPU를 넘겨주도록 되어있다.

모든 프로세스들의 우선순위가 동등하지는 않다.

2. CPU 수행 관련 하드웨어 값

- Program Counter
- Register

![](https://velog.velcdn.com/images/sujipark2009/post/16faac4b-f619-4549-a036-2fac619e6bb1/image.png)

CPU를 뺏길 때, 그냥 뺏기는게 아니라 현재 CPU에서 어디까지 수행했고 register에 어떤 값을 가지고 있었는지 그런것을 저장해놔야 한다.

CPU가 프로세스 A에서 B로 넘어간다면, A가 지금 CPU에서 수행되면서 현재 어디를 실행했고 register에 어떤 값을 넣었는지, 이런 정보를 프로세스 A의 PCB에 다 기록을 한 후에 B에게 CPU를 넘겨야 한다.

B 또한 예전에 특정 부분까지 프로세스를 사용했을 것이고, 그 정보 또한 B의 PCB에 저장되어있을 것이다. 그 정보를 그대로 불러온 후에 CPU를 B에게 넘겨준다.

그래서 이렇게 프로세스 A로부터 B로 CPU가 넘어가는 것을 `Context Switching` 이라고 부른다.

3. 메모리 관련

- code,stack,data의 정보

4. 파일관련 정보

- open file descriptors

...

![](https://velog.velcdn.com/images/sujipark2009/post/f7d9a170-594a-4bc5-8c4c-1684997acb2a/image.png)

컨텍스트 스위칭은, CPU가 한 프로세스에서 다른 프로세스로 넘어가는 과정이다.

여기서 주의할점은, 1번케이스는 컨텍스트 스위칭이 아니라는 점이다.

A가 수행하다가 인터럽트 or 시스템 콜을 하고싶어서 CPU가 커널로 넘어갔다면 이것은 컨텍스트 스위칭이 아니다.

컨텍스트 스위칭이라는 것은 사용자 프로그램 A에서 사용자 프로그램 B로 CPU가 넘어가는 것을 의미한다.

`Timer 인터럽트`가 생기거나, `I/O 요청 시스템 콜`이 생기는 경우에 컨텍스트 스위칭이 일어나게 된다.

#### 프로세스를 스케쥴링 하기 위한 큐

---

![](https://velog.velcdn.com/images/sujipark2009/post/39d12d0c-7fa3-4c6e-9347-3ddf9107b10a/image.png)

OS는 프로세스들을 큐에 넣어놓고 관리를 한다.

모든 프로세스들은 Job Queue에 있는데, 그 중에서 당장 CPU를 얻어도 되는 프로세스들이 Ready Queue에 들어가게 된다.

나머지 오래 걸리는 프로세스들은, 그 원인에 해당하는 각 device의 queue에 들어가게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/6cbd384d-1d2a-4c2d-a87d-3085680b401c/image.png)

Ready Queue, Disk Queue, Terminal Queue,.. 이렇게 다양한 종류의 큐 안에서 PCB들이 연결되어있는 형태로 존재한다.

PCB안에 포인터가 있었는데,

![](https://velog.velcdn.com/images/sujipark2009/post/49abfe44-89c3-4664-ae2b-b1fd4edb3356/image.png)

그게 다 LinkedList처럼 다음 PCB를 가리키도록 다 이어져있는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/1605686d-de7d-4335-bb6f-31f32aea6b0e/image.png)

같은 이야기를 다른 그림으로 표현한 것이다.

프로세스가 처음에 실행이 되면 Ready Queue에 들어와서 본인 차례가 되면 CPU를 얻고, CPU를 쓰다가 오래 걸리는 I/O 작업을 만나게 되면, I/O큐에 가서 줄을 서게되고, I/O가 끝나면 또 Ready Queue에 가게 되는 것이다.

만약 Timer Interrupt가 걸려서, 주어진 CPU 할당시간이 끝나면 또 Ready Queue에 들어가서 줄서고..

...

#### 스케쥴러(Scheduler)

---

스케쥴러는 보통 순서를 관리하고 시간을 정하고 그런것을 하는건데

OS에는 CPU 스케쥴링 / Disk 스케쥴링이 있다.

여기에서는, `Long-term`,`Short-term`,`Medium-Term` Scheduler에 대해 알아보자.

OS에서 스케쥴링을 하는 코드를 그냥 스케쥴러라고 이름을 붙인 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/412fc48b-35e8-4327-bfd0-88e473218e58/image.png)

#### Long-term Scheduler(장기 스케쥴러 / Memory Scheduler)

---

프로세스 상태도에서, 프로세스가 생성되면 바로 Ready상태가 되는것이 아니라

admitted가 되면 Ready상태가 되는데, 이 admit을 해주는것이 바로 `장기 스케쥴러`이다.

우리가 프로그램을 여러개를 실행시켰다고 했을 때, 무조건 다 CPU를 얻는게 아니라 메모리에 당장 필요한 부분이 올라와있어야 CPU에서 실행이 가능하다.

그래서 처음에 프로세스가 시작이 될 때 메모리에 들어오는것을 허락해주는게 장기 스케쥴러의 역할이다.

현대의 범용 운영체제(Linux / windows)는 일단 프로그램을 실행시키면 다 실행이 된다.

admit 같은것을 하는 과정이 없다 -> 장기 스케쥴러 같은게 없다

현대의 Time Sharing System에는 보통 장기 스케쥴러가 없는데, 프로그램이 실행되면 바로 메모리에 진입해서 Ready상태에 들어가게 된다.

그럼 이 이야기가 왜 여기에 있냐?

Time Sharing System 이전에는 장기 스케쥴러가 있었기 때문에 있는 것이다.

장기 스케쥴러는 메모리를 주는 문제라고 했다. 메모리를 준다는 건 메모리에 올라가는 것이고, 장기 스케쥴러가 허락해서 메모리에 올라가게 되면 메모리에 올라간 프로그램의 수가 하나 더 증가하는 것이다.

100개의 프로그램을 띄웠는데 100개를 허락하면 100개가 올라가는 것이다.

근데 너무 많이 올라가게 되면, 메모리는 한정된 자원이기에 성능이 떨어지게 된다.

그림을 보면, `Degree of Multiprogramming` 이라는게 적혀있는데

메모리에 여러 프로세스가 올라가는것을 Multiprogramming이라고 하는데, Degree of Multiprogramming이라는 것은, "메모리에 올라가는 프로그램이 몇개가 될 것인가?" 를 장기 스케쥴러가 조정한다 라고 생각하면 된다.

근데 현대 OS에 장기 스케쥴러가 없으면 어떻게 메모리 관리를 할까?

1000개를 눌러서 싹 다 메모리에 올라가면 안되잖아.

Time Sharing System에서는, 대신에 **중기 스케쥴러** 를 둔다.

#### Medium-term Scheduler(중기 스케쥴러 / Swapper)

---

장기 스케쥴러가 없기 때문에, 실행된 프로그램은 우선 메모리에 모두 올라오게 된다.

그렇게 되면, 메모리 경합이 너무 심해서 성능이 안나오기 때문에 그런 상황에서는 메모리에서 일부 프로그램을 통째로 날려버리는 게 효과적일 수 있다.

그런 역할을 하는게 `중기 스케쥴러` 이다.

프로세스에게서 Memory를 뺏는 문제와 관련되어있다.

`Degree of Multiprogramming` 을 제어한다.

![](https://velog.velcdn.com/images/sujipark2009/post/c0e8dd7b-2d63-427d-90c3-4d229b816465/image.png)

지금까지 프로세스의 상태는, Ready,Running,Blocked가 있었는데 중기 스케쥴러가 들어가게 되면서 추가되는 프로세스의 상태가 바로 `Suspended(stopped)` 상태이다.

프로세스가 중기 스케쥴러 때문에 메모리에서 쫓겨난 상태를 일컫는다.

꼭 중기 스케쥴러 때문에 쫓겨나야만 Suspended는 아니고, 이 상태가 되는 몇 가지 원인이 있다.

그런 원인들의 공통점은 **항상 외부적인 이유**이다.

예를들어, 방금 봤던 OS가 메모리 경합이 너무 심해 메모리가 부족하기 때문에 프로세스를 메모리에 쫓아내느 경우,

또 사람이 잘 돌아가던 프로세스를 정지시키는 경우(리눅스에서 Ctrl + Z 커맨드를 누르는 것)

Suspended 상태가 되면, 메모리를 다 빼앗기고 Disk로 쫓겨나는 상태가 된다.

여기서 **Blocked**와 **Suspended**의 차이는 뭘까?

둘 다 CPU를 얻을 수 없는 상태인데 차이가 있다며

Suspended의 위쪽(Running,Ready,Blocked)는 정지된 게 아니라 계속 실행중인 상태이다.

실행이라는 의미를 CPU에서 기계어를 실행해야만 실행이다 라고 한다면 전부 실행은 아니지만, 프로세스의 일생은 CPU에서 기게어를 실행하는 것도 있지만 Disk에서 I/O를 수행하는 것도 프로세스는 무언가 일을 하는 것이다.

CPU를 쓰건, I/O를 하건 프로세스는 일을 하고 있는 상태가 저기 위에 있는 상태이고

Suspended는 아예 일을 못하는 상태를 의미하는 것이다.

그래서 Blocked상태에 있다가 Blocked 원인이 된 이벤트가 끝나면 다시 Ready로 돌아갈 수 있다.

그러나 Suspended 상태에서 위로 올라가는 것은 본인이 직접할수는 없고, 외부에서 resume을 해주어야 한다.(사람이 멈췄거나, OS가 메모리가 부족해서 쫓아냈다면 다시 OS가 위로 올려줘야 한다)

![](https://velog.velcdn.com/images/sujipark2009/post/35f9106e-f9e4-407d-8d2b-30cbd27c4ba5/image.png)

`Suspended`가 추가됨으로써 바뀌는 프로세스 상태도이다.

Running,Ready,Blocekd 이 3가지 상태를 `Active` 상태라고 부른다.

프로세스가 열심히 일을 한다는 것이다. CPU에서 하던지.. I/O를 하러가서 Sleep이라고 되어있지만 I/O 작업 같은것을 하고 있는 상태이다.

아래쪽에 Suspended도 상태를 2개로 나눠놨는데 Blocked 상태와 Ready상태에서 Suspended로 가는걸 각각 `Suspended Blocked` , `Suspended Ready` 라고 한다.

둘 다 메모리를 빼앗겨서 메모리에 없는 상태인데,
어떻게 하면 다시 위로 올라올 수 있냐면, 외부에서 메모리를 뺏었으니 다시 외부에서 메모리를 줘야한다.

OS가 나중에 여융가 생기면 다시 Active한 상태로 올려줄 수 있고, 사람이 프로세스를 정지시켰다면 다시 재개해줘야지 올라갈 수 있는 상태이다.

Suspended는 메모리를 뺏겨서 아무것도 못한다고 했지만, 사실 그림을 보면 Suspended 상태에도 화살표가 있는것을 알 수 있다.

이건 뭐냐면, 메모리를 통째로 빼앗겼으니까 CPU 작업 이런건 일절 못하지만, I/O를 하던도중에 Suspended로 들어갔으면 그런 I/O 작업은 계속 할 수 있다.

Suspended Blocked에서

왜 Blocked가 되었냐면, Disk에서 뭘 읽어와야 한다던지 그런 작업 때문에 Blocked가 되었는데 그 상태에서 메모리까지 빼앗겨서 Suspended Blocked가 되었다면 I/O 작업이 끝난 이후에는 Suspended Ready 상태로 넘어올 수 있는 것이다.

하지만 계속 말했듯이, 메모리를 빼앗겼기에 Active 상태로 스스로 들어갈 수는 없고 외부에서 재개시켜줘야한다.

위의 그림에서, Swap in / Swap out 이라는 표현을 썼는데

Swap out은 메모리에서 통째로 쫓겨나는 것이고 in은 다시 들어오는 것을 의미한다.

이 그림이 전과 달라진 점은, Running을 둘로 쪼갰다는 것인데

User mode와 Kernel mode로 쪼갰다.

이게 뭐냐면,

어떤 프로세스가 자기 코드를 수행중이면 `User mode`에서의 running이라고 부르고,

IO 작업이나 본인이 할 수 없는 일을 OS에게 부탁할 때 시스템 콜을 한다고 했었는데
, 시스템 콜을 해서 OS의 코드가 수행중일 때 OS가 CPU를 잡고 기계어를 수행하고 있으니 OS가 running(Kernel mode) 이라고 생각하기 쉬운데 **그건 아니다**

Running,Ready,Blocked는 OS가 사용자 프로세스를 관리하기 위해 둔 상태이지, OS 본인의 상태를 표현하지는 않는다.

OS가 Running,Ready,Blocked 되었다.. 라는 표현은 사용하지 않는다.

그러면 OS가 code를 수행중일 때, **OS를 불렀던 A의 상태는 뭐라고 해야할까?**

이게 CPU를 빼앗긴것인가 아니면 A를 대신해서 OS가 일을 해주고 있는것인가..

이런 두 관점이 있다면, CPU를 빼앗겼다고 보는 것 보다는 A가 여전히 CPU에서 일을 하는것으로 보는게 타당하다.

User mode에서 A가 수행하다가 시스템 콜을 통해 Kernel의 코드가 수행되는 상태를 `kernel mode` 의 Running 이라고 한다.

조금 더 어려운 이야기를 하면.. 인터럽트가 들어오는 경우가 있다고 해보자.
A라는 프로그램이 CPU를 가지고 돌아가다가 Disk Controller가 인터럽트를 발생시켰다.

왜 발생시켰을까?

I/O 요청을 한 또 다른 프로세스(프로그램 B)의 디스크 요청이 끝났다고 알려주는 것이다.

그럼 A는 돌다가 CPU가 OS에게 넘어가게 된다.
이때, A의 상태는 어떻게 바뀔까? A가 CPU를 뺏긴거니 Ready일까?

=> 여전히 A가 Running하고 있다고 간주한다.. A가 커널모드에서 동작하고 있다고 생각한다.

한가지 더 추가하면 Disk I/O 와 관련된 인터럽트는 하드웨어 인터럽트일까 소프트웨어 인터럽트일까?

정답은 둘 다 인데,

Disk I/O를 하기 위해서는, 본인이 직접 요청을 못하기 때문에 OS에게 요청을 하게 된다. I/O가 시작될 때는 시스템 콜을 해서 OS에게 요청을 하면 OS가 CPU를 잡고 있으면서 CPU가 Disk Controller에게 요청을 하게 된다.

여기서는 Sofeware interrupt가 발생한다(시스템 콜).
그럼 I/O가 진행이 될 것이고, 그게 끝나면 Disk Controller가 CPU에게 인터럽트를 걸고 I/O가 끝났다고 알려줄텐데, 이것은 Hardware interrupt이다.

그래서 2가지의 인터럽트가 다 존재한다고 할 수 있다.

그림에서 인터럽트 / 인터럽트 복귀는, 인터럽트 코드를 수행하던 도중에 더 우선순위가 높은 인터럽트 코드가 들어올 수 있는데, 그것을 제자리에서 도는 화살표로 표현한 것이다.

커널의 코드가 다 끝나고 나면, 다시 사용자 프로세스로 되돌아 가서 User mode의 사용자 코드가 수행이 되는 것이다.

#### Short-term Scheduler(단기 스케쥴러 / CPU 스케쥴러)

---

CPU를 누구에게 얼마나 줄 지를 결정하는 것이다.

CPU는 굉장히 빠르게 넘어가게 때문에 단기 스케쥴러는 굉장히 자주 호출이 된다.

ms단위로 단기 스케쥴러가 수행이 된다.

#### Thread

---

지금까지는 프로세스에 대해서 이야기를 했었다.

스레드 라는게 있는데, 이거는 프로세스 중에서 CPU 수행단위를 `스레드` 라고 부른다.

![](https://velog.velcdn.com/images/sujipark2009/post/8f60dd63-d620-4b6b-a698-e63543fb9f1d/image.png)

원래 프로세스는 저렇게 생겼다.

메모리 주소 공간에 code,stack,data가 있고 OS가 이런 프로세스 하나를 관리하기 위해서 PCB를 하나씩 두고있다.

현재 Program Counter, register,.. data에 전역변수는 어떤게 있고,, stack에 함수 몇 개를 실행중인지.. 이런게 바로 프로세스를 나타내는 것이다.

우리가 프로그램을 실행시킬 때, 예를들면 크롬 브라우저를 여러 개 띄워놓고 쓸 수 있을것이다.

그럼 동일한 웹 브라우저 프로그램이지만 여러개를 띄우면 여러 프로세스가 되는 것이다.

그렇게 되면, 각 웹 브라우저가 각각의 프로세스니까, 각각의 code,data,stack을 가지는 주소공간과 PCB가 생성되게 된다.

그럼 이걸 좀 더 효율적으로 할 수는 없을까?
사실 실행파일은 같으니까 코드는 같을거잖아?
여러 code의 COPY가 메모리에 올라가게 되는 것이다.

다만 서로서로 다른 것을 보고있으면, 현재 code에서 어느 부분을 실행하고 있는가 하는건 다른 위치를 실행하고 있을 것이고, PCB값도 다를 것이다

근데 이게 너무 비효율적이라는 것이다. 프로세스 하나를 만드는 것과 각각이 메모리에 올라가는게..

그렇게 하지말고 Thread라는 걸 써보자

![](https://velog.velcdn.com/images/sujipark2009/post/caf9738a-7e78-4ae7-809f-fdda933a681b/image.png)

동일한 프로그램을 여러개 띄우더라도, 프로세스가 1개가 만들어지는 것이다.

즉, code,stack,data 구조가 1개만 만들어지고 대신에 각각의 여러개들은 서로 다른 부분의 코드를 실행할 수 있으니 그것만 따로 관리를 해주자는 것이다.

그것을 **CPU의 수행단위**라고 할 수 있다. **현재 CPU를 어디 실행하고 있는가와 관련된 정보**를 따로 두자는 것이다.

PCB에서, 어차피 프로세스 1개이니까 다른 정보는 다 공유를 하고

Program Counter나 register 값을 각각 두고, 각 스레드가 코드의 어떤 부분을 실행하고, 또 함수를 실행하면 stack에다가 쌓아놓는게 있을것이고.. 이런것들도 별도로 관리가 되어야 할 것이다.

**프로세스에서 CPU수행과 관련된것만 별도로 가지고 있고, 나머지는 단일 프로세스로 Share하는 구조가 효율적이라는 것이다.**

그래서 웹 브라우저를 여러개 키면, code는 공유하고 프로세스는 1개가 뜨는데 그 웹 브라우저가 현재 무슨일을 하느냐에 따라 stack과 register 값에는 다른 위치가 기록되는 것이다.

뭐가 더 좋을까?

프로세스 A에서 프로세스 B로 넘어가는 것을 `Context Switching` 이라고 했고 `Overhead` 가 큰 작업이라고 했다.

그런데, 스레드1에서 스레드2로 넘어가는건 값비싼 Context Switching이 필요없고 효율적으로 진행할 수 있다.

스레드는 프로세스 내부에서 CPU수행의 단위에 해당하는 것이며, `lightweight process` 라고 부른다.

CPU 수행단위이기에 PC나 register,stack을 별도로 가지고 있어야 한다.

그 외의 모든 것들은 스레드끼리 다 공유를 하게 된다.
(주소공간의 code,data,OS resources(어떤 파일을 열었는지..) 등을 공유)

#### 스레드의 장점

---

스레드가 1개가 있으면, I/O를 하게 되면 CPU를 뺏기게 된다. 왜냐하면 **당장 할 일이 없으니까**

근데, 그런 경우에 비효율적인 경우가 있는데

웹 브라우저 예시를 들면, 웹 브라우저에서 어떤 포탈 사이트를 접근한다고 해보자.
그 포탈 사이트의 url을 치면, 네트워크로부터 해당 페이지의 내용을 읽어오게 될 것이다.

그 과정도 오래걸리는 작업으로 일종의 네트워크 I/O이다.

그 작업이 일어나는 동안, 네트워크에게 CPU를 안주면 어떻게 될까?

CPU는 효율적으로 다른곳에서 사용되겠지만, 사용자는 답답하게된다. 아무것도 안나오니까..

네트워크로 웹 페이지를 읽어오는 동안에도 화면에 당장 보여줄 수 있는 것만이라도 보여주면 사람이 느끼기에 더 빠르게 느껴진다.

HTMl 문서를 읽어와서 홤녀에 표시하려고 봤더니, HTML안에 텍스트만 있는게 아니라 이미지도 있다. 그럼 또 그 이미지 url을 받아오려고 웹 서버에 요청하게 되고..

이렇게 오래 걸리는 작업이니까 이걸 Blocked 시켜버리면, 화면에 아무것도 안나오게 되고 사용자는 답답함을 느끼게 된다.

하나의 스레드가 네트워크로부터 화면을 읽어오는 동안에 다른 스레드가 화면에 표시할 텍스트라도 표시해주면 사람이 느끼기에 응답성이 더 빠르게 느껴진다는 것이다.

결론은, **한 스레드가 Blocked 상태인 동안에도 다른 스레드가 running을 하면 더 응답성이 빨라질 수 있다** 는 말.

예전에 비동기식 입출력을 설명하면서, 입출력이 진행되는 동안에 입출력을 요청한 프로세스를 Blocked 시키면 동기식이 되는데 그렇게 하지 않고 I/O가 완료가 되던 말던 프로세스가 바로 할 수 있는 일이 있으면 하게 해준다.

즉, CPU제어권을 바로 넘겨서 할 수 있게 한다. 라고 했었는데 그게 사실 스레드가 여러개 있는 경우에 가능하게 된다.

스레드 A가 I/O를 하러 갔더라도, 스레드 B가 할 일이 있다면 이 친구에게 CPU를 바로 주더라도 일을 할 수 있으니까 그런 비동기식 입출력도 사실은 스레드 환경에서 효과적으로 동작할 수 있게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/7e2e0a69-731c-4518-8096-db5424aaef1e/image.png)

PCB는 프로세스 하나를 관리하기 위한 구조인데,

프로세스 안에 스레드가 여러개 있다면 PCB에서 CPU 수행과 관련된 정보(PC,register)만 따로 빼서 관리한다.

![](https://velog.velcdn.com/images/sujipark2009/post/6d332773-f2af-44d5-a8a7-f8069bb89089/image.png)

code,data, 어떤 file을 열었는가.. 이런 정보들은 스레드끼리 공유하게 되고

stack,register 같은 건 스레드마다 별도로 가지고 있게 된다.

스레드의 장점은,

1. 응답성이 빠르다

하나의 스레드가 네트워크를 통해 읽어오는 동안 다른 스레드가 화면에 표시할 수 있다.

2. 자원을 공유하는 효과가 있다.

동일 프로세스 안에 있는 스레드 끼리는 CPU수행과 관련된 정보를 제외한 나머지를 공유한다.

3. 똑같은 일을 프로세스 여러개로 하느냐 vs 프로세스 안에 스레드 여러개를 두느냐

프로세스 하나를 만드는 것에 비해, 스레드 하나를 만드는게 훨씬 효율적이라고 한다.

Solaris의 경우 30배 정도 효율적이라고 한다.

또한 동일한 프로세스 안에서 스레드 A -> B로 넘어가는 오버헤드와 프로세스 A -> B로 넘어가는 오버헤드를 비교하면 5배 차이가 난다고 함.

4. Utilization of MP Architecture

멀티 프로세서(CPU가 여러개)환경에서, 스레드를 사용해서 **병렬성(Parallel)**을 추구할 수 있다.

1000 x 1000 행렬을 곱셈해야 한다면, 한 행 한 열을 순차적으로 계산해야한다.

근데 CPU가 여러개거나, CPU안에 여러 **core**가 있다면, 그런 행렬의 곱셈을 여러 스레드로 나누어서 병렬적으로 처리하면 더 빨리 결과를 얻을 수 있다.

...

스레드를 구현하는 방법은 어떤게 있을까?

OS가 이미 스레드의 존재를 알게 구현하는 커널스레드 방식이 있는데

이 경우는, 서로 다른 스레드가 OS에게 마치 서로 다른 프로세스처럼 보이기 때문에 OS가 CPU 스케쥴링을 할 때 A라는 프로세스에서 B라는 프로세스로 넘겨야지 이게 A라는 스레드에서 B라는 스레드로 넘겨야지.. 이렇게 되는 것이다.

유저 스레드라는 것도 있는데, 이것은 OS가 스레드의 존재를 모르도록 하는 것이다.

사용자가 프로그램을 만들 때 스레드에 기반해서 만들었지만 OS가 볼 때는 스레드가 없는 하나의 프로세스로 보이는 것이다.

이런 상황에서는 OS는 그냥 그 프로세스에게 CPU를 주는 것이고, 그 프로세스 내부에서 A라는 스레드가 실행되다가 I/O를 하러가면 OS에게 비동기실 입출력을 요청해서 바로 CPU를 받은 다음에 B라는 스레드에게 CPU를 넘기고 .. 이렇게 사용자 프로그램 단에서 스레드를 관리하는게 유저 스레드이다.

이건 구현을 어떻게 하느냐에 따라 다른 문제이다.

...

#### 프로세스 생성(Process Creation)

---

프로세스는 어떻게 만들어질까?

부모 프로세스가 자식 프로세스를 만들게 되는데, 부모 프로세스가 자식 프로세스를 만들면 **복제생성**을 하게 된다.

부모와 똑같은 나이를 가진 그런 프로세스가 만들어진다.

그럼 프로세스는 사용자 프로세스가 만들까 아니면 OS가 만들까?

프로세스를 만드려면 PID도 필요하고, PCB도 필요한데 이걸 사용자 프로세스가 만드는게 맞나?

사실 우리가 직접 못하는건 `시스템 콜` 을 통해 OS에게 요청을 할 수 있는데, 부모 프로세스가 자식 프로세스를 만들 때 본인이 직접 만들지는 못하고 OS에게 만들어달라고 요청을 해서 만들게 되는데 그 시스템 콜이 바로 `fork()` 이다.

fork()는 자식 프로세스를 만들어달라고 호출하는 시스템 콜이다.

부모가 자식을 만들면 트리(계층)구조가 형성이 된다.

프로세스가 실행되려면 자원이 필요하고 그 자원은 OS로부터 받게 되는데 경우에 따라서는 부모 프로세스와 자식 프로세스가 자원을 공유하는 경우도 있다.

스레드끼리는 자원을 공유할 수 있었는데 프로세스간에도 가능하다는 말인가?

부모 프로세스가 자식 프로세스를 만들면, 이 둘은 서로 독립적인 프로세스이다.
그래서 원칙적으로는 프로세스간에 자원을 공유하는게 아니라 자원을 가지고 경합하게 된다.

공유한다는건 이례적인 경우에 공유할 수 있다 이렇게 보면 된다.

자식 프로세스가 만들어지면, 그 둘은 별개의 프로세스이기 때문에 각자 수행이 되는데 자식을 만든 다음에 부모하고 자식간의 관계가 서로 경쟁하는 관계인 경우도 있고,

어떤 경우에는 자식을 만들어놓고 자식이 종료될 때 까지 부모가 일을 안하고 기다리는 경우도 있다.

원칙은 자식을 만들면 부모 자식 둘 다 독립적으로 돌아가는건데, 부모가 기다리는 `Blocked` 상태가 되는 그런 경우가 있다..

일단 프로세스가 만들어지면, 그 프로세스만의 독자적인 주소공간 code,data,stack이 만들어진다.

자식 프로세스는, 부모의 메모리를 그대로 복사해서 만들어지는데 code,data,stack을 다 복사하게 된다.

전역변수나 stack도 그대로 COPY한다는 이야기는, 부모가 수행하고 있는 그 위치에서부터 자식이 수행된다는 이야기이다.

부모가 수행한 바로 그 Program Counter를 복사하기 때문에 그 위치에서부터 실행되게 된다.

그렇게 되면, 시스템 안에 존재하는 모든 프로세스는 다 같은 일만 하고있겠지? 부모를 복제생성하면?..

그런데 우리는 여러 프로세스를 돌리고있다.

일단은, 복제를 해놓고 거기다가 돌리고 싶은 프로그램을 덮어씌워서 새로운 프로그램을 돌리는 것이다.

프로세스가 하나 만들어질 때는, fork()를 해서 복제생성을 해놓고 다른 프로그램을 돌리고싶다!! 하면,
자식에다가 새로운 프로그램을 올려서 돌리는데 그걸 `exec()` 시스템 콜 이라고 한다.

프로세스가 종료될 때는, `exit` 이라는 시스템 콜을 해서 종료를 하겠다라고 표시를 하면 OS가 종료시키게 된다.

모든 자원을 반납하고 종료를 하는데, 프로세스는 항상 부모 프로세스가 자식을 만들었을 경우 자식 프로세스가 종료될 때 부모에게 자식이 종료된다는 사실을 알리게 된다.

이렇게 프로세스의 세계에서는, 계층 구조도에서 자식이 먼저 죽고.. 부모가 그 뒤처리를 하는 구조로 되어있다.

근데 이것도 2가지가 있는데..

프로세스가 자발적으로 exit 시스템 콜을 호출해서 종료가 되고 부모에게 통보가 되는 경우와,

부모가 자식을 강제로 죽이는 `abort` 경우가 있다.

어떤 경우에 자식 프로세스를 강제로 죽이느냐 하면, 자식이 자원의 할당치를 넘어서는 행동을 하거나, 일을 시키려고 자식을 만들었는데 더 이상 시킬 일이 없는 경우이다.

이런게 일반적인 룰이다.

그런데, 부모가 먼저 종료하는 경우가 있다.

그럴때는,, 룰을 위반하게 되니까 그 룰을 지키기 위해 부모가 죽기전에 **자식을 먼저 죽이고** 죽게된다.

트리 구조의 맨 아래부터 순차적으로 죽이고 올라가야하며, 이걸 단계적인 종료라고 한다.

#### fork() 시스템 콜

---

![](https://velog.velcdn.com/images/sujipark2009/post/bf52574f-4be4-45c6-81ff-17bc77667877/image.png)

fork()를 호출한 부모 프로세스는, 그 다음 부분을 수행하게 되고 자식 프로세스는 fork()를 한 바로 다음부터 부모와 똑같은 위치부터 수행을 하게 된다.

그런데, 이게 부모인지..자식인지.. 구분할 수가 없다.

fork를 해서 자식을 만들어놨는데, 이게 자식인지 부모인지 구분할 필요가 있는데 이걸 fork()를 호출한 **결과값**으로 구분하게 된다.

return value가 부모 프로세스인 경우, 양수를 받게되고 그 양수는 사실 자식 프로세스의 PID를 의미한다.

자식 프로세스는 fork()의 결과값으로 0을 받게되서 로직에서 자식과 부모를 구분할 수 있게 된다.

나는 부모다 => pid > 0 인 로직 수행

나는 자식 => pid == 0 인 로직 수행

pid를 통한 로직 구분이 없으면, 부모나 자식이나 같은 일을 하게 되는 것이다.

어쨌든, fork의 결과값이 다르다고 하더라도 이것은 하나의 프로세스의 동일한 실행파일을 돌린것에 불과하다.

완전히 다른 프로그램을 돌리려면, 새로운 프로그램을 덮어씌우는게 필요하다.

#### exec() 시스템 콜

---

![](https://velog.velcdn.com/images/sujipark2009/post/d4e6e077-7dca-488d-8ca2-880eef53302b/image.png)

저렇게, `execlp` 라는 명령어를 통해 실행하게 되는데

하나의 프로세스를 완전히 다른 프로세스로 덮어씌워서 실행을 하는 그런 역할을 하나다.

간단하게 살펴보면,

![](https://velog.velcdn.com/images/sujipark2009/post/dd62bfa3-d0e1-4c75-8dd5-34bd7b0d3ba6/image.png)

이런 프로그램을 만들었다고 해보자.

화면에 Hello를 출력하고 그 다음 라인에 어떤 함수를 호출했는데, 이건 새로운 프로그램으로 덮어씌우는 함수이다.

execlp의 사용방법은,

- 경로를 포함한 프로그램의 이름을 2번 적어주고
- 3번째 argument 부터는 이 프로그램에 전달할 argument를 나열하고 마지막에 zero pointer를 보내주면 실행이 된다.

참고로 date는 현재 날짜를 표현하는 linux 명령어이다.

![](https://velog.velcdn.com/images/sujipark2009/post/f6d48490-e8eb-4370-a39a-c174b2fedc3d/image.png)

이렇게 수행하면, execlp 아래의 명령어는 수행이 안되는데 왜냐하면 **완전히 새로운 프로그램**이 되기 때문이다.

보통 fork()와 연계지어서 설명을 하게 되는데, 자식 프로세스에게 새로운 프로그램을 덮어씌우려고 하기 때문이다.

나는 main에서 시작해서 쭉 흘러가는데 자식에게는 다른 일을 시키고싶다! 가 일반적인 흐름이기 때문

...

#### wait() 시스템 콜

---

![](https://velog.velcdn.com/images/sujipark2009/post/786af1ed-65db-4739-972a-5b1c6777683c/image.png)

부모 프로세스가 자신의 코드를 보다가 fork() 가 있으면 자신을 그대로 복제한 자식 프로세스를 만들게 된다.

부모가 만약에 자식을 만들어놓고 wait 시스템 콜을 하게 되면, 자식이 끝날때까지 부모 프로세스를 blocked상태(sleep)로 만들어 놓는다.

프로세스가 blocked 되는 경우는 오래 걸리는 작업(I/O)나, 공유 데이터를 기다리는 경우라고 했었는데, 자식의 종료를 기다리는 경우에도 blocked가 될 수 있다.

그럼 언제 깨어나서 Ready queue로 돌아와서 CPU를 얻을 수 있게 될까?

**자식이 종료되면 부모가 다시 CPU를 얻을 수 있게 된다**

리눅스에서, 커맨드를 쳐본 경험이 있으면 wait 시스템 콜을 다 경험해본 것인데

예를들어 vi a 라고 치고 파일 편집기로 들어가면, 그 프로그램이 종료될때까지는 아무것도 뜨는게 없고 종료되면 다시 무언가를 입력할 수 있는 터미널로 돌아가게 된다.

리눅스에서 커맨드를 입력할때는 그 커맨드를 입력받는 자체가 하나의 프로세스이다.(shell 이라 함)

이러한 커맨드를 실행시키면 그것의 자식 프로세스 형태로 커맨드가 실행되는 것이다.

그래서 vi가 입력이 되면, 부모 프로세스는 커맨드를 입력받지 못하도록 blocked 가 되었다가 자식이 종료되어야 다시 깨어나서 커맨드를 입력받을 수 있게 되는 것이다.

보통 wait을 하지 않으면, 부모와 자식은 서로 경쟁적인 프로세스가 되지만 부모가 wait을 호출하면 자식이 종료될 때 까지 부모는 blocked 상태가 된다.

#### exit() 시스템 콜

---

![](https://velog.velcdn.com/images/sujipark2009/post/31760a26-d02f-4a0a-b942-f4298800da14/image.png)

이것은 프로세스를 종료시키는 시스템 콜이다.

C언어로 프로그래밍을 했을 때, 마지막에 exit을 명시적으로 호출하지 않더라도 컴파일러가 자동으로 넣어주게 된다.

혹은, 우리가 명시적으로 exit 시스템 콜을 호출할 수도 있다

exit이라는 건 프로세스가 정상적으로 종료시킬 때 사용되는 명령어이다.

또 비자발적 종료라는게 있는데, 이건 본인이 원하지 않는데 강제로 종료되는 경우로

부모 프로세스가 자식을 강제 종료시키는 경우가 있다.

한계를 넘었다거나,, 더 필요없다거나 한 경우.

프로세스의 세계에서는, 자식이 먼저 죽고 부목 죽는 룰이 있다고 했다.
그런데 만약 부모 프로세스가 종료가 된다? 그럼 그 전에 자식을 먼저 싹 죽이고 나서 본인이 죽도록 되어있다.

exit 시스템 콜을 호출하게 되면, 모든 자원을 다 반납하고 부모 프로세스에게 본인이 죽는다는 걸 전달하게 됨으로써 프로세스는 제 역할을 다 하게 된다.

...

#### 프로세스 간 협력

---

![](https://velog.velcdn.com/images/sujipark2009/post/798d7f79-de81-4554-92bb-67753a2b87f8/image.png)

일반적으로 프로세스는 만들어 놓으면 각자 독립적으로 동작하게 된다.

서로 간섭을 주지 않고, 자기 혼자만 OS를 쓴다는 전제하에 만들어졌기 때문에 CPU달라..메모리 달라.. 이렇게 한다.

A라는 프로세느는 B라는 프로세스의 메모리 공간을 볼 수 없으며, 항상 자기자신의 주소공간만 볼 수 있도록 되어있다.

![](https://velog.velcdn.com/images/sujipark2009/post/2fbf0dbb-6257-45d2-ac19-026c569fbd36/image.png)

이렇게 실행파일을 실행시켜 프로세스가 되면, 각자 자신의 주소공간만 보며 일을하게 되는 것이다.

그래서 A는 저기 파란영역만 접근할 수 있으며, 빨간공간에는 접근자체를 할 수 없다.

근데 여기서 말하는건 프로세스간 **협력** 이다.

경우에 따라 프로세스들끼리 협력이 필요한 경우가 있을텐데, 그럴 때 어떤 식으로 협력을 할 수 있을까?

바로 **IPC(Interprocess Communication)** 을 통해 프로세스끼리 정보를 전달할 수 있게 된다.

2가지 방법이 있는데,

1. **`Shared Memory`**

메모리를 서로 공유하는 방법이다.

![](https://velog.velcdn.com/images/sujipark2009/post/0c449aa0-f788-45b0-b50c-c887773a9b46/image.png)

지금 빨간색이 A의 공간이고 노란색이 B의 공간인데, 그 사이에 겹쳐지는 부분이 있다.

이게 바로 `Shared Memory` 라는 것이다.

원칙적으로 프로세스는 본인의 code,stack,data 영역만 접근할 수 있도록 되어있어서 다른 프로세스가 접근할 수 없다.

이것도 사실 OS에게 부탁해서 "나는 이 친구와 메모리 일부공간을 공유해서 쓰겠습니다!!"" 하면 OS가 해당 부분을 공유하도록 알려주는 것이다.

메모리를 공유한다는 것은,서로 협력이 가능하다는 것이다.

공유공간에 A가 뭐라고 써 넣으면 B는 그걸 읽어서 프로세스간의 커뮤니케이션이 가능해진다.

근데 여기서 주의할 점은, 두 프로세스가 서로 신뢰할 수 있는 경우에는 공유해도 상관이 없는데, share를 해놨더니 다른 프로세스가 이상할 수 있다.. 는 그런 단점이 존재하긴 한다.

그럼, **Thread는** 협력을 하기가 더 쉬울까 어려울까?

thread는 하나의 프로세스 안에 CPU 수행단위인 스레드가 여러 개 존재하는 것이다.
thread 간에는 메모리 공간을 어느정도 공유하는게 아니라, 메모리 공간이 하나뿐이다.

스레드들 끼리는 협력이 훨씬 쉬운것이다.

shared메모리는 명시적으로 서로 다른 프로세스 둘이서 OS에게 시스템 콜을 해서 일정부분을 공유하겠다 하고 쓰는것이고, 스레드는 스레드를 만드는 것 자체가 주소공간이 공유가 되는 것이다.

2. **`Message Passing`**

이것은 말 그대로 프로세스 A가 B에게 어떤 메시지를 전달하는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/f4051351-521b-4735-b273-184ec4f6fad3/image.png)

P라는 프로세스가 Q라는 프로세스에게 메시지를 전달하는 것이다.

Send(Q,Message) -> Receive(P,Message)

그럼 메시지는 대체 뭘로 보낼까?.. 자기 주소공간만 볼 수 있고 사실 메시지를 보내는 방법 자체도 없다.

![업로드중..](blob:https://velog.io/886ffbba-0871-45f0-ac6b-90d1d20b696b)

OS가 매게가 되어서, A는 B에게 메시지를 보내겠다고 시스템 콜을 하게 되고, OS는 그걸 B에게 전달해주는 것이다.

Message Passing은 2가지가 있는데,

`Direct Communication`,`Indirect Communication` 이 있다.

Direct는 말 그대로 누구에게 보낼 지 직접 명시하는 것이고, Indirect는 누가 받을 지 명시하지 않고 그냥 어떤 메일박스나 port에다가 메시지를 집어넣는 것이다.

Q가 운좋게 메일박스를 열어봤으면 Q가 받을거고.. 다른 프로세스가 열어보면 다른 프로세스가 받을꺼고.. 협력하는 프로세스 중 누군가가 꺼내도록 하는 방법.

어쨌든, OS의 커널에 메시지를 전달해서 다른 프로세스가 커널로부터 전달을 받는 이런 방법을 사용한다는 것이다..
