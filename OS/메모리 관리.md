### 배경지식

#### Logical vs Physical Address

---

![](https://velog.velcdn.com/images/sujipark2009/post/c56fa9ed-480e-4a29-9db3-f96d848e3ab1/image.png)

메모리는 주소를 통해서 접근하는 장치이다.

메모리의 종류는 크게 2가지가 있는데, 하나는 **Logical**, 하나는 **Physical**이다.

물리적인 메모리에는 기본적으로 OS 커널이 올라가있고 사용자 프로그램들이 디스크에 실행파일의 형태로 존재하다가 사용자가 실행시키면 메모리에 올라가서 프로세스가 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/bdd10945-4580-4aac-9815-86968e1b3060/image.png)

저기에 있는 메모리는 실제 물리적 메모리이고.. 낮은 주소부터 OS의 커널이 존재한다.

![](https://velog.velcdn.com/images/sujipark2009/post/bc1541aa-f566-4b7a-82ee-e5dc13763911/image.png)

그런데, 실제로는 저렇게 올라가는게 아니라 한단계를 더 거치게 되는데

프로그램이 실행되면 그 프로그램만의 독자적인 메모리 주소공간인 `가상 메모리`가 생긴다.

프로세스마다 0번지부터 시작하는 각자의 메모리주소가 생기게 된다.

그리고 이것들이 실제 물리적 메모리에 올라가야 실행이 되기에 이 과정에서 `주소 변환` 이라는 것이 이루어지게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/736a4720-92e9-4b48-9336-4fd1ab402094/image.png)

프로세스 A의 가상메모리 0번지에 있던 어떤 데이터를 실제 메모리에 올릴 때,
실제 메모리의 0번지에는 다른 프로세스가 동작하고 있을 수 있기 때문에 다른 위치에 올려야한다.

그런데 우리가 프로그래밍을 할 때, 논리적이던 물리적이던 메모리를 사용하긴 하지만
메모리 주소를 직접 적어가며 프로그래밍을 하지는 않는다.

int a,b 이런식으로 `symbol`을 사용하여 프로그래밍을 하게 된다.

프로그래머는 이렇게 주소를 생각할 때 숫자로 된 주소가 아닌, 변수 이름이나 함수 이름처럼 symbol로 된 주소를 가지고 프로그래밍을 하는데 그것을 여기에서는 `Symbolic Address`라고 부른다.

이것이 컴파일이 되어서 실행파일이 만들어지면, 그 프로그램만의 독자적인 메모리 주 소가 매겨지고 진짜 메모리에 올라가서 실행이 될 때는 물리적인 메모리 주소를 가지게 된다.

그럼 프로세스마다 가지게되는 **Logical Address**기 **Physical Address**로 바뀌는 시점은 언제일까?

#### 주소 바인딩(Address Binding)

---

![](https://velog.velcdn.com/images/sujipark2009/post/1c470033-dc48-4d34-a759-d3cdddf1aff5/image.png)

이 주소변환은 하드웨어가 해주는데, 이러한 주소변환을 `주소 바인딩` 이라고 부른다.

주소변환의 시점에 따라 여러가지로 나눌 수 있다.

![](https://velog.velcdn.com/images/sujipark2009/post/96e656a2-93d7-4013-8c0e-2e7302d4b73e/image.png)

그림을 살펴보면, 좌측에 프로그램의 소스코드가 있다.

ADD A,B는 A와 B를 더해서 A에 저장하라는 의미이다.
이 문장을 수행하고 나면, A의 값은 430으로 바뀌고 Jump C를 통해 exit하면서 종료가 될 것이다.

이렇게 고급언어로 프로그래밍을 할 때는 저렇게 Symbol을 이용해서 메모리의 위치를 표시하고 Jump하는 등의 방법으로 코딩을 하게 된다.

그런데 이게 컴파일이 되어서 실행파일이 되면, 이 Symbol들이 숫자로 된 주소로 바뀌게 된다.

ADD A,B가 Logical Address로 바뀌어서 20번지의 내용과 30번지의 내용을 더해서 20번지에 저장하라는 식으로 바뀌게 된다.

이것을 실행시켜서 프로세스가 되면 이러한 내용이 메모리에 올라가서 실행이 될 것이다.

이때, 논리적인 메모리 주소가 물리적인 주소로 바뀌어야 하는데 시점을 살펴보자.

![](https://velog.velcdn.com/images/sujipark2009/post/f2c62992-cfd1-43e8-b986-79e67a368f16/image.png)

#### Compile time binding

---

컴파일을 하는 시점에 이미 **논리적인 주소 = 물리적인 주소** 가 되는 것이다.

내가 만든 이 프로그램을 메모리에 올릴때 항상 0번지부터 올라가야한다~ 이런 의미이다.

이 방식은 대단히 비효율적ㅇ인데, 실제 0번지에는 현대 OS의 커널이 위치하는 곳이기 때문이다.

그냥 그대로 메모리에 올리면 되는 `절대코드(absolute code)` 를 생성한다.

#### Load time binding

---

논리적인 주소가 물리적인 주소로 바뀌는 시점이, **프로그램을 실행시키는 시점에 바뀌게 된다.**

그럼 Loadtime과 Runtime의 차이는 뭘까?

Load time은 이 프로그램의 실행이 시작되는 시점에 주소가 변환이 되고 **주소가 바뀌지 않는다**

`재배치 가능 코드(relocatable code)`라는 의미는, 메모리의 주소가 바뀔 수 있는 코드라는 의미이다.

#### Run time binding

---

프로그램이 실행될 때 주소바인딩이 이루어지고, 프로그램이 실행되는 도중에 바인딩이 바뀔 수 있다는 것이다.

아까 300번지에 올라갔었는데 700번지로 이동을 하는 등의 수행이 시작된 이후에도 프로세스의 메모리 상 위치를 옮길 수 있다는 것이다.

여기서 한가지 질문은,

**CPU가 바라보는 주소는 물리적 주소일까 논리적 주소일까?**

CPU는 HW이니까 물리적 주소를 바라볼 것 같은데, 실제로는 **논리적 주소**를 바라보게 된다.

아까 소스코드를 컴파일해서 만든 실행파일이 있었는데, 바인딩과정에서 실제 주소가 바뀔 수 있다고 했었다.

![](https://velog.velcdn.com/images/sujipark2009/post/04c42a50-81c2-4415-b714-8ae19c271a9f/image.png)

그런데, 컴파일해서 나온 실행파일 안의 주소는 `논리적 주소`이다.

실행파일의 0번지에 있던 내용이 실제 물리적 주소 500번지에 올라가는 것처럼 실제 메모리에 올라갈때는 주소가 변환이 되지만, 실행파일 안에 있는 주소(20번지,30번지..)는 바뀔수가 없다.

컴파일해서 만들어진 그 안에있는 주소는 논리적 주소이기 때문에 바꿀수가 없다.
저것을 바꾸려면 컴파일을 다시 해야하기 때문이다.

그래서 CPU는 매 순간 기계어를 실행하는데, 그 기계어에 있는 주소는 논리적인 주소가 될 수 밖에 없다.

컴파일해서 만들어지는 코드는 논리적인 주소이기 때문이다.

그래서 CPU가 기계어를 실행하려면 그 주소를 하나하나 물리적 주소로 변환하는 과정이 필요하다.

![](https://velog.velcdn.com/images/sujipark2009/post/a2845645-8018-444d-8f12-a72fe9bc0a99/image.png)

여기서 Jump 40이라고 했으면, 실제로는 540번지로 가는것으로 변환을 해야한다.

Runtime Binding에서는 까다로운 점이, 300번지에 있던것이 실행시에는 700번지로 가고 그럴 수 있으니, CPU가 메모리를 접근할 때마다 바인딩을 점검해야한다.

그런 메모리 주소를 변환하는 행위는 OS가 하는 행위가 아니라 HW가 하는 일이라고 했었다.

#### Memory Management Unit(MMU)

---

![](https://velog.velcdn.com/images/sujipark2009/post/9f65501d-85d7-41b4-8441-73124a00a924/image.png)

주소 변환을 하는 하드웨어를 MMU라고 부른다.

![](https://velog.velcdn.com/images/sujipark2009/post/cdb7f22c-1660-414f-9d8d-49a9a6986dc9/image.png)

간단한 주소변환은 이런식으로 이루어지는데, 실제는 더 복잡하다. 메모리가 쪼개져서 필요한 곳에 산발적으로 올라가기 때문인데 여기서는 간단하게만 살펴보자.

프로그램이 실행되면서 CPU가 346번지에 있는 내용을 달라! 하면

![](https://velog.velcdn.com/images/sujipark2009/post/79348027-95cb-4a8e-959e-6e6b4327a5f2/image.png)

CPU가 보는 주소는 논리적 주소라고 했고, 실제 저 검은 부분을 요청한 것이다.

이 프로그램이 실제 물리적 메모리에 올라가있는데, 이 프로그램의 논리적 주소 0번지가 실제 메모리의 14000번지에 올라가있다.

그래서 14000~17000까지 올라가있다고 볼 수 있다.

주소 변환을 하는 방법은, 346번지를 달라고 했으면 시작 위치가 14000이니까 14000+346의 물리적 주소 14346번지 주소가 나온다.

이렇게 프로그램이 통째로 메모리에 올라가는 환경에서는 register가 2개만 있으면 된다.

`Relocation register`(= base register)는 물리적 메모리의 시작위치를 가지고

`limit register`는 논리적 주소의 범위를 담고있다. 이것이 필요한 이유는 만약 이 프로그램이 악의적인 프로그램이라서 5000번지를 달라하는 그런 명령어가 있을 경우,

14000 + 5000을 한 결과가 이 프로세스의 위치를 벗어나 다른 프로세스의 위치가 되버릴 수 있기에 이런것을 막기 위함이다.

![](https://velog.velcdn.com/images/sujipark2009/post/d42dc9bd-121c-4074-acde-0af85db1384e/image.png)

다시 살펴보면, CPU가 논리적 주소를 주면 MMU가 limit register보다 작은지를 확인하고, 거기에다가 base register의 값을 더해서 메모리 변환을 한다.

만약 잘못된 경우 trap이라는 SW 인터럽트를 걸게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/6acb74bf-62b4-4255-b997-0a9465cc3558/image.png)

몇 가지 용어를 살펴보자.

#### Dynamic Loading

---

Loading은 메모리에 올리는 것을 말하는데, 동적 로딩이라는 것은 메모리에 올리긴 하는데 한번에 올리는 게 아니라 그때그때 올리는 것을 말한다.

이렇게 하면 Memory utilization이 향상된다.

프로그램을 만들면 그 프로그램 안의 코드가 다 사용되는게 아니다.
예외적인 상황을 처리하는 코드가 대부분의 프로그램안에 많이 있는데, 그런 부분은 잘 실행되지 않는 부분이다.

그런 부분까지 메모리에 올리게되면 낭비가 되기때문에 실제 실행되는 부분만을 메모리에 올려놓으면 메모리를 아낄 수 있다.

Dynamic loading은 누구의 책임일까?

OS ?/ 사용자 프로그램 ?

Dynamic Loading은 OS의 지원없이 프로그램 자체에서 라이브러리를 사용해서 구현이 가능하다.

근데 프로그램을 만들면서, 이건 지금 올리고 저 부분은 나중에 올리고.. 이런것을 하지는 않는다.

그냥 프로그래밍을 하면 OS가 그때그때 필요할때 메모리에 올려준다.

그래서 현대 OS에서 하는 방식은 엄밀히 말하면 Dynamic Loading이 아니다.

#### Overlays

---

![](https://velog.velcdn.com/images/sujipark2009/post/9de0e62b-b24b-4962-9ace-44eb7aaf1d47/image.png)

마찬가지로 필요한 부분을 그때그때 메모리에 올린다는 의미이다.

초장기에는 메모리의 크기가 작아서 프로그램을 다 메모리에 올리는게 불가능했다.
그래서 지금 올리고.. 나중에 올리고.. 이런것을 수동으로 프로그래머가 다 했었다.

~~딱봐도 복잡했을 것 같다.~~

#### Swapping

---

![](https://velog.velcdn.com/images/sujipark2009/post/96d9a323-b9db-408c-952a-3ca4bdbe2bd8/image.png)

메모리에서 쫓아내는 것을 의미한다.

메모리에서 `backing store`(= swap area)로 쫓아내는 것

![](https://velog.velcdn.com/images/sujipark2009/post/eeb67a92-aa40-49fd-8654-829bae088faf/image.png)

워드 프로세스가 메모리에 있다가 swap out되면 디스크로 쫓겨나고, 또 swap in을 통해 들어오고 이렇게 된다.

프로세스의 상태를 살펴보면서 **중기 스케쥴려**라는 것을 살펴봤었는데
중기 스케쥴러는 메모리에 너무 많은 것이 올라오면 비효율적이기 때문에 일부 프로세스를 메모리에서 통째로 쫓아내는 역할을 했었다.

그리고 그렇게 쫓겨나는 경우, 프로세스의 상태는 **suspended**가 됐었다.

swap out된 프로세스는 suspended 상태가 되고, swap in이 되면 ready나 running의 상태가 된다.

메모리가 부족할 때 프로세스를 통째로 쫓아내는게 중기 스케쥴러의 역할이었는데, 그럼 어떤 프로세스를 쫓아낼 것인가..

그것은 CPU 우선순위가 낮은 프로세스를 쫓아내는 것이 적절하겠다~ 라고 했었다.

아까 바인딩 이야기를 했었는데, swapping이 지원이 되려면 바인딩이 **Compile time binding / Load time binding** 에서는 조금 제한이 있게된다.

어떤 프로그램이 swap out 되었다가 다시 들어왔는데 그 공간에 다른것이 들어온다면?

Load time이나 Compile time 바인딩은 항상 같은 주소에 올라가야 해서 이 경우에 제약사항이 있다.

그래서 swapping이 지원이 되려면 **Runtime binding**이 되는 것이 좋다.

원래 메모리 위치로 올라가는것은 상당히 비효율적이므로, Runtime binding의 경우 빈 메모리의 아무곳에나 올릴 수 있다.

그리고 예전에 Disk에 I/O 요청을 하게 되면 가장 오래걸리는 시간이 바로 Disk head를 움직이는 시간이고 실제 데이터를 읽고쓰는 시간(transfer time)은 짧다고 했었는데,

Swapping에서는 파일을 읽고 쓰는것과는 다르게 메모리에 프로세스 주소공간을 통째로 디스크로 쫓아내고 읽어들어오고 하기 때문에 I/O의 양이 굉장히 많다.

여기서는 이례적으로 데이터 transfer time이 swap time의 대부분을 차지하게 된다.

그런데 이렇게 통째로 쫓아내는것도 있지만, 부분적으로 쫓아내는 방식도 있다. 그게 바로 `Paging` 기법인데, 이건 나중에 다시 보자.

#### Dynamic Linking

---

![](https://velog.velcdn.com/images/sujipark2009/post/d4ae9e2a-b792-4219-a83c-9d667f5ff03a/image.png)

우리가 프로그램을 만들게 되면, 컴파일을 하고 Linking을 해서 실행파일이 만들어지게 된다.

프로그램을 만들 때 코드를 내가 다 만드는게 아니다.
내가 만든 함수가 있고, 누군가가 잘 만들어놓은 것을 가져다쓰는 라이브러리가 있는데,

내가 만든 코드 + 라이브러리가 합쳐져서 실행파일이 된다.
이때, 라이브러리를 연결하는 작업을 `Linking` 이라고 하고 이 Linking이 언제 되느냐에 따라서 `Static Linking`과 `Dynamic Linking`으로 나누어진다.

**Static Linking**은, 라이브러리가 프로그램의 실행파일 코드에 포함되는 것이다.

static linking을 하는 라이브러리를 `static library`라 한다.

**Dynamic Linking**은, 라이브러리가 내 실행파일 안에 포함되는게 아니라 별도의 파일로 존재하다가 프로그램 실행 중에 라이브러리를 호출해야할 때 라이브러리가 어디있는지 파일형태로 찾아서 메모리에 올려 연결하는 방식이다.

라이브러리를 찾기위한 위치정보가 포함된 코드(stub)만 둔다.

Dynamic Linking을 하는 라이브러리를 `shared library`라고 한다.

리눅스 환경에서는 이 파일을 **shared object라고 해서, .so 형식의 확장자**를 가진다.

윈도우에서는 **.dll**의 확장자를 가진다.

이 방식의 장점은, 공유를 하는 개념이기 때문에 만약 static linking이였으면

프로그램을 만들어서 printf를 사용한다고 했을 때, 60개의 프로그램을 실행시키면 그 60개에 printf가 각자의 주소공간에 들어가있게 된다.

하지만 shared library로 구현되어있다면, "printf는 어떤 파일에서 찾을 수 있다!"
는 정보를 통해, 중복해서 메모리에 올리는게 아니라 공유해서 실행하게 된다.

#### Allocation of Physical Memory

---

![](https://velog.velcdn.com/images/sujipark2009/post/09931d08-974a-499b-9247-9f1473a14d7e/image.png)

지금부터는 물리적인 메모리의 관리기법을 살펴보자.

물리적 메모리의 낮은주소 영역에는 OS의 커널이 상주하게 되고, 나머지 영역에는 사용자 프로세스가 위치하게 된다.

사용자 프로그램이 위치할 메모리 영역을 어떻게 관리할 것인가.. 에 대해 2가지가 있는데

**`Contiguous allocation(연속할당)`**

연속할당이란, 프로그램이 쪼개지지않고 메모리에 통째로 올라가는 방식을 말한다.

이 경우, 주소변환이 register 2개만 있으면 간단하게 이루어졌었다.

시작 위치만 더해주면 된다.

**Fixed Partition** 방식과, **Variable Partition** 방식이 있다.

둘 다 현대 OS에서는 사용되지 않는 방식이고, 개념적으로만 알아보자.

#### Fixed Partition

---

![](https://velog.velcdn.com/images/sujipark2009/post/2cf7a567-f9f9-4c77-b6c2-542d87bff3bb/image.png)

물리적인 메모리를 미리 나누어놓고 프로세스를 할당하는 것이다.

분할3을 보면, 분할3의 크기가 프로그램 B의 크기보다 더 크기 때문에 내부적으로 남는 공간이 생기는데 이것을 `Internal Fragmentation(내부조각)`이라고 한다.

분할2번은 비어있지만 프로그램A의 크기보다 작아서 활용이 되지 않았다. 결국 낭비되어 버렸는데 이것을 `External Fragmentation(외부조각)`이라고 한다.

이렇게 고정 분할 방식을 사용하면 내/외부 조각 모두가 생겨 메모리가 낭비되게 된다.

#### Variable Partiton

---

여기서는 메모리 영역을 미리 나누지 않고, 프로그램 A,B,C를 그냥 쭉쭉 올려서 슬 수 있다.

그러다가 B가 끝나고 D가 들어가려는데 B의 공간보다 D가 크기 때문에, 거기에는 못 들어가고 다른 부분에 들어가게 되면서 또 B의공간이 낭비되는 `외부조각`문제가 발생하게 된다.

여기서는 내부조각 문제는 발생하지 않는다.

#### Hole

---

Hole이라는 건 가용 메모리 공간이다.

![](https://velog.velcdn.com/images/sujipark2009/post/3f3d2567-50ab-4ffe-bc80-43adb8e03249/image.png)

프로세스가 실행되고 종료되기를 반복하다보면, 여유공간들이 흩어져있게 된다.

프로그램이 실행될 때 저 가용공간 중 어디다가 올릴 것인지를 결정해야 한다.

#### Dynamic Storage Allocation Problem

---

![](https://velog.velcdn.com/images/sujipark2009/post/91e54626-42d3-43c9-8eb3-10023710d1b6/image.png)

`First-fit`은 가장 먼저 발견되는 빈 공간에 넣는 방법

`Best-fit`은 여러 hole중에 프로그램이 딱 들어갈 수 있는 최적의 공간이다.

맞춤형으로 넣으니 좋긴하지만, 다 찾아봐야 한다는 탐색 overhead가 존재한다.
아무리 잘해도 hole은 생길 것이다.

`Worst-fit`은 가장 큰 hole에 집어넣는 것이다.

이것은, 나중에 더 큰 프로그램이 실행될 여지가 없어지기에 좋은 방법은 아니다.

First-fit과 Best-fit 이 Worst-fit보다 속도 / 공간 이용률 측면에서 효과적이라고 한다.

![](https://velog.velcdn.com/images/sujipark2009/post/e7ba7a28-bbe0-4e22-a024-cd346656fdbd/image.png)

외부 단편화(외부조각)을 해결하는 방법 중 하나로, **compaction**이 있는데, 완전 비효율적이다.

프로세스를 다 밀어야하기 때문이다.

최적화를 하기 위해서는 이론적으로도 매우 복잡하다. 그리고 Runtime binding에서만 Compaction이 가능해진다.

**`NonContiguous allocation(불연속할당)`**

![](https://velog.velcdn.com/images/sujipark2009/post/d36bec20-1c84-4ed9-b46d-bcacfbe981bb/image.png)

연속할당에서는 프로그램을 구성하는 가상메모리 공간이 물리적인 메모리에 통째로 올라가는 것을 전재로 하고 있다.

이러한 환경에서는 메모리 주소변환이 비교적 간단했었는데, 각각의 프로그램마다 0번지부터 시작하는 독자적인 메모리 주소가 있는데 이게 실제 물리적 메모리에 올라왔을 때의 시작지점만 알면 되기 때문에 간단했었다.

register 2개 (base register + limit register)로 주소변환을 했었다.

그런데, 불연속할당은 통째가 아니라 잘려진 조각이 올라가기 때문에 그 조각 하나하나의 시작위치를 얻을 수 있어야 한다.

일반적인 방식에는 page하나가 4KB의 동일한 크기로 잘리게 되고, 이 각각에 대한 주소변환이 필요하게 된다.

그럼 register가 여러개가 필요할까? 그러면 너무 많을 것 같다..

그런 것을 매핑해놓은게 메모리에 mapping table 형태로 올라가게 되는데, 살펴보자.

#### Paging

---

![](https://velog.velcdn.com/images/sujipark2009/post/62f75583-5253-41a9-92c0-a7b07bc6b601/image.png)

Paging기법이란, 프로세스 각각의 주소공간을 동일한 크기의 Page 단위로 나누는 것이다.

전체를 다 메모리에 올리는게 아니라, 일부는 backing storage에 일부는 physical memory에 저장하게 된다.

같은 크기로 자르니까 물리적인 메모리 또한 그 페이지가 들어갈 수 있는 동일한 크기로 잘라놔야한다.

그래서 물리적인 메모리를 page의 크기로 나눈것을 `frame` 이라고 한다.

프로세스를 구성하는 가상 메모리는 page단위, 물리적 메모리는 frame단위로 자른다고 생각하면 된다.

그리고 주소 변환은 `page table`이라는 것으로 하게 된다.

paing기법은 앞의 연속할당 기법과는 다르게 외부 단편화가 발생하지 않는다.
단, 내부 단편화는 생길 수 있다.

프로그램을 구성하는 주소공간을 4KB크기로 자르다보면 꼭 4KB로 나누어떨어진다는 보장이 없기때문에 그렇기에 남은 공간이 생길 수 있다고 생각하면 된다.

(19KB 짜리를 4로 나누면, 4칸하고 3KB가 남는데 이 경우 1KB의 내부 단편화가 생긴다)

![](https://velog.velcdn.com/images/sujipark2009/post/0fa6e962-d59a-49d0-b85d-f1f9e145c5d8/image.png)

논리적인 메모리를 4개의 페이지로 나누고, 각 페이지는 물리적 메모리의 서로 다른 위치에 올라갈 수 있다.

그리고 이들에 대한 주소변환은 각각의 페이지가 어디에 올라가있는지를 찾아주는 page table을 통해서 하게 된다.

1번 페이지가 4번 프레임에 있구나 하고 알 수 있다.

사실 어떠한 페이지는 프레임에 안 올라가있을 수도 있으니, 그것을 판별하기 위한 `valid-invalid bit`이 존재한다.

![](https://velog.velcdn.com/images/sujipark2009/post/af02814d-970e-4be3-a3df-8f5c162f7392/image.png)

CPU가 보는 논리적인 주소를 페이지 테이블을 통해 물리적인 주소로 바꾸게 된다.

주소를 <page번호,페이지내부의 offset> 으로 구분하여 변환하게 된다.

offset정보는 페이지 내부에서의 상대적인 위치이므로, 이 상대적인 위치는 프레임에 올라가더라도 변하지 않는다.

여기서 저 주소가 32bit라고 해보면, 프로그램의 최대 크기는 얼마일까?

메모리의 주소 단위는 1B로 나누어지는데, 1bit면 2B를 구분할 수 있다.

그러면,32bit는 2^32B를 구분할 수 있는데, 이것은 4GB의 주소공간을 만들 수 있다는 의미이다.

4GB를 4KB 단위의 페이지로 자른다고 했는데, 그럼 2^20개의 페이지가 나오게 된다.

1M(약 100만개)가 나오게 된다.

통째로 올라가는 연속할당에서는 시작위치를 기록하는 레지스터만 있으면 주소변환이 쉽게 되었는데, 지금 페이징 기법에서는 페이지가 100만개가 생기므로, 페이지 테이블의 Entry가 100만개가 필요하다는 이야기이다.

그러면 32bit 주소 중에 페이지 번호는 몇 bit이고 offset은 몇 bit일까?

2^20개의 페이지가 나오므로, 페이지 번호는 20bit이고 페이지의 크기가 4KB(=2^12)이므로 12bit가 될 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/38f2c2e4-6e8d-4679-9a7d-7f949bc61f24/image.png)

그래서 페이지의 개수가 프로세스마다 100만개가 넘게되는 상황이다.
(각각의 프로세스는 각자의 메모리 공간을 가지고있으므로)

저런것을 담을 수 있는 레지스터는 없다.

그래서 페이지 테이블은 Main Memory에 올라가서 상주하게 된다.

기존에 Base register와 limit register가 있었는데, 이것이 이제
`Page table Base Register`,`Page table Length Register`로 페이지 테이블의 시작위치 + 페이지 테이블의 크기 를 보관하는 용도로 사용이 된다.

페이지 테이블이 메모리에 있기 때문에 생기는 문제가 있는데

**메모리에 한 번 접근하기 위해서는 메모리를 총 2번 접근해야 한다는 것이다.**

주소 변환을 위해 1번 + 실제 주소 접근을 위해 1번

메모리 접근 속도가 느려졌다..

그래서 이 주소 변환을 전담하는 **조금 빠른 캐시**를 두고 있는데
그것을 `Translate look aside Buffer(TLB)` 라고 한다.

캐시라는건 모든 정보를 다 담지는 못하고, 자주 사용되는 것들만 담게된다.

Page table의 일부를 TLB에다가 담고 있어서 더 빠르게 주소변환을 할 수 있는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/7767f911-cf86-4779-812c-dd10de933773/image.png)

TLB 캐시가 없는 경우, page table에 접근하게 되고 있으면 바로 실제 주소로 변환하여 접근할 수 있게 된다.

TLB는 당연히 메모리보다 접근속도가 더 빠르다.

여기서 자료구조를 보면서 생각해야 할 점은, 페이지 테이블은 일종의 배열이라는 것이다.

0~100만번까지 엔트리가 다 만들어져있다.

90만이라는 페이지 번호를 보면, 위에서부터 순차적으로 보는것이 아니라 90만번째 entry로 바로 갈 수 있다.

근데 TLB는 전부를 담고있는게 아니라, 일부만 담고있으므로 인덱스로는 접근하기가 어렵다.

TLB는 Page Number와 Frame Number를 쌍으로 가지고 있고 그렇기에 순차적으로 살펴봐야한다.

그렇게 되면 overhead가 굉장히 클 것인데, 그림을 보면 TLB는 **Parallel**하게 병렬적으로 찾고있음을 알 수 있다.

저런게 가능하려면 그렇게 하기 위한 HW가 있어야 하고, 그런 HW를 `Associative Register`라고 부른다.

![](https://velog.velcdn.com/images/sujipark2009/post/75baa307-00a0-4439-8b25-4a03e0c8b3d6/image.png)

Associative Register라 불리는 HW를 이용해서 Parallel하게 TLB를 탐색할 수 있는 것이다.

Page table이라는 건 각각의 프로세스마다 존재하는데, 프로세스가 여러개있으면 당연히 Page table도 여러 개 있을 것이다.

그래서 프로세스 A와 B가 있다면, 이 둘의 Page table 내용도 다를 것이고 TLB의 내용 또한 다를것이다.

그래서 Context Switching이 일어날 때 TLB또한 비워져야 한다.

![](https://velog.velcdn.com/images/sujipark2009/post/fa17ce31-7186-4433-9c11-d01cf789c088/image.png)

TLB를 통해 메모리 접근 시간이 얼마나 바뀌는지를 보면,

TLB를 통해 주소변환이 일어나는 비율을 a라고 하고, 메모리 접근시간을 e라고 하면 대충 위의 식이 나온다.

TLB의 Hit ratio가 1에 가까운 값을 가지기 때문에 메모리 접근시간을 크게 줄일 수 있는 효과가 있다고 한다..

#### Two-Level Page table

---

![](https://velog.velcdn.com/images/sujipark2009/post/41c20e36-1b92-4331-981f-0aeef3840611/image.png)

페이지 테이블을 사용하면 좋은점은, 프로그램을 동일 크기의 페이지로 잘라서 메모리의 빈 공간에 아무곳이나 올 수 있고 당장 필요한 페이지만 올릴 수 있어서

메모리를 효율적으로 사용할 수 있다는 것이다.

그런데 페이지 테이블은 프로세스마다 있다고 했고 그럼 프로세스마다 테이블 Entry수가 100만개가 있다는 것이다.

이 Entry 하나하나가 Frame번호를 가지고 있고, 또 valid-invalid bit도 가지고 있어서 Entry하나의 크기가 4B정도 된다.

이런개 100만개가 있으니, 대충 페이지 테이블 하나 당 4MB의 메모리 공간이 필요하게 된다.

당장 프로세스가 100개만 있어도 벌써 400MB를 잡아먹는다는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/85fe62b4-dafa-49d3-ab94-81be75a1f3b1/image.png)

그래서 2단계 이상의 페이지 테이블을 사용하게 되는데, 아까는 주소를 주면 그것을 확인하는 페이지 테이블이 1개였지만 이제는 2단계로 되어있는 것이다.

2단계 페이지 테이블을 쓰면, 주소변환을 위해 메모리를 2번 접근하고 실제 메모리레 접근하기 위해 1번까지 총 3번의 메모리 접근을 하게된다.

**시간상으로는 손해이다.**

**하지만 공간상으로는 이득**이기에, 이걸 얻기위해 쓰는것이다.

그런데 오히려 공간 낭비가 아닐까? 어차피 1M개의 엔트리를 표현하기 위한게 있고, 바깥 테이블까지 만들면 손해같은데

시간 손해 + 공간 손해 => x손해가 아닌가?

왜 손해가 아니냐면..

32bit 기준 4GB를 4KB의 페이지로 자르면 총 1M개의 페이지가 나온다고 했는데, 그 중 실제 사용되는건 얼마 되지 않는다.

![](https://velog.velcdn.com/images/sujipark2009/post/d4275cb6-84ed-497f-9a24-c4decdc296eb/image.png)

왼쪽의 페이지에서 실제 사용 되는건 몇 개 안되더라도 그것들을 위해 페이지 테이블에는 Entry가 존재해야한다. 그리고 invalid 표시 또한 있어야한다.

왜냐하면 없애버리면 나중에 바로 접근을 못하니까.

2단계 페이지 테이블을 쓰게되면

![](https://velog.velcdn.com/images/sujipark2009/post/297cc92c-3880-46aa-a759-f4e4d784d658/image.png)

바깥 테이블을 따라가면 안쪽 테이블이 있고, 안쪽을 따라가면 실제 메모리 주소가 나오는 구조이다.

그런데 사용이 안되는 영역에 대해서는 안쪽 테이블이 만들어지지가 않고, 바깥쪽 테이블에 **NULL**이 되어있다.

그럼 안쪽 테이블 하나의 크기는 얼마일까?

4KB이다.

그러니까 이 테이블 하나하나가 사실은 Page화 되어서 메모리의 Frame에 들어가있는 형식인 것이다.

그럼 하나가 4KB라면, 엔트리의 개수는 몇 개 일까?

아까 엔트리의 크기가 4B라고 했으므로, 2^12 / 2^2 = 2^10(1K) 이다.

![](https://velog.velcdn.com/images/sujipark2009/post/1fe4fba9-2611-44d6-834c-9bbf76b391e5/image.png)

그래서 2단계 페이지 테이블에서 주소변환이 되는 과정을 보면,

32bit의 주소가 총 3부분으로 나눠지게 된다.

맨 뒤의 페이지 offset은 페이지 내부에서 얼마나 떨어져있냐를 나타내고 페이지 하나의 크기가 4KB이기때문에 12bit가 된다.

P1의 바깥 테이블, P2는 안쪽 테이블을 나타내는데

내부 테이블의 엔트리가 1K개가 있으므로, 10bit를 가져가고 나머지 10bit를 바깥 테이블이 가져가는 구조이다.

다시 정리하면

안쪽 페이지 테이블은, 테이블 자체가 "페이지화" 되어서 페이지 어딘가에 들어있게 된다.

2단계 페이지 테이블에서 기억해야 할 점은, 안쪽 페이지 테이블의 크기가 페이지 크기랑똑같다는 것이다.(4KB)

지금까지를 정리하면,

물리적인 메모리 관리에서 가장 중요한것은 **주소변환**이다.

여기서 OS가 하는 역할은 아무것도 없다. HW가 주소변환을 해준다.

각 프로세스마다 논리적 메모리가 있고, 그게 물리적 메모리에 올라가서 실행이 되는 것이다.

그 주소변환 과정은 전적으로 HW의 역할이다.

메모리 접근을 위해 OS에게 CPU가 넘어간다? 는 것은 말이 안되는 것이다.
OS도 일종의 SW이다.

단, I/O 접근은 반드시 OS를 거치도록 되어 있다.

물리적 메모리 관리방법이 연속 / 불연속 할당이 있고

연속은 프로세스가 통째로 물리적인 메모리에 올라가는 것이었고, 불연속은 쪼개져서 올라가게 되며 필요없는 경우 backing store에 내려가있기도 하는 그런 방식이었다.

페이징 방식은, CPU가 논리적 주소를 주면 그것의 앞부분을 보고 페이지 번호를 찾아서 주소 변환이 이루어졌었다.

그 번호를 찾는건 페이지 테이블에서 했었고, 다단계 페이징까지 살펴봤었다.

![](https://velog.velcdn.com/images/sujipark2009/post/e4afaaa1-8c17-4261-9148-4d9db6b55f3d/image.png)

그리고 페이지 테이블에 각 페이지별로 물리적으로 어느 프레임에 올라가있냐는 것 이외에 valid-invalid bit를 통해 물리적인 메모리에 올라가있는지를 알 수 있었다.

그리고 protection bit라는 것도 있는데, 이것은 말 그대로 보안 / 보호를 위한 목적이다.

page table은 프로세스마다 각각 존재한다. 주소 변환을 하더라도 자기 자신의 주소공간에만 접근이 가능해야한다.

이 보호가 필요한 이유는, 그 페이지가 read만 가능한지 아니면 write만 가능한지 이런것을 나타내기 위함이다.

code,data,stack 영역 중, code 영역은 함수와 코드 같은것을 가지고 있기 때문에 실행 도중에 변경되면 안된다. 그래서 read-only 설정이 필요하다.

#### Inverted Page table

---

![](https://velog.velcdn.com/images/sujipark2009/post/4de68ded-8b8e-4090-925e-6cafcddfe1dc/image.png)

이런게 있는데,,

![](https://velog.velcdn.com/images/sujipark2009/post/adde6f84-34a6-4615-b589-a27b718dfb37/image.png)

원래 페이지 테이블이라는 것은, 논리주소로부터 물리주소를 얻는 과정이다.

그래서 CPU가 논리주소를 주면, 그 페이지 번호에 해당하는 Entry에 가서 물리적 메모리 위치인 프레임 번호를 얻었는데 그러다 보니 페이지 테이블을 위한 주소공간 낭비가 너무 심하다는 것이다.

그것을 막기위한 방식으로 Inverted Page table은, 물리적인 frame 하나하나 당 페이지 테이블이 존재하게 된다.

물리적인 주소를 가지고 논리적인 주소를 얻어내기 쉬운 구조로 되어있다.

frame1은 p1의 첫 페이지, frame2는 p2의 두번째 페이지..

이런 것을 알 수 있다는 말이다.

장점은, 물리적인 메모리는 하나니까 페이지 테이블이 하나만 있으면 된다는 장점이 있다.

하지만 주소변환 자체에는 별 도움이 안된다.

주소변환은 논리적 주소를 물리적 주소로 바꾸는 것이 목적인데, 물리적 주소를 주면 논리적 주소 어디에있다는 것을 얻는것이므로 사실 쓸모가 없다.

#### Shared Page

---

![](https://velog.velcdn.com/images/sujipark2009/post/cef0344d-821e-45e5-b0b9-54bc8af14b09/image.png)

![](https://velog.velcdn.com/images/sujipark2009/post/b8d9a510-124d-4447-96a0-c6a19a43495a/image.png)

P1,P2,P3의 주소공간과 물리적 메모리가 있다.

프로세스가 3개이지만 셋 다 동일한 프로그램이라고 해보자.

그럼 이 프로세스들의 code부분은 다 같을 것이다.

data부분은 다를 것이다.

프로세스가 다르기 때문에, 동일한 코드를 가져다가 메모리에 올리면 똑같은 것이 올라가기 때문에 메모리 낭비가 될 것이다.

그걸 막기위해 `Shared code`를 담는 Page는 여러 Copy를 올리지 말고 1개만 올려서 공유를 하자는 것읻.

예전에 IPC에서 Shared Memory 방식을 이야기 했었는데, 공유 메모리라는 건 서로 다른 프로세스가 서로간의 Communication을 목적으로 주소공간의 일부를 공유하는 방법이었다.

그래서 공유된 주소공간은 물리적 메모리의 같은 공간을 가리키고 있고, 그 공간은 읽기와 쓰기가 다 가능했었다.

그런데 여기서 말하는 `Shared Code`는 `read-only`로 되어있는 코드를 하나의 Copy만 올리자는 것이다.

Shared Code는 2가지 제약조건이 있는데,

1. Read-Only로 되어 있어야 한다.
2. 모든 프로세스의 동일한 Logical Address Space에 있어야 한다.

1번은 됐고, 2번을 보면 동일한 **논리적 주소**에 있어야한다?

한마디로 각 프로세스의 페이지 번호가 같아야 한다는 의미이다.

P1에 1,2,3번 페이지에 들어가있는데 P2에서는 3,4,5에 가있으면 안된다는 의미이다.

이유를 보면..

![](https://velog.velcdn.com/images/sujipark2009/post/36b445ab-d1cd-45c0-9c25-b1b10f894822/image.png)

기계어가 물리적 메모리의 어디에 올라가느냐 하는것은 바뀔수가 있지만,

기계어 내부의 주소들은 논리적인 주소가 그대로 남아있어서 바뀌지 않는다.

그래서 Shared Page는 논리적인 주소가 같아야 한다는 것.

#### Segmentation

---

![](https://velog.velcdn.com/images/sujipark2009/post/c4eac5bb-b63b-4f3c-9f5e-9e13ac7e4af5/image.png)

페이지가 동일 크기로 잘라서 올리는 방식이었다면, Segmentation은 의미 단위로 잘라서 올리는 방식이다.

code segement / stack segment / data segment 이런 식으로.

그런데, 의미적으로 자르면 그게 균일하다는 보장이 없다.

그래서 미리 메모리를 프레임처럼 잘라서 관리할 수 없다.

그리고 Segmentation에도 세그먼트 테이블이 존재한다.

code라는 것도 여러 개의 함수들도 나눠진다. main(), function(),...

![](https://velog.velcdn.com/images/sujipark2009/post/d47c26eb-7151-4fc3-9f4c-603097c4a669/image.png)

페이지와 비슷하게 (번호,Offset)으로 되어있다.

![](https://velog.velcdn.com/images/sujipark2009/post/d670f914-3852-450d-aea3-56ad388974cf/image.png)

S번째 세그먼트가 물리적인 메모리 어디에 위치하는지를 나타내고 base + limit register를 사용해서 나타낸다.

페이징 기법에서는 limit이라는게 필요가 없었다. 왜냐하면 어차피 다 길이가 같았기 때문이다.

그런데, Segmentation은 길이가 다르기 때문에 길이 범위가 필요하다.

만약 offset이 limit보다 큰 곳을 접근하려고 한다면 trap을 걸게된다.

주소 변환을 위해 register 2개가 제공이 되는데, 페이징 기법에서는 페이지 테이블로 변환을 하게 되면서 페이지 테이블의 시작점(PTBR) + 페이지 테이블의 길이(PTLR)를 담는 용도로 사용했었다.

세그멘테이션에서도 비슷한데, 세그먼트 테이블의 시작위치를 담는 STBR

세그먼트 테이블의 길이를 담는 STLR(엔트리 수가 N개이면 길이가 N)이 있다.

페이징 기법과 또 다른 점은, 페이지 테이블에는 프레임 번호가 붙어있었는데 세그먼트 테이블에는 바이트단위의 주소가 들어가있게 된다.

또 세그먼트 길이가 다 제각각이므로, `외부 단편화` 문제가 발생할 수 있다.

![](https://velog.velcdn.com/images/sujipark2009/post/9693b155-f327-47f2-bf78-1383ebf95d4d/image.png)

![](https://velog.velcdn.com/images/sujipark2009/post/bb317a80-512b-4cb8-9e06-a0ed2f62f114/image.png)

또 세그먼트를 각각의 조각 중 어느곳에 집어넣어야 하는지의 문제가 생긴다(Best,First,Worst)

이 문제는 이미 연속할당에서 살펴봤던 문제이다.

대신 페이징과 비교한 장점은, 세그멘테이션이라는것이 의미단위로 쪼개서 메모리에 올리는 것이므로 의미단위로 하는 일들(Protection,Sharing)에 대해서는 유리하다.

어떤것은 Code segment 어떤것은 Stack segment인데

스택이라는 것은 함수를 호출 / 리턴을 하기 위해 쓰는 곳이니 read / write가 가능해야하고 코드 부분은 기계어를 담은 코드 부분이니 변경하면 안되는 곳이다.

이런곳은 read-only로 세팅해야한다.

또 실행권한을 주는 그런 것들을 표현하는데 효과적이다.

페이지 테이블에서도 물론 표기가 가능했으나, 같은 크기로 메모리를 자르다보면 페이지의 일부는 코드 / 일부는 스택인 경우가 있을 수도 있다.

그렇게 잘라지면 앞부분은 읽기만, 뒷부분을 읽기 / 쓰기 둘 다 가능하게 되어 이런것을 처리하기가 까다롭다.

결론적으로, 의미단위로 관리해야하는 공유나 보안에 유리하나 Allocation에서 생기는 외부 파편화 문제는 존재한다고 할 수 있겠다.

![](https://velog.velcdn.com/images/sujipark2009/post/1aa02cdb-c989-4fe8-b716-6dc7f7aef1a9/image.png)

공유 세그먼트도 페이지와 똑같이 적용이 된다.

같은 논리적 주소를 가져야 한다.

근데 현실적인 측면에서보면 다른 이슈가 있다.

세그멘테이션은 세그먼트 개수가 많지가 않다. code / data / stack .. 그리고 code 여러개로 나눠봤자...

근데 페이징에서는 엔트리가 1M개였다. 세그먼트 테이블은 엔트리 수가 몇 개 안되고 페이징은 너무 많고..

현실적인 구현측면에서 보자면 메모리낭비는 페이징 기법이 더 심하다. 사실 그것을 막기위해 다단계 페이징을 사용했었다.

세그먼트가 얼마 안되면 세그먼트 자체를 메모리에 올리지 말고 레지스터나 캐시에 다 올릴수도 있을 것이다.

근데 안타깝게도, Pure Segmentation기법을 시스템에 구현해서 사용하는 경우는 거의 없다.

가변 공간의 문제도 있고, 실제 시스템에서는 페이징 기법을 근간으로 해서 사용하고 있다.
