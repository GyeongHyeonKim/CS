### 프로세스 주소공간에 대해 설명해주세요

---

- 운영체제가 각 프로세스에 독립적으로 할당한 메모리 주소의 논리적 영역
- 프로세스가 사용할 수 있는 메모리 영역

![](https://velog.velcdn.com/images/sujipark2009/post/cd914ed2-ca4e-4f88-bf09-7ce4407eb3c1/image.png)

**code**

- 코드 자체를 구성하는 메모리 영역(프로그램 명령)

- 읽기전용

같은 프로그램의 프로세스 간 공유 가능
수정에 대한 보안성

- 프로그램의 기계어 코드를 저장

**Data**

- 전역변수, 정적변수

- Data 영역 : 초기화된 데이터

- Bss 영역 : 초기화되지 않은 데이터

**Heap**

- Runtime에 크기가 동적으로 변하는 영역
- 동적할당

new(),malloc() 등

- 방향 : 하위 주소에서 위로 확장

**Stack**

- 함수 호출과 관련

지역변수,매개변수,리턴 주소(임시 메모리 영역)

- 함수 호출 시 스택 프레임 생성

종료되면 스택 프레임 해제

- 방향 : 주소 공간 상위 영역에서 아래로 확장

#### Call Stack에 대해 설명해주세요

---

- 프로그램이 실행되는 동안 함수 호출과 관련된 정보를 저장하는 자료구조

- LIFO 구조 / Call Stack Frame

#### 다음과 같이 공간을 분할하는 이유가 있을까요?

---

- 메모리 보호

다른 프로세스에서 메모리 접근 불가

- 프로세스 격리

독립적인 프로세스 실행 / 서로 영향 배제

- 효율적 메모리 관리

운영체제가 각 영역을 다르게 관리, 동적 할당 및 해제

**code** : 보안(읽기전용으로, 수정에 대한 보안성)

**data** : 전역 변수와 정적 변수의 활용 및 공유

**stack** : 함수 호출 및 반환 과정에서 메모리를 효율적으로 관리

프로그램의 구조와 모듈화를 개선

#### 초기화되지 않은 변수들은 어디에 저장될까요?

---

- 전역변수와 정적변수

data 영역에 저장 -> 특히 BSS영역

- 로컬 변수

함수 호출 시, Stack Frame 생성 -> Stack 영역에 변수 저장
이전에 스택에 있던 어떤 값이든 그대로 남아 있을 수 있음 -> 쓰레기 값

- 동적 할당 변수

Heap에 동적할당 -> 변수 저장

#### Heap과 Stack의 장단점을 알려주세요

---

**스택(Stack)**

메모리 할당을 자동으로 처리 - 메모리 누수를 걱정할 필요가 없음

메모리 할당과 해제가 매우 빠름

**단점**

크기가 제한.

스택 오버플로우가 발생하면 프로그램이 중단

**힙(Heap)**

동적 메모리 할당을 제공 -> 필요한 만큼의 메모리를 할당하고 해제

**단점**

- 메모리 관리는 프로그래머에게 맡겨져 있음

사용 후에 반드시 반환하지 않으면 메모리 누수가 바ㅏㄹ생
메모리 단편화가 발생할 수 있는 공간

#### 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요?

---

- 시스템에서 할당된 메모리 양과 프로그램의 요구에 따라 다름

일반적으로, 스택은 고정된 크기(운영체제나 프로그램 설정에 따라 결정)

Window는 기본 1MB, 변경 가능

힙은 사용 가능한 메모리 양에 따라 동적으로 크기가 조정.
운영체제 유후 메모리 양에 따라 아주 커질 수 있음

- Unix 계열 운영체제에서 기본 스택 크기는 대략 8MB(커스터마이징 가능)

#### Stack의 정적 할당과 Heap의 동적 할당에 대해 설명해주세요

---

**정적 할당**

- 함수에 사용되는 지역 변수의 크기는 컴파일 타임에 정해짐

- 스택에 할당된 메모리는 함수가 실행되는 동안 크기가 변하지 않음 - 프레임 크기를 기반으로 포인터를 이동하기 때문

```
void funcA() {
    int x = 10;       // 4 bytes
    char y = 'a';     // 1 byte (패딩으로 4 bytes 정렬)
    double z = 3.14;  // 8 bytes
}

```

이렇게 funcA가 호출되면, **스택 프레임**이 생성된다.

- 이 스택 프레임은, x,y,z의 메모리를 저장하기위해 16B를 차지한다.
- 컴파일러는 이미 `funcA` 에 필요한 메모리 크기를 알고 있으며, 함수가 실행될 때 고정된 크기의 스택 프레임을 생성한다.

- 함수 실행중에도, 스택프레임의 크기는 변하지 않는다. x나 y의 값을 변경할수는 있지만, 값의 변경은 이미 할당된 메모리 공간 내에서 이루어지므로 **스택 프레임 크기는 그대로 유지** 된다.

함수 실행이 끝나면, 스택프레임이 제거되고 스택 포인터가 이전 위치로 돌아간다

**동적 할당**

런타임에 메모리 크기가 변함

#### Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?

---

**Stack**

- 스택에서 메모리를 할당하고 해제하는 것은 단순히 스택 포인터를 이동시키는 것을 의미하므로 매우 빠름

- CPU Cache 친화적

메모리 상 연속적인 위치에 할당되기 때문

**Heap**

- 힙에서 메모리를 할당하고 해제하는 것은, 복잡한 데이터 구조를 관리하는 데 시간이 걸릴 수 있음

메모리 블럭 위치가 불규칙적 / 힙 메모리는 포인터로 접근

포인터로 접근하기에 이 과정에서 간접 참조가 발생하여, 스택보다 더 많은 단계가 필요할 수 있다

#### 스레드 주소공간에 대해 설명해주세요

---

- 스레드가 생성되고 실행되는 동안 접근가능한 메모리 영역

- 프로세스 주소공간 내 위치

#### 스레드의 주소공간은 어떻게 구성되어 있을까요?

---

**공유하는 부분**

code,data,heap,OS File

특히 힙 영역은, 동시성 문제를 방지할 필요가 있다

**고유**

스택

스레드의 로컬 변수,함수 매개변수, 반환 주소등을 저장

이것은 스레드마다 독립적으로 다른 스레드의 영향을 받지 않는다.

#### Stack을 스레드마다 독립적으로 할당하는 이유는 무엇인가요?

---

- 스레드마다 독립적인 실행 흐름을 위해서이다.

스택은 함수 호출 시 전달되는 인자, 복귀 주소값 및 함수 내에서 선언하는 변수를 저장하는데 사용되는 메모리 공간이다.

스택 메모리 공간이 독립적이라는 것은 독립적인 함수 호출이 가능함을 의미한다.

스레드는 CPU에서의 수행 단위를 뜻하는데, CPU의 수행단위에는
현재 어디까지 명령어를 실행했는지(PC), Register등의 정보가 포함된다.

이것은 스레드마다 다를 수 있기 때문에 독립적으로 할당해야 한다.

#### IPC가 무엇이고 어떤 종류가 있는지 설명해주세요

---

Interprocess Communication

프로세스는 독립적이지만, 프로세스 간의 통신이 필요한 상황이 있다

그때, 프로세스 간의 통신을 가능하도록 OS의 커널이 제공하는 기능이다.

**익명 PIPE**

한 프로세스의 출력 스트림을 다른 프로세스의 입력 스트림에 연결하는 방식으로 통신하는 메커니즘

- 반이중 통신

한 쪽은 읽기만 가능 / 한 쪽은 쓰기만 가능

전이중 통신(양쪽 통신)을 위해서는, 2개의 파이프가 필요하다

![](https://velog.velcdn.com/images/sujipark2009/post/d9e7383c-3307-4664-94c1-306878ac8d26/image.png)

![](https://velog.velcdn.com/images/sujipark2009/post/cff52558-2304-46ee-a796-b960481c058f/image.png)

- 통신할 프로세스를 명확히 아는 경우에 사용한다

부모 / 자식 프로세스 간 통신

**외부 프로세스에서 이 파이프를 사용할 수 없어서** 익명파이프라고 한다.

이름이 없기 때문에 외부 프로세스에서는 이 파이프를 부를 수 없지만, 부모 프로세스가 자식 프로세스를 생성하는 경우에는, 파일 지정 번호를 상속받아 익명파이프로 통신을 할 수 있다.

- pipe함수로 생성

**장점**

- 간단하고, 단순한 데이터 흐름을 가질 때 효율적이다.

- 전이중 통신을 위해 2개를 만들어야 하면 복잡해짐

**Named PIPE(FIFO)**

- 통신을 위해 이름이 있는 파일을 사용

- 전혀 모르는 상태의 프로세스들 사이 통신에 사용

익명 파이프의 확장된 형태
부모 프로세스와 무관한 다른 프로세스와도 통신이 가능한 것

**단점**

읽기/쓰기 동시에 불가능
익명 파이프와 마찬가지로 2개를 만들어야 전이중 통신 가능

익명 파이프는 부모 - 자식간 통신만 가능하기 때문에, **외부 프로세스와 통신**을 하기 위해서 파이프에 이름을 붙여주는 것

- mkfifo or mknod 함수로 생성

**Message Queue**

![](https://velog.velcdn.com/images/sujipark2009/post/fb106b6f-8d7d-4894-af36-23cd37657a7c/image.png)

- 입출력 방식은 Named 파이프와 동일하다

- 파이프와 같은 데이터 흐름이 아니라, 메모리 공간

- 사용할 데이터에 번호를 붙이면서 여러 프로세스가 동시에 데이터를 쉽게 다룰 수 있다.

- 메세지는 큐에 순서대로 저장되어 수신 프로세스가 준비되면 메시지를 꺼내 사용 가능

- 비동기적, 동기화를 자동으로 처리

**공유 메모리**

![](https://velog.velcdn.com/images/sujipark2009/post/43bd51b6-fe16-4676-89ee-53b1b3cd99e0/image.png)

- 파이프,메시지 큐가 통신을 이용한 설비라면, 공유 메모리는 데이터 자체를 공유하도록 지원하는 설비

- 프로세스 간 메모리 영역을 공유해서 사용하도록 허용(스레드 처럼)

- 프로세스가 공유 메모리 할당을 커널에 요청

커널은 해당 프로세스에 메모리 공간을 할당
모든 프로세스가 해당 메모리 영역에 접근 가능

**장점**

중개자(OS) 없이 곧바로 메모리에 접근할 수 있기에 IPC중에 가장 빠르게 작동

**단점**

메시지 전달 방식이 아니기에 읽을 시점을 알 수 없음 - 동기화 기술 필요

Lock 메커니즘 필요

**메모리 맵**

- 공유 메모리처럼 메모리를 공유

- 열린 파일을 메모리에 mapping 시켜서 공유하는 방식

공유 매개채는 파일 + 메모리

- 파일로 대용량 데이터를 공유해야 할 때 사용

**소켓**

- 네트워크 소켓 통신을 통해 데이터 공유
- 클라이언트와 서버가 소켓을 통해 통신하는 구조
- 원격에서 프로세스 간 데이터를 공유할 때 사용
- TCP/IP,UDP 등의 프로토콜을 사용하여 통신

#### Shared Memory를 사용할 때 유의해야 할 점에 대해 설명해주세요

---

- 동시성 제어와 동기화를 위한 별도의 메커니즘이 필요하다

- 뮤텍스 / 세마포어

#### 메시지 큐는 단방향이라고 할 수 있나요?

---

- 메시지 큐는 일반적으로 단방향 통신을 지원

- 서로 다른 메시지 큐를 사용하면 양방향 통신이 가능

단, 2개의 메시지 큐가 필요

### 프로세스와 스레드

#### 프로그램과 프로세스, 스레드에 대해 설명해주세요

---

**프로그램**

- 어떤 작업을 위해 실행할 수 있는 파일
- 컴퓨터가 이해할 수 있는 명령어의 나열

**프로세스**

- 메모리에 올라와 실행되고 있는 프로그램의 인스턴스(독립적인 개체)

- 운영체제로부터 시스템 자원을 할당받는 작업의 단위

시스템 자원이라 하면 CPU 시간 / Code,Data,Stack,Heap의 구조로 된 메모리 영역이 있다.

**특징**

- 기본적으로 프로세스당 최소 1개의 스레드

- 각 프로세스는 별도의 주소 공간ㅇ에서 실행

- 다른 프로세스와의 교류

한 프로세스는 다른 프로세스의 변수나 자료구조에 직접 접근할수는 없다.

이를 위해서는 IPC를 사용해야 한다.

**스레드**

- 프로세스 내에서 실행되는 여러 흐름의 단위

![](https://velog.velcdn.com/images/sujipark2009/post/ffec1feb-c5f0-42ba-9d68-2c1eec8424ae/image.png)

- stack만 따로 할당받고 ,Code,Data,Heap 영역은 스레드 간에 공유

- PC,register,스택은 스레드마다 관리

- 힙 메모리는 스레드 간 공유

#### 리눅스에서 프로세스와 스레드는 각각 어떻게 생성될까요?

---

**프로세스**

fork() 시스템 호출을 사용하여 생성

- fork() 시스템 콜을 사용하면, 기존 프로세스를 복제하여 새로운 프로세스를 생성

- 자식이라고 하는 새 프로세스는 부모라고 하는 호출 프로세스의 정확한 복사본

- 자식은 새 프로세스 ID(PID)를 가진다
- parent Descriptor의 복사본을 가진다

**스레드**

- POSIX 스레드 라이브러리의 일부인 pthread_create() 함수를 사용하여 생성

- 기존 프로세스 내에서 새로운 실행 스레드를 생성한다

호출 프로세스를 복제하지 않는다.

#### Child Process 가 무엇인가요?

---

- 부모 프로세스로부터 생성된 프로세스

- 자식 프로세스는 부모 프로세스로부터 code,data,자원 등을 상속받아 실행

- 자식 프로세스는 부모 프로세스와 병렬적으로 실행되어 동시성을 증가

#### 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?

---

**좀비 프로세스**

- 자식 프로세스는 작업 완료 후 종료되었지만, 부모 프로세스가 자식의 종료 상태를 수집하지 않아 프로세스 테이블에 남아있는 프로세스

**발생 이유**

- 자식 프로세스가 exit()을 호출해 종료되면 종료 상태가 부모에게 전달

부모는 wait(),waitpid()를 호출하여 자식 종료상태를 확인하고 제거해야 한다.

이것을 호출하지 않은 상태이다.

**처리**

부모가 wait()을 호출하면 해결

부모가 종료되면 고아 프로세스 처리로 넘어간다

**고아 프로세스**

- 부모 프로세스가 자식 프로세스를 두고 먼저 종료되면, 자식은 고아 프로세스가 됨

**발생 이유**

부모의 비정상 종료
부모가 의도적으로 자식을 백그라운드에서 실행한 상태로 먼저 종료

**처리**

부모가 종료된 경우에는 init 프로세스에게로 소유권을 양도

init 프로세스는 고아 프로세스를 자동으로 수집해 프로세스 테이블에서 제거함

#### 사용자 수준 스레드와 커널 수준 스레드의 차이점은 무엇인가요?

---

**사용자 수준 스레드(User-Level Thread)**

- 이들 스레드는 커널이 알지 못하고, 사용자 프로그램이 관리한다

스레드의 생성,스케쥴링,동기화 등이 사용자 영역에서 처리

- 컨텍스트 전환(Context Switch)은 커널의 개입이 필요 없음

빠르다

- 한 스레드가 시스템 호출을 통해 block되거나 입출력을 기다리는 경우

해당 프로세스 내의 모든 스레드가 block될 수 있음

커널이 사용자 수준 스레드의 존재를 알지 못하기 때문이다.

```
void thread1() {
    // 파일 읽기 (블로킹 호출)
    read(fileDescriptor, buffer, size);
    printf("Thread 1 completed\n");
}

void thread2() {
    // 계산 작업 (비블로킹)
    for (int i = 0; i < 1000000; i++) {
        // 연산 수행
    }
    printf("Thread 2 completed\n");
}

int main() {
    // 사용자 수준 스레드 라이브러리로 두 스레드 생성
    create_user_thread(thread1);
    create_user_thread(thread2);
    return 0;
}

```

1. 스레드1이 파일 I/O 작업을 요청한다

- 이 작업은 블로킹 시스템 호출(read)로 인해 완료될 때까지 멈춘다.

2. 사용자 수준 스레드 라이브러리는 **커널의 개입 없이** 사용자 공간에서 스레드를 관리한다

- 하지만 커널은 **스레드1이 포함된 프로세스**를 통째로 block된 상태로 인식한다

3. 이로 인해 같은 프로세스의 스레드2도 실행되지 못한다.

- 스레드2는 파일 I/O와 무관한 작업을 하고 있음에도 실행 기회를 읽게된다.

![](https://velog.velcdn.com/images/sujipark2009/post/5d14dfd4-77a3-4ee8-a0f2-f8d2ab4df14c/image.png)

**커널 수준 스레드(Kernel-Level Thread)**

- OS가 직접 관리

- 스레드의 생성,스케쥴링,동기화 등 모든 작업이 커널에서 이루어짐

- 커널이 각 스레드를 개별적으로 인식하여 한 스레드가 block되어도 다른 스레드는 계속 실행

- 컨텍스트 전환은 커널의 개입이 필요하므로 상대적으로 오버헤드가 큼

```
#include <pthread.h>
#include <stdio.h>
#include <unistd.h> // for sleep()

void* thread1_func(void* arg) {
    printf("Thread 1: Starting file I/O operation (simulated).\n");
    // 파일 읽기 또는 네트워크 I/O 작업을 시뮬레이션
    sleep(5); // 5초 동안 블로킹
    printf("Thread 1: File I/O operation completed.\n");
    return NULL;
}

void* thread2_func(void* arg) {
    printf("Thread 2: Starting computation.\n");
    for (int i = 0; i < 5; i++) {
        printf("Thread 2: Computation step %d.\n", i + 1);
        sleep(1); // 1초 대기
    }
    printf("Thread 2: Computation completed.\n");
    return NULL;
}

int main() {
    pthread_t thread1, thread2;

    // 두 개의 커널 수준 스레드를 생성
    pthread_create(&thread1, NULL, thread1_func, NULL);
    pthread_create(&thread2, NULL, thread2_func, NULL);

    // 메인 스레드가 두 스레드가 완료되기를 기다림
    pthread_join(thread1, NULL);
    pthread_join(thread2, NULL);

    printf("Main thread: Both threads have finished.\n");
    return 0;
}

```

1. main 함수

- pthread_create를 호출하여 두 개의 **커널 수준 스레드**를 생성한다

2. 스레드 1

- sleep(5) 호출로 5초동안 block 상태에 들어간다
- 이 작업은 커널에서 처리되며, thread1만 블록된다.

3. 스레드 2

- 반복문을 실행하며 매 초마다 출력
- thread1이 블록된 동안에도 thread2는 계속 실행된다

4. pthread_join

- main 스레드는 두 스레드가 작업을 완료하기를 기다린다

**실행결과**

```
Thread 1: Starting file I/O operation (simulated).
Thread 2: Starting computation.
Thread 2: Computation step 1.
Thread 2: Computation step 2.
Thread 2: Computation step 3.
Thread 2: Computation step 4.
Thread 2: Computation step 5.
Thread 2: Computation completed.
Thread 1: File I/O operation completed.
Main thread: Both threads have finished.

```

#### 리눅스에서, 데몬 프로세스에 대해 설명해주세요

---

- 사용자가 직접 제어하지 않고, 백그라운드에서 눈에 띄지 않게 실행되는 유닉스 계열 운영체제의 프로그램 유형

- 일반적으로 백그라운드 프로세스로 시작

**특징**

- 리눅스 시스템이 부팅될 때 실행되는 첫 번째 프로세스인 init 시스템(PID 1)또는 시스템 사용자에 의해 생성

- 백그라운드 프로세스로 실행되고 터미널을 소유하지 않으므로, 사용자의 터미널을 제어하지 않음

- 일반 사용자 프로세스에서는 허용되지 않는 서비스(예: 1024 미만의 네트워크 포트에서 수신 대기, 시스템 파일 읽기/쓰기)를 제공하기 때문에 종종 시스템 수준 권한으로 실행

- 활성화되는 고유한 방법이 있음

어떤 이벤트가 발생하기를 반복적으로 기다린 다음 행동에 뛰어들어 지정된 작업을 수행

- 예시 :

들어오는 SSH 연결을 기다리는 SSHD(Secure Sheel Daemon)

로깅을 처리하는 syslogd

웹 서버에 대한 HTTP 요청을 처리하는 httpd와 같은 서비스

### PCB와 Context Switching

---

#### PCB가 무엇인가요?

---

Process Control Block(PCB) - 프로세스 제어 블럭

- 프로세스 메타데이터를 저장해 놓는 곳

프로세스의 상태와 실행에 필요한 정보를 저장하는 자료구조

**구성**

![](https://velog.velcdn.com/images/sujipark2009/post/5f005f67-9441-482b-a542-dba08c359366/image.png)

PID - 프로세스 식별자

프로세스 상태 - New/Ready/Running/Blocked ..

PC(Program Counter) - 이 프로세스가 다음에 실행할 명령어의 주소 / 컨텍스트 스위칭 시 다시 실행할 주소

Registers - 누산기 /인덱스 레지스터 /스택 레지스터 /범용 레지스터 /상태 코드

메모리 관리 정보 - 프로세스 주소 공간 정보, 페이지 테이블 등

입출력 상태 정보 - 프로세스가 열고 있는 파일이나 입출력 장치에 관련된 정보

CPU 스케쥴링 정보 - 프로세스 우선순위와 스케쥴 큐에 대한 포인터와 다른 스케쥴 매개변수

우선순위 값을 보고 스케쥴러가 프로세스 실행순서 결정

accouting 정보 - CPU 사용 시간/경과된 실시간/시간 제한

#### PCB는 어떻게 관리되나요?

---

커널에서 안전하게 존재

**형태**

LinkedList -

- PCB List Head에 PCB들이 생성될 때마다 붙음

- 주소값으로 연결이 이루어져 있는 연결리스트이기 때문에 삽입 삭제가 용이

#### PCB가 필요한 이유는 무엇일까요?

---

- 프로세스 상태 추적

OS에서 쉽게 관리
다음 실행할 프로세스 결정

- 컨텍스트 스위칭 지원

전환 전/후 프로세스 상태 저장

- 자원관리 및 보호

다른 프로세스에서 읽기 불가

#### PCB의 라이프사이클에 대해 설명해주세요

---

- 프로세스 생성(New)

OS가 프로세스 관리를 위해 새 PCB를 커널에 생성
준비 상태로 전환

- 준비 상태(Ready)

PCB가 Ready Queue에 들어가면 Ready 상태
스케쥴러가 PCB를 참조하여 다음 실행 프로세스 선택

- 실행 상태(Running)

스케쥴러에게 선택된 프로세스는 CPU를 할당받음

PCB의 PC와 레지스터 상태가 업데이트

할당된 CPU 시간 초과 또는 인터럽트 발생 -> PCB가 CPU 상태를 저장하고 Ready 상태로 전환

- 대기 상태(waiting / blocked)

프로세스가 I/O 작업 또는 특정 이벤트를 기다리는 경우

PCB 대기 큐에 추가

이벤트가 발생하면 PCB가 Ready 상태로 전환

- 종료 상태

프로세스의 실행이 끝난 상태
OS가 프로세스 자원 회수
PCB는 OS에 의해 삭제되거나 보류 - 좀비 상태로 PCB가 유지될 수 있음. 부모 프로세스 종료 후 PCB가 제거

#### 그렇다면, 스레드는 PCB를 갖고 있을까요?

---

![](https://velog.velcdn.com/images/sujipark2009/post/096af63d-fc15-4444-b48d-e19ee89f8d96/image.png)

스레드는 PCB를 직접 가지고 있지는 않음

#### 스레드 개별적인 정보는 어디에 저장될까요?

---

- TCB(Thread Control Block)라는 별도의 데이터 구조에 저장
- 각 스레드마다 TCB가 할당

- 프로세스의 PCB는 관련된 스레드의 TCB와 연결되어 있어 스레드 관리에 도움
- TCB는 유저 영역과 커널 모두에 있을 수 있지만, 요즘은 커널에 있는 추세

#### TCB에는 어떤 정보가 포함되어 있나요?

---

스레드 ID/PC/Registers/스택 포인터/스레드 상태/우선순위/스레드 로컬 저장소

### 컨텍스트 스위칭이란 무엇인가요?

#### 컨텍스트 스위칭이 필요한 이유는 무엇인가요?

---

- 여러 프로세스와 스레드들을 동시에 실행시키기 위해

- 높은 우선순위 작업 빠르게 처리

- 프로세스, 스레드 스케쥴링

공정한 자원 분배 / 다중 작업 지원

- 인터럽트 처리

인터럽트는 현재 실행 중인 작업을 중단하고 인터럽트 처리 루틴으로 전환

인터럽트 처리를 수행하고 다시 이전 작업으로 복귀를 위해 컨텍스트 스위칭

#### 컨텍스트 스위칭은 언제 일어날까요?

---

![](https://velog.velcdn.com/images/sujipark2009/post/3315b28f-ac02-46e9-b4d4-1e5e8d71acfe/image.png)

- 인터럽트가 발생
- 실행 중인 CPU 사용 허가시간을 모두 소모
- 입출력을 위해 대기해야 하는 경우

#### 시스템 콜이 일어나면 항상 컨텍스트 스위칭이 일어나나요?

---

![](https://velog.velcdn.com/images/sujipark2009/post/84cf93a3-6a00-4083-9a1b-7e00e7ff89d2/image.png)

아니다.

1번의 경우, 문맥 중 일부를 PCB에 저장하지만, 프로세스의 실행 모드만 전환되고 프로세스나 스레드가 변하지는 않는다

#### 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?

---

- 현재 작업의 상태 저장

CPU 레지스터의 값, 프로그램 카운터(Program Counter), 스택 포인터(Stack Pointer)

컨텍스트 스위칭이 시작되면, CPU는 현재 작업의 상태를 해당 작업의 컨텍스트라고 하는 곳에 저장

- 다음 작업의 상태 복원

다음으로 실행될 작업의 컨텍스트가 필요

CPU는 스케쥴러 또는 스레드 관리자로부터 다음 작업의 컨텍스트를 가져와서 CPU 레지스터,프로그램 카운터,스택 포인터 등의 값을 변경하여 다음 작업의 상태로 전환

- 메모리 관리 유지

현재 작업의 가상 메모리 매핑정보, 페이지 테이블과 같은 메모리 관련 데이터는 해당 작업의 컨텍스트에 저장

컨텍스트 스위칭 중에는 메모리 관리에 필요한 작업이 수행

- 캐시 플러싱과 로드

CPU의 캐시 메모리에는 현재 작업의 데이터나 명령어가 저장되어 있을 수 있음

컨텍스트 스위칭 시에는 현재 작업의 캐시를 플러시하고, 다음 작업의 데이터를 로드하는 작업이 필요

- 인터럽트 처리

인터럽트가 발생하면 CPU는 현재 작업을 중단하고 인터럽트 처리 루틴으로 전환

컨텍스트 스위칭은 현재 작업의 상태를 저장하고 ISR의 상태를 복원하는 작업을 포함

#### 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?

---

**프로세스 간 컨텍스트 스위칭**

- 실행중인 프로세스의 상태를 PCB에 저장

프로세스의 메모리 상태, 레지스터 상태, I/O 상태 정보, PC,CPU 레지스터, 스택 포인터, 스케쥴링 정보 등...

- 다음 실행할 프로세스 결정(스케쥴링)

- 해당 프로세스의 PCB를 불러와서 CPU 상태를 복원

- 새로운 프로세스가 시작

**스레드 간 컨텍스트 스위칭**

- TCB 정보만 저장하면 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/6a2d9f23-a8b1-46ff-be0e-fd9d7f524699/image.png)

실행 중인 스레드의 상태를 TCB에 저장
Ready Queue가 TCB를 가리킴
스레드의 상태 정보,PC,레지스터 상태,스택 포인터

- 프로세스 내의 다른 스레드를 실행하기 위해 해당 스레드의 TCB 정보를 불러옴

code,data,heap,open file등의 자원을 공유 -> 비용이 덜 듬

- 스레드의 컨텍스트를 복원하여 계속 실행한다

- Cache Miss Overhead가 적다

같은 프로세스의 thread간에 context Switching이 발생하면 cache를 비울 필요가 없다

#### 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널 스택에 어떠한 형식으로 저장되나요?

---

- PCB에 저장

프로세스 상태 정보

현재 실행중인 프로세스의 상태정보가 저장

프로세스의 우선순위,스케쥴링 정보,상태 플래그 등이 저장

- 커널스택에 저장

1. 프로그램 카운터(Program Counter) - 현재 실행 중인 프로세스의 다음 실행할 명령어 주소인 프로그램 카운터가 저장

다음에 해당 프로세스가 다시 실행될 때 정확한 위치에서 계속할 수 있도록 해준다

2. 레지스터 값

현재 실행중인 프로세스의 중요한 레지스터 값들
해당 프로세스가 중단되었던 시점의 레지스터 상태를 보존하여, 다시 실행될 때 이전 상태로 복원할 수 있도록 함

ex) 일반 목적 레지스터, 스택 포인터, 베이스 포인터, 프레임 포인터

3. 스택 데이터

현재 실행중인 프로세스의 스택에 있는 데이터 중 일부는 커널 스택에 복사

해당 프로세스의 스택 데이터를 보존하면서, 다른 프로세스를 실행하다가 다시 해당 프로세스를 실행할 때 이전 상태로 복원

**특징**

OS의 내부 구조에 따라 다를 수 있다..

### 작업처리

#### 멀티 프로세스와 멀티 스레드에 대해 설명해주세요

---

**멀티 프로세스**

하나의 프로그램에 대해 여러개의 프로세스로 구성하여 각 프로세스가 병렬적으로 작업을 수행하는 것

![](https://velog.velcdn.com/images/sujipark2009/post/74ebad58-d22b-45f7-a221-ae7ee0d081a1/image.png)

- 부모 프로세스가 여러 자식 프로세스를 생성

- PID와 PPID를 이용한 통신

프로세스마다 가진 ID : PID
부모 프로세스의 ID : PPID

ex) 웹 브라우저 상단 탭이나 새 창

**장점**

하나의 프로세스가 죽어도 다른 프로세스는 정상적으로 수행 - 안전성

각 프로세스가 독립적이기에 새로운 기능 및 모듈을 추가할 때 다른 프로세스에 영향을 주지 않음 - 확장성

**단점**

Context Switching으로 인한 성능 저하

멀티 스레드보다 많은 메모리 공간과 CPU시간을 차지

자원 공유 비효율 - IPC 사용

**멀티 스레드**

- 하나의 프로세스에 여러 스레드를 구성하여 작업을 처리하는 것

**장점**

- 자원의 효율성 증대

멀티 스레드를 이용하면, 프로세스를 생성하여 자원을 할당하는 시스템 콜이 줄어든다

프로세스 간의 Context Switching은 단순히 CPU 레지스터 교체 뿐만 아니라, RAM과 CPU 사이의 캐시 메모리에 대한 데이터까지 초기화되므로 오버헤드가 크다

정적 변수과 전역변수 자료 공유 가능 - 스레드 간 데이터를 주고받는 것이 간단하여 시스템 자원 소모가 줄어들게 된다

- 처리 비용 감소 및 응답 시간 단축

IPC보다 스레드 간의 통신 비용이 적음 - 스레드는 스택을 제외한 메모리를 공유하기 때문

프로세스간의 전환 속도보다 스레드 간의 전환 속도가 빠름 - 전환 시 스레드는 stack 영역만 처리하기 때문, 하지만 스레드가 너무 늘어난다면 context switching overhead가 극도로 커진다

**단점**

- 안전성 문제

하나의 스레드가 데이터 공간을 망가뜨리면, 모든 스레드가 작동 불능 상태

- 동기화 문제

#### 멀티 프로세스 대신에 멀티 스레드를 이용하는 이유는 무엇인가요?

---

멀티 스레드의 장점..(오버헤드 감소/자원 공유 용이)

멀티 프로세스의 장점..(안전성/확장성)

시스템마다 적합한 방식이 존재함..

#### 그렇다면 스레드 간에 자원 공유를 할 때 주의할 문제는 무엇인가요?

---

동기화 문제

#### 병렬 프로그래밍과 동시성 프로그래밍의 차이는 무엇인가요?

---

**병렬 프로그래밍**

Parallel Programming

여러 처리 유닛(코어)을 사용하여, 여러 작업을 **물리적으로** 동시에 실행하는 프로그래밍 기법

**여러 작업을 동시에 하여 처리 속도를 높이는데** 목표가 있다

ex) 대용량 데이터 처리 / 고성능 컴퓨팅 / 복잡한 계산 작업

**동시성 프로그래밍**

Concurrency Programming

작업들을 빠르게 전환하면서 실행하여 **동시에 실행되는 것처럼**보이게 하는 기법(논리적인 개념)

사용자에게 작업들이 마치 동시에 실행되는것처럼 보이는 illusion을 제공하는 것

**응답시간 줄이기**와 **자원을 효율적으로 사용**에 목적이 있다.

ex) 사용자 인터페이스 반응성 유지, 서버의 다중 클라이언트 요청 처리, 비동기 작업 실행

#### 동시성 프로그래밍과 비동기 프로그래밍의 관계는 무엇인가요?

---

비동기 프로그래밍은 동시성을 구현하는 주요 방법 중 하나.
단일 스레드에서 동시성을 실현하기 위해 사용.

ex) 네트워크 요청 응답을 기다리지 않고 다른 작업 처리

### 동기와 비동기 / 블로킹과 논블로킹

---

![](https://velog.velcdn.com/images/sujipark2009/post/78d631e4-5284-484e-95f7-9ee3f7f21822/image.png)

#### 동기,비동기에 대해 설명해주세요

---

**Blocking/Non-Blocking**

**작업이 중단되는지의 여부**

Blocking - 호출된 함수가 **제어권**을 뺏어 사용하고 작업이 끝나면 반환

작업이 특정 지점에서 중단

Non-Blocking - 호출된 함수가 **새 제어권**을 얻어서 동작하여 호출한 쪽의 제어권이 여전히 존재

작업이 중단되지 않음

**Sync/Async**

**작업의 실행 순서에 관한 것**

동기 - 작업 실행 순서가 미리 결정되고 보장

비동기 - 작업 실행 순서가 불확정적

**여러 조합**

**Blocking/Sync**

함수를 호출하면, 함수에서 작업이 완료된 후에만 리턴

작업 중단이 있지만, 순서가 보장

**Non blocking/Sync**

순차적으로 실행되고 중단되지 않음

호출자는 작업이 완료되었는지 확인하기 위해 주기적으로 함수를 호출하거나 상태를 확인 - Polling

**Blocking/Async**

함수를 호출하면, 함수에서 작업이 완료된 후에만 리턴
작업 완료에 대한 통지는 콜백 함수등을 통해 비동기적으로 받음

- 실제 사용이 매우 드문 케이스

**Non Blocking/Async**

함수를 호출하면, 함수는 즉시 리턴
작업 완료에 대한 통지는 콜백 함수 등을 통해 비동기적으로 받게 됨
호출자는 다른 작업을 계속 수행할 수 있으며, 작업 완료 통지를 통해 필요한 처리를 할 수 있음

#### 동기이면서 논블로킹이고, 비동기면서 블로킹인 경우에는 의미가 있다고 할 수 있나요?

---

- 흔하진 않지만 의미가 있음

**Non Blocking/Sync**

작업이 완료될 때까지 기다리는 동시에 다른 작업을 수행할 수 있음

멀티스레딩 환경에서 사용되며, 한 스레드가 작업을 기다리는 동안 다른 스레드가 계속 작업을 수행

스레드는 블로킹되지않지만, 각각의 작업은 여전히 동기적으로 수행

**Blocking/Async**

작업이 완료될 때까지 프로세스나 스레드가 블로킹되지만, 이러한 작업들은 별도의 스레드나 프로세스에서 비동기적으로 수행

특정 작업의 완료를 기다리는 동안 다른 작업을 수행하거나, 여러 작업을 동시에 시작하고 나중에 결과를 수집하는데 사용

#### Blocking / Non Blocking I/O 에 대해 설명해주세요

---

- I/O 작업은 데이터를 읽고 쓰는 데 시간이 소요될 수 있음

- 처리하는 방식에 따라 애플리케이션의 성능과 동작이 크게 영향을 받을 수 있음

**Blocking I/O**

![](https://velog.velcdn.com/images/sujipark2009/post/3e9e60ca-0bda-4258-9c42-593e0700c67b/image.png)

- I/O 작업이 완료될 때까지 프로세스 또는 스레드는 블록(즉,일시중지)상태

- I/O 작업이 완료되기 전까지는 해당 프로세스가 다른 작업을 수행할 수 없음

I/O 작업이 오래 걸리는 경우에 문제

ex) 디스크에서 데이터를 읽는 동안 프로세스는 대기 상태. 데이터가 준비되면 그제서야 작업을 계속 수행

**Non-blocking I/O**

![](https://velog.velcdn.com/images/sujipark2009/post/e7f7868a-a9b1-418f-bb9a-d32ae2ba2914/image.png)

- I/O 요청이 즉시 완료되지 않더라도 프로세스 또는 스레드는 블록 상태가 되지 않음

- I/O 작업이 완료되지 않았을 경우, 즉시 에러 코드를 반환

- 프로세스는 다른 작업을 계속 수행할 수 있음

이후에 I/O 작업이 완료되었는지 확인함

단점으로는, I/O 작업의 완료상태를 주기적으로 확인해야 한다는 것(Polling)

Non Blocking I/O 가 항상 Blocking I/O 보다 나은것은 아니다.

데이터가 즉시 사용 가능할 것으로 예상되는 경우, Blocking I/O가 적합하고

I/O 작업이 오래 걸리거나 프로세스가 다른 작업을 계속 수행해야 하는 경우에는 Non-Blocking I/O가 적합하다.
