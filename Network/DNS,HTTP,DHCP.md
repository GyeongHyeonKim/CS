### 네트워크 일반

---

네트워크의 정의 - 컴퓨터,서버,네트워크 장치, 기타 디지털 기기들이 통신할 수 있도록 서로 연결된 구조

네트워크의 용도 - 데이터와 정보 공유, 시스템간 상호작용, 자원의 효율적 분배

네트워크의 구성요소 -

노드 : 네트워크에 연결된 컴퓨터,서버,스위치,라우터 등의 기기

링크 : 노드들을 연결하는 통신 채널로, 유선이나 무선 방식을 사용

유선 링크 : 광섬유,이더넷 케이블 등
무선 링크 : WI-FI,블루투스,셀루러 등의 기술

프로토콜 : 네트워크에서 데이터를 교환할 때 사용되는 절차를 포함한 통신규약.
데이터 전송의 형식,속도,인코딩 방식 등을 정의

#### 네트워크의 종류

---

네트워크는 크기와 범위에 따라 다양한 종류로 분류된다.

LAN(Local Area Network) : 작은 지역(집,사무실,학교) 내의 컴퓨터와 장치를 연결하는 네트워크

WAN(Wide Area Networok) : 넓은지역(도시,국가,대륙)을 연결하는 네트워크.
일반적으로 더 낮은 속도의 연결을 제공
ISP(Internet Service Provider)를 통해 구축

WLAN(Wireless Local Area Network) : 무선 기술을 사용하여 지역적인 범위의 네트워크를 구성하는 방식. WI-FI가 있음

PAN(Personal Area Network) : 개인용 디지털 기기를 연결하는 작은 네트워크.
블루투스 기술을 이용한 헤드셋,스마트폰,스마트 워치 등의 기기 간 연결

#### 인터넷이란 ?

---

정의 : 전 세계의 컴퓨터 네트워크들이 상호 연결된 거대한 컴퓨터 통신망
Inter-network => network들을 하나로 연결한다는 의미

#### Web/WWW 이란 ?

---

정의 : 인터넷을 통해 정보를 검색,공유,표현하는데 사용되는 시스템.

HTML문서를 기반으로 하이퍼링크로 연결된 정보 시스템

특징 :

- HTTP를 기반으로 동작.
- 각 웹 페이지는 URL을 통해 접근.
- 웹 브라우저는 웹페이지를 렌더링해서 사용자에게 보여줌.

#### Host란 ?

---

정의 : 인터넷 또는 LAN에 연결되어 있는 컴퓨터 장치.
IP 주소를 가지고 해당 주소를 통해 다른 호스트와 통신

#### OSI 7계층에 대해 설명해주세요.

---

![](https://velog.velcdn.com/images/sujipark2009/post/13211d79-53f6-4f26-9dc3-b4169bdde247/image.png)

정의 :
Open Systems Interconnection.

표준 프로토콜을 사용하여 다양한 통신 시스템이 통신할 수 있도록 국제표준화기구에서 만든 개념 모델

계층 :

- 1. 물리계층(Physical Layer)

주로 전기적 신호나 광 신호와 같은 물리적인 통신 매체를 이용하여 데이터를 전송하는 계층.

데이터 전송 속도, 전기적인 신호와 광 신호의 전송 방식 등을 정의

- 2. 데이터 링크 계층(Data link layer)

물리 계층에서 전송된 데이터를 프레임으로 구성하고, 에러 검출 및 수정을 수행
MAC 주소를 이용하여 데이터를 보내는 측과 받는 측을 구분

- 3. 네트워크 계층(Network layer)

다양한 경로를 거쳐 목적지에 데이터를 전송하는 역할.
IP주소를 통해 목적지를 식별.
라우터와 같은 장비를 이용하여 경로를 결정.

- 4. 전송 계층(Transport layer)

송신자와 수신자 간에 연결을 설정하고, 데이터의 전송을 보장.
데이터의 분할,재조립,에러 검출 및 복구등을 수행.
TCP,UDP 프로토콜

- 5. 세션 계층(Session layer)

통신하는 양쪽 사이의 세션을 만들고, 세션관리를 담당 => 세션 연결,유지,종료
데이터가 통신하기 위한 논리적인 연결 담당 => TCP/IP세션을 만들고 유지. 종료되거나 전송이 중단될 시 복구하는 기능

양 끝단의 응용 프로세스가 통신을 관리하기 위한 방법을 제공

- 6. 표현 계층(Presentational layer)

데이터의 형식 변환,암호화,복호화 등의 작업을 수행
응용 계층이 사용하는 데이터 형식을 일관성 있게 유지
데이터가 하드웨어,OS에 구애받지 않도록 함 => ASCII를 사용하는 컴퓨터와 EBCDIC를 사용하는 컴퓨터 사이 문자를 보낼 수 있게 함

- 7. 응용 계층(Application layer)

사용자가 네트워크에 접근할 수 있도록 서비스를 제공하는 계층
HTTP,FTP,SMTP 등 다양한 프로토콜이 이 계층에서 사용

#### OSI Model과 TCP/IP Model의 차이점

---

공통점 : 네트워크 통신에서 사용되는 프로토콜을 계층적으로 분류한 모델

현재 대부분의 인터넷 프로토콜을 TCP/IP모델을 기반으로 동작

#### Transport layer와 Network layer의 차이

---

Transport :
어플리케이션 간의 데이터 전달.
송신자와 수신자 사이의 신뢰성 있는 전송

Network :
패킷이 전달되는 경로 설정, 올바른 목적지로 전달

#### 각 Layer는 패킷을 어떻게 명칭하는가?

---

명칭 :

응용,표현,세션 => 모두 `데이터`

전송 계층 => TCP의 경우 `세그먼트` UDP의 경우 `데이터그램`

네트워크 계층 => `패킷`

데이터 링크 계층 => `프레임`

물리 계층 => `비트`

#### 각 Header의 Packing Order에 대해 설명해주세요

---

각 네트워크 계층은 헤더를 추가하여 해당 계층의 프로토콜 및 기능을 처리.

헤더 패킹 순서 : 전송계층 -> 네트워크 계층 -> 링크 계층

전송 계층
TCP 또는 UDP 프로토콜이 사용
해당 프로토콜의 헤더가 데이터 앞에 추가
헤더는 포트 번호, 시퀀스 번호, 확인 응답 번호, 체크섬 등의 정보를 포함

네트워크 계층
IP 헤더가 패킷 앞에 추가
출발지 IP 주소, 목적지 IP 주소, 프로토콜, TTL(Time To Live) 등의 정보를 포함
패킷이 네트워크를 통해 전달되는 과정에서 라우팅 및 기타 네트워크 기능을 수행

데이터 링크 계층
출발지 MAC 주소, 목적지 MAC 주소, 프로토콜 타입 등의 정보를 포함
프레임의 끝에는 오류 검사를 위한 FCS(Frame Check Sequence)가 추가
프레임이 데이터 링크 계층에서 처리되며, 물리 계층을 통해 전송

#### DNS에 대해 설명해주세요

---

정의 :

Domain Name System or Domain Name Service.

도메인 이름을 네트워크 주소로 바꾸거나 그 반대의 변환을 수행하는 시스템

Domain Name이란, 클라이언트 소프트웨어에서 웹사이트에 엑세스 하는 데 사용되는 숫자 IP주소에 매핑되는 텍스트 문자열

**네임 서버란,** DNS를 운영하는 서버를 말한다.

**DNS의 구조**를 알아보면..

일반적으로 DNS를 가장 쉽게 구현하는 방법은, <hostname,ip주소> 의 레코드를 하나의 테이블에 다 때려박아넣는것이다.

하지만 실제로는 이렇게 하지 않는데, 이유는

1. 핑차이에 의한 속도차이
2. SPOF(Single Point of Failure)
3. 테이블의 레코드가 너무 많아서 탐색속도가 느려짐

이런 문제가 발생할 수 있기 때문이다.

그래서 `계층화`,`분산화`를 시켜놓는다.

![](https://velog.velcdn.com/images/sujipark2009/post/935dbf1b-aad7-412d-8c85-457f7cedb8b9/image.png)

이런식으로 DNS를 많은 서버로 나누고 이를 계층형태로 구성하여 전 세계로 분산시켜놓았다.

가장 위의 root server라는 것은, 개념상으로 특정 도메인의 ip주소를 알고싶을 때 가장 먼저 접근해야하는 곳이다.

그리고 바로 아래의 TLD(Top level domain)의 주소를 관리하고 있다.

가장 하위에는 `Authoritative DNS Server` 가 있는데,

인터넷에 속한 모든 기관들은 자신의 Authoritative DNS Server를 가지고 있어야 한다.
각자 기관들의 host에 대한 ip 매핑을 책임지는 것이다.

예를들어, 한양대학교의 Authoritative는 한양대학교의 매핑을 가지고 있는 것이다.

`www.hanyang.ac.kr` 이런 건 특정 컴퓨터를 지칭하는 것이며 특정 IP주소로 연결이 된다.

또, `portal.ac.kr` 이것에 대한 ip주소도 가지고 있어야 한다.ㅏ
이 정보를 다른 대학교에서는 알 수 없으니, 이런건 기관들이 자체적으로 관리해야하는 정보이다.

그러니까 한마디로.. 각 기관에 속한 정보는 각 기관이 관리하게되고 특별히 그런 기관을 Authoritative DNS Server라고 부르는 듯 하다.

DNS의 장점은,

`IP주소는 바뀌더라도 hostname은 변하지 않는다`는 것이다.

IP주소는 컴퓨터의 물리적인 위치와 관계가 깊은데, hostname은 그것을 초월한 개념이다.

네이버가 이사를 하면 IP주소는 바뀌지만 hostname은 바뀌지 않는다.

#### DNS 캐싱이란 ?

---

누군가가 www.hanyang.co.kr에 접속하고 싶다고 해보자.
그럼 이 도메인의 IP주소를 알아와야 한다.

각 기관에서는 내부적으로 local DNS를 두고 있어서, 사용자가 특정 도메인에 대한 ip주소를 알고싶으면 우선 내부 네트워크의 name server에 먼저 물어보게 되고, 거기에 없으면 네트워크 밖으로 나가서 답을 찾아오게 된다.

만약에 www.amazon.com을 물어봤는데 local DNS에 없었다?

그럼 local DNS는 이론상 Root name server부터 물어봐야 한다.

만약에 local DNS에 .com의 ip주소가 있었으면 root에 갈 필요 없이 거기로 바로 점프해서 찾을 수 있다.

이렇게, 클라이언트로부터 같은 질의가 Local DNS에 도착하면 해당 도메인에 대한 책임이 없어도 IP를 반환하는게 DNS 캐싱이다.

#### 계층 구조에서 IP를 찾는 과정을 설명해주세요

---

1. 우선 클라이언트의 캐시를 확인한다

브라우저나 운영체제의 캐시를 확인한다.

2. host파일을 확인한다.

3. 브라우저가 클라이언트의 Local DNS캐시를 확인하고 있으면 바로 IP주소를 반환한다.

4. 로컬 DNS 서버로 요청을 전송

   - ISP나 네트워크의 로컬 DNS 서버에 질의
   - 로컬 DNS 서버도 캐시를 확인하여 있으면 반환

5. 로컬 DNS 서버는,

- 루트 DNS 서버 조회 -> TLD서버 주소 반환 -> TLD는 도메인 최상위 수준(.com,.net)을 관리

- TLD 서버 조회 -> Authoritative DNS Server 주소 반환 -> .example.com 을 관리

- Authoritative DNS Server 조회 -> 도메인에 대한 최종 IP반환

- 클라이언트에게 IP 전달 -> 자신의 캐시에 저장

#### hosts파일은 어떤 역할을 하는가?

---

정의 : 도메인 이름과 IP주소의 매핑을 저장하는 로컬 파일

DNS 서버보다 우선순위가 높다는 특징이 있다.

#### DNS 레코드란 ?

---

정의 :

DNS 서버가 해당 패킷을 받았을 때 어떤식으로 처리할지 나타내는 지침.

DNS 상에서 도메인에 관한 설정을 하기 위해 사용되는 일련의 설정 문자.

#### DNS 레코드 타입 중 A,CNAME,AAAA의 차이는 ?

---

A :

- 해당 도메인 주소가 가지는 IP(1:1)

![](https://velog.velcdn.com/images/sujipark2009/post/093dc9a3-b43b-483e-aa10-71ba08f67050/image.png)

- 도메인 매핑에 따라 다대일도 될 수 있다.

![](https://velog.velcdn.com/images/sujipark2009/post/c5217363-ec80-4b95-82d5-df7fadba0a16/image.png)

- 한번의 요청으로 바로 IP를 얻을 수 있기에 빠르다.
- IP주소가 자주 바뀌는 환경에서 번거로울 수 있다.

A레코드의 장점은 **한번의 요청**으로 찾아갈 서버의 IP주소를 한번에 알 수 있다는 점이다.

즉,빠르다. 반면 단점은 **IP 주소가 자주 바뀌는 환경**에서는 번거로울 수 있다는 점인데

![](https://velog.velcdn.com/images/sujipark2009/post/2eda2649-ca02-4bd0-ae7f-15b917a4dad9/image.png)

이런식으로 2개의 도메인에 A레코드로 IP주소를 매핑했다고 하면

실 서버 주소가 업데이트로 인해 22.22.1.30으로 변경되는 경우, 일일이 도메인의 A레코드를 변경해줘야 한다.

지금은 2개뿐이지만, 도메인을 수십개 관리하고 있는 인프라 환경에서는 번거로울 수 밖에 없다.

CNAME :

- 별칭을 부여한 특정 도메인 주소
- 도메인 주소를 또 다른 도메인 주소로 이중매핑시키는 방식
- daum2.net에 접속해도 daum.ent으로 접속됨
- IP주소가 자주 변경되는 환경에서 유연하게 대처가능

![](https://velog.velcdn.com/images/sujipark2009/post/801daa0b-c008-4298-bb2d-b586c8554ffa/image.png)

브라우저에 daum2.net을 입력하면 daum.net으로 접근이 되는 형식이다.
그리고 daum.net에 매핑된 A레코드를 통해 IP주소를 얻어 최종적으로 서비스에 접속하게 되는 방식이다.

CNAME 레코드의 장점은 IP주소가 자주 변경되는 환경에서 유연하게 대응할 수 있다는 점이다.

![](https://velog.velcdn.com/images/sujipark2009/post/5b3fc70a-bf59-45eb-9abc-dff92a69f4df/image.png)

이렇게 두개의 서브도메인을 하나의 메인 도메인으로 매핑시키는 CNAME으로 저장하고

메인 도메인을 서버 IP로 매핑시키는 A 레코드로 저장하여 도메인 인프라를 구성해 놓았다면,

만일 서버의 IP주소가 바뀌었을 때 main.co.kr의 A레코드 정보만 변경시키면 나머지 CNAME으로 연결된 서브 도메인들은 따로 작업이 필요 없어진다.

그러나 CNAME 레코드의 단점은 아무래도 매핑을 중복으로 연달아 하여, 실제 IP주소를 얻으려면 여러번 DNS 정보를 요청해야 한다는 점이다.

따라서 DNS 정보를 해석하는데 경우에 따라서 **성능저하**를 유발할 수 있게 된다.

AAAA :

- IPv6 버전 A레코드
- 도메인에 IPv6 주소가 매핑되어 있음

#### DNS 쿼리 과정에서 손실이 발생한다면?

---

- 재전송 :
  DNS 프로토콜은 UDP를 사용하기에 자동 복구 매커니즘이 없음
  타임아웃시 자동으로 패킷을 재전송하게 된다.

- TCP :
  DNS에서 UDP를 사용할 때 512바이트를 넘는다면 TCP로 전환하여 재전송하게된다.

- 대체 DNS 서버 사용 :

DNS 클라이언트가 보통 여러 개의 DNS서버 주소를 구성 가능.
초기 서버에서 응답이 없다면 대체 DNS 서버를 사용

#### DNS는 몇 계층 프로토콜?

---

7계층 Application layer이다.

#### DNS는 UDP와 TCP중 어떤 것을 사용할까?

---

결론적으로는 둘 다 사용할 수 있다.

평소에는 UDP/53을 사용하지만, 큰 데이터의 전송을 위해서는 TCP/53을 사용한다.

주로 UDP를 사용하는 이유는,

UDP의 경우 연결 설정에 드는 비용(3way handshaking)이 없기에 속도가 빠르기 때문이고

DNS의 경우는 신뢰성보다는 속도가 중요한 서비스로, 못 받으면 그냥 다시 전달하면 된다.

또한 연결상태를 유지할 필요가 없으므로 DNS 서버가 더 많은 클라이언트를 수용할 수 있도록 하기 위함이다.

#### DHCP란?

---

DHCP(Dynamic Host Configuration Protocl)

네트워크에서 IP 주소 및 기타 네트워크 구성정보를 동적으로 할당해주는 프로토콜

클라이언트 컴퓨터가 네트워크에 연결될 때 자동으로 IP주소, 서브넷 마스크, 기본 게이트웨이,DNS 서버 등의 네트워크 설정을 제공한다.

IP : 192.168.1.47
mask : 255.255.255.0
router: 192.168.1.1
DNS : 192.168.1.1

이 정보가 바로 인터넷을 하기 위해 기본적으로 알고있어야 하는 정보이다.

이 네트워크의 prefix는 192.168.1이다.

router는, 내가 외부로 패킷을 보내기 위해 전달해야할 바로 옆에있는 라우터의 IP이다.
주소를 보면 IP와 같은 네트워크에 속한 1번임을 알 수 있다.

DNS는 내가 웹 브라우저를 열어서 www.naver.com을 쳤을 때 이 IP주소를 알아오기 위한 Local Name Server의 IP주소이다.

router와 DNS가 IP가 같으므로, Local Name Server 프로세스가 라우터에서 작동하고 있다는 것이다.

근데 이런 정보를 나는 적은적이 없다.
이런 인터넷을 활용하기 위한 필수적인 정보를 적은건 바로 `DHCP`이다.

이런 정보를 동적으로 해주는 이유는, 내가 새로운 곳에 갔을 때 알기가 어렵기 때문이다.

물론 자기자신만의 고정된 IP를 쓰는 경우도 있다.(대학원의 Desktop을 배정받는 경우.)

근데 나는 여기저기 떠돌면서 wi-fi를 쓰니까 이런 정보들을 자동으로 얻어오는 과정이 필요한데 그게바로 `DHCP`라는 것이다.

DHCP는 개념적으로, 누가 필요하다고 요청하면 특정시간동안 빌려주고 다시 회수하는 방식이다.

**IP주소 할당** :

네트워크에 연결된 클라이언트에게 사용가능한 IP주소 중 하나를 동적으로 할당

IP주소의 효율성을 높이고 IP주소 충돌을 방지

**서브넷 마스크 설정** :

네트워크 주소와 호스트 주소를 구분

서브넷 마스크는 IP주소의 범위를 정의하며, 클라이언트는 이를 통해 네트워크에 속하는지를 판별

**기본 게이트웨이 설정** :

DHCP는 클라이언트에게 기본 게이트웨이 주소를 제공

클라이언트가 다른 네트워크로 패킷을 전송할 때 사용되는 경로

**DNS 서버 설정** :

DNS(Domain Name System)서버의 IP주소를 제공

**장점** :

클라이언트가 네트워크에 처음 연결될 때 자동으로 IP주소를 얻을 수 있도록 하여 네트워크 관리자가 수동으로 IP 주소를 할당하는 번거로움을 줄임

네트워크 확장이나 변경 시에도 유연하게 IP주소를 재할당

**구성** :

DHCP서버와 DHCP클라이언트로 구성되어있는데,

DHCP서버는 네트워크에 대한 구성 정보를 관리한다.

DHCP 클라이언트는 네트워크에 연결되면 DHCP 서버에게 IP 주소 및 구성 정보를 요청하여 할당받는다.

#### DHCP는 몇 계층 프로토콜?

---

7계층에 속하는 프로토콜이다.

#### DHCP는 어떻게 동작하나?

---

네트워크에 새로운 호스트가 들어왔다고 해보면, 새로운 호스트는 아무정보가 없다.

내가 누구인지도 모르고 나에게 IP를 부여해 줄 서버의 ID도 모른다.

그래서 다음의 과정을 거친다.

1. DHCP Discvoer

- 클라이언트는 네트워크에 연결되면서 DHCP 서버를 찾기 위해 DHCP Discover 메시지를 브로드캐스트로 전송한다.

- 클라이언트의 MAC 주소 등의 정보가 포함되어있다.

source IP : 0.0.0.0 dest IP : 255.255.255.255
임의의 transactionID : 654

이런식의 메시지를 서브넷에 있는 모든 호스트에게 broadcast로 보낸다.

이 정보를 DHCP서버만 받고 나머지는 버리게되는데, 원리를 살펴보면

![](https://velog.velcdn.com/images/sujipark2009/post/7585363a-0d1b-4faf-8449-6059ad1cc530/image.png)

67번 포트로 보냈으니, 그 포트를 연 호스트만 받아들이게 된다.
67번 포트는 DHCP서버전용 포트여서 DHCP만 이 정보를 받아들이게 된다.

참고로 67,68번 포트는 DHCP 요청을 위한 `well-known` 포트이다.

2. DHCP Offer

- DHCP 서버는 DHCP Discover 메시지를 수신

- 사용가능한 IP주소 중 하나와 클라이언트에게 할당할 수 있는 다른 네트워크 구성 정보를 포함한 DHCP Offer 메시지를 클라이언트에게 전송

한마디로, "나 남는거 있으니까 하나 줄게!" 라는 의미이다.

source IP : 223.1.2.5,67 dest: 255.255.255.255,68
transactionID : 654(처음에 받은 것)

방금 들어온 호스트는 아직 IP주소가 없으므로, broadcast를 시킨다.

3. DHCP Request

- 클라이언트는 받은 DHCP Offer 중에서 원하는 IP주소와 함께 DHCP Request 메시지를 브로드캐스트로 전송

- 다른 DHCP서버가 해당 IP주소를 중복해서 할당하는 것을 방지

offer를 받아들이고 사용하고 싶다라는 메시지를 보낸다.

source : 0.0.0.0,68 dest: 255.255.255.255,67
transactionID: : 655(기존의 ID에 +1을 해서 request의 의미로 보낸다)

4. DHCP Acknowledgement

- DHCP 서버는 클라이언트의 DHCP Request 메시지를 수신하고, 클라이언트에게 해당 IP 주소와 함께 할당된 다른 네트워크 구성 정보를 포함한 DHCP Acknowledgement 메시지를 전송

- 클라이언트는 이를 받고 할당된 IP 주소 및 네트워크 구성 정보를 사용하여 자신을 구성

여기서 드는 의문점1

"offer 하면 끝난거아닌가? 이후의 과정이 왜 있을까?"

이유는 DHCP서버가 여러개가 있을 수 있어서 그렇다.

클라이언트는 각각의 offer중에 마음에 드는것을 찾아 request를 보내야한다.

의문점2

"DHCP request의 DEST는 왜 또 브로드캐스트일까?"

선택이 안된 나머지 DHCP서버들에게 내가 선택한건 이거라고 간접적으로 알려주기 위해서이다.

5. IP 주소 갱신

- 클라이언트는 DHCP 서버와 설정된 임대시간(lease time)동안 주기적으로 통신

- 더 사용해야한다면, 만료되기전에 IP주소 갱신을 요청

#### DHCP에서, IP주소 말고 추가로 제공해주는 정보가 있나요?

---

**서브넷 마스크(Subnet Mask)** :

클라이언트가 속한 서브넷의 네트워크 마스크를 제공하여 IP주소의 네트워크 부분과 호스트 부분을 구분한다.

**기본 게이트웨이(Default Gateway)** :

클라이언트가 외부 네트워크와 통신하기 위해 사용해야 하는 기본 게이트웨이(라우터)의 IP주소를 제공한다.

**DNS 서버 주소(DNS Server Address)** :

클라이언트가 도메인 이름을 IP주소로 변환하기 위해 사용해야 하는 DNS(Domain Name System) 서버의 IP주소를 제공한다.

**시간 서버 주소(Time Server Address)** :

클라이언트가 정확한 시간을 유지하기 위해 사용할 수 있는 시간 서버의 IP주소를 제공한다.

**호스트 이름(Host Name)** :

클라이언트의 호스트 이름을 제공하여 네트워크 내에서 식별할 수 있도록 한다.

**도메인 이름(Domain Name)** :

클라이언트가 속한 도메인의 이름을 제공한다.

**DNS 도메인(Domain Name Server)** :

클라이언트가 속한 도메인의 DNS 서버의 도메인 이름을 제공한다.

### HTTP 정리

---

정의 :

HyperText Transfer Protocol.

웹 상에서 클라이언트와 서버 간 요청/응답 으로 정보를 주고 받을 수 있는 프로토콜

주로 HTML 문서를 주고받는 데 쓰인다.

TCP와 UDP를 사용하며, 80번 포트를 사용

Client - Server 구조

응용 계층

#### HTTP가 동작하는 방식에 대해 말해주세요

---

1. 클라이언트에서 HTTP 요청을 생성

사용자가 웹 브라우저에 URL 주소를 입력하는 것

2. DNS 서버에 웹 서버의 호스트 이름을 IP주소로 변경 요청

IP주소를 획득한다

3. 웹 서버와 TCP 연결 시도

3way-handshaking

4. Http 요청 전송

Http Request를 보내는데, 3가지로 구성이 된다.

**Request Header** :

요청 메서드 + 요청 URI + HTTP 프로토콜 버전

ex) GET /background.png HTTP/1.0

Header정보 (key-value구조)

**공백** :

요청에 대한 모든 메타정보가 전송되었음을 알리는 용도

**Request Body** :

GET, HEAD, DELETE, OPTIONS처럼 리소스를 가져오는 요청은 바디 미포함

데이터 업데이트 요청과 관련된 내용(HTML 폼 컨텐츠 등)

5. 서버가 클라이언트에게 데이터 응답

HTTP Response도 3가지로 구성이 된다.

**Response Header** :

HTTP 프로토콜 버전 + 응답코드 + 응답 메시지

ex) HTTP/1.1 404 NOT FOUND

Header 정보(key-value 구조)

**공백** :

요청에 대한 모든 메타정보가 전송되었음을 알리는 용도

**Response Body** :

201,204 상태 코드는 바디 미포함

응답 리소스 데이터

6. 서버 클라이언트 간 연결 종료 또는 유지

4way-handshaking

Http/1.1에서는 Persistent Connection

7. 웹 브라우저가 웹 문서 출력

### Stateless와 Connectionless에 대해 설명해주세요

#### 왜 HTTP는 Stateless 구조를 채택하고 있을까요?

---

확장성 때문이다.

트래픽이 급증하여 scale out된 상황에 상태에 관계없이 새 서버를 확장가능하다.
왜냐하면 한 서버에만 있는 상태가 없기 때문이다.

또한 서버가 요청에 대한 정보를 기억할 필요가 없으므로 개발과 유지보수가 더 단순해진다.

#### HTTP가 Connectionless라고 했는데, TCP Handshaking은 연결된 상태인 것에 모순이지 않나요?

---

http는 TCP 위에서 만들어진 7계층 프로토콜이다.
4계층의 시선에서 보면 TCP를 통해 연결된 상태이다.

7계층의 시선에서 보면 서버와 클라이언트의 연결을 끊는다는 점에서 connectionless

"논리적으로 연결이 끊어진다"는 표현은 각 요청이 독립적으로 처리됨을 강조하기 위한 말이라고 한다.

실제 TCP 연결은 HTTP/1.1의 Keep-Alive에 의해 유지될 수 있지만, HTTP 프로토콜 자체는 요청-응답 간의 상태를 기억하지 않는 stateless하고 connectionless한 특성을 가진다고 함.

각 요청이 독립적으로 처리(connectionless)가 되기에 논리적으로는 연결이 끊어진 것 같지만, HTTP/1.1의 경우 TCP연결은 살아있어서 다음 요청에 같은 TCP연결을 사용하게 된다.

HTTP/1.0의 경우에는 논리적으로 연결을 끊으면 TCP연결도 끊긴다고 함

#### HTTP Persistence Connection 이 무엇인가요?

#### Persistence Connection이 필요한 이유와 장점은 ?

---

**Site Locality** 의 존재 :

서버에 연속적으로 동일한 클라이언트가 여러 요청을 보낼 가능성이 높은 경우.
웹에서 특정 페이지를 보여주기 위해 서버에 연속적으로 request를 보내는 경우가 많음.

장점 : Handshake를 1번만 해서 네트워크 혼잡 감소 및 latency 감소

#### TCP Keep-alive와 HTTP keep-alive의 차이는 무엇인가요?

---

**HTTP Keep-alive** :

정의 : HTTP에서 Persistence connection을 맺는 기법 중 하나.

목적 : HTTP요청마다 같은 TCP연결을 재사용

방식 : 헤더에 Keep-alive를 포함 => 클라이언트와 서버 연결을 유지하겠다는 의사
Keep-alive 타임아웃 => 연결상태에서 일정 시간 후에 연결을 종료

Keep-alive 시간 동안 http 요청을 받지 못하면 TCP Connection을 종료

**TCP Keep-alive** :

정의 : TCP 계층에서의 연결을 주기적으로 확인하기 위해 ACK를 주고받는 행위

목적 : 연결이 비정상적으로 끊어지지 않았는지 확인

방식 : 일정시간마다 Keep-alive 패킷을 전송 => 응답유무로 연결확인

특징 :

선택적옵션, 기본적으로 비활성.

디폴트로 2시간 간격으로 패킷 전송.

HTTP/1.1에서부터 Keep-alive 스펙이 존재하는데,

HTTP Keep-alive는 최대 얼마동안 연결을 유지하도록 하는게 목적인 반면 TCP Keep-alive는 두 종단 간의 연결을 유지하기 위함이다.

#### HTTP 응답코드에 대해 설명해주세요

---

정의 : 클라이언트 HTTP요청에 대한 서버의 응답 코드

상태 코드에 따라 요청의 성공/실패 여부를 판단

#### 401(Unauthorized)와 403(forbidden)은 의미적으로 어떤 차이가 있나요?

---

401의경우, 클라이언트가 요청한 리소스에 접근하기 위해 인증(authentication)이 필요한 경우이다.

인증 헤더(ex: Authorization 헤더)를 포함하여 요청을 다시 보내야 한다.

403의 경우, 인증(authentication)은 되었지만 인가(Authorization)가 되지 않아 권한이 없는 경우이다.

#### 200(ok)와 201(created)의 차이에 대해 설명해주세요

---

200의 경우, 클라이언트의 요청이 성공적으로 처리되었음을 의미한다.
서버는 요청에 대한 적절한 응답을 제공한 경우.

201의 경우, 클라이언트의 요청으로 새로운 리소스가 성공적으로 생성되었음을 의미한다
일반적으로 POST요청과 함께 사용한다.

### HTTP Method에 대해 설명해주세요

---

정의 : 서버에 요청할 작업의 종류를 정의

#### HTTP Method의 멱등성에 대해 설명해 주세요

---

정의 :

같은 연산을 여러번 실행한다고 해도 그 결과가 달라지지 않는 성질

필요성 : 데이터 일관성과 신뢰성 보장

멱등 이라는 단어의 뜻은 수학이나 전산학에서 연산을 여러 번 적용하더라도 결과가 달라지지 않은 성질을 의미한다.

위의 정의를 HTTP의 멱등성(Idempotent)에 대입해보면, 멱등성이란 요청(Request)을 한 번을 호출하든 여러 번을 호출하든 그 결과가 같음을 의미한다.

즉, **동일한 요청을 한번 보내는 것과 여러 번 연속으로 보내는 것이 같은 효과를 가지고, 서버의 상태도 동일하게 남을 때** 해당 HTTP 메서드가 멱등성을 가진다고 말한다.

HTTP 메소드의 멱등은 리소스에 **수정이 발생한다고 하더라도** 메서드를 여러 번 실행한 결과가 한 번 실행한 결과와 같다면 만족하는 속성이다.

또한 **호출을 실행한 결과**가 의미하는 것이 **응답 상태 코드가 아닌 서버의 상태**라는 점에 유의해야한다.

예를들어 똑같은 요청을 했을 때 응답하는 상태코드가 다르더라도 서버의 상태가 같은 상태라면 멱등성이 있다고 판단하는 것이다.

HTTP 스펙에 명시된 것에 의하면 `GET`,`PUT`,`DELETE`는 멱등성을 가지도록,

`POST`,`PATCH`는 멱등성을 가지지 않도록 구현해야 한다.

**GET의 멱등**

GET은 데이터를 한 번을 조회하든 여러 번을 조회하든 같은 결과가 조회되므로 안전과 멱등을 동시에 만족하는 메서드이다.

1. GET /post/1 요청
2. 서버에서 id값이 1인 게시글을 조회
3. 해당 게시글 데이터를 응답

위의 경우 같은 요청을 여러 번 보내더라도 서버의 상태는 항상 같게 된다.

**멱등적이지않은 GET의 설계**

만약 개발자가 조회수 기능을 추가하면서, 게시글 조회시 조회수도 올리도록 구현한다면?

1. GET /post/1 요청
2. 서버에서 id값이 1인 게시글을 조회
3. 해당 게시글의 조회수 데이터를 1증가
4. 해당 게시글 데이터를 응답

이 경우, GET 요청을 여러번 보낼 경우 서버의 데이터 상태는 매번 바뀌게 될 것이다.

즉, 위의 GET 요청 로직은 멱등성을 가지지 않는 것이며, 개발자는 **HTTP 스펙에 부합하지 않게 API를 구현**했다고 볼 수 있다.

따라서 GET의 멱등성에 맞게 API를 설계하기 위해서는, 조회수 컬럼의 값을 증가시키는 요청을 `PATCH` 요청으로 따로 분리하는게 올바르다.

**멱등하다고 해서 결과가 항상 같은것은 아님**

GET이 멱등성을 만족하기에 어떤 상황에서도 여러 번 요청할 경우 항상 같은 결과물을 내놓는다고 했지만, 이는 엄밀히 말하면 틀리다.

1. A가 GET /members/100 통해 리소스를 조회
2. B가 PUT /members/100 통해 리소스를 변경
3. A가 GET /members/100 통해 리소스를 다시 조회

위의 상황은, A가 멱등성이 있는 GET 메서드를 사용했는데도 불구하고 중간에 B의 개입으로 응답받는 결과값이 달라지게 된다.

그럼 멱등성이 깨진 잘못된 설계가 아니냐고 할 수 있지만, 멱등성의 여부는 외부 요인으로 인해 중간에 리소스가 변경되는 것은 고려하지 않으며, 또한 서버의 상태 기준으로 판단하기 때문에 GET의 멱등성은 문제가 없는것이다.

**DELETE의 멱등**

GET이 단순 조회라면, DELETE는 단순 삭제이다. 따라서 DELETE는 멱등성을 가진다.

DELETE를 처음 요청하면, 서버에서 해당 리소스는 삭제가 된다. 이후 DELETE를 여러번 요청하더라도 해당 리소스는 삭제된 상태 그대로 일 것이니 서버의 상태는 변하지 않는다.

서버에서 삭제 동작이 되니 서버의 상태가 변경된 것이 아니냐라고 생각하지만, 멱등성은 한번 호출하든 두번 호출하든 결과 상태가 같다는 의미이지, 전혀 변경이 일어나지 않음을 의미하는 것은 아니다.

즉, 처음 요청하든 다시 여러번 요청을 하든 서버의 상태는 리소스가 삭제된 상태를 반환하고 추가적인 동작을 하지 않으니 멱등하다는 것이다.

**멱등적이지 않은 DELETE의 설계**

DELETE의 멱등성 때문에, DELETE API를 설계할 때에는 **정확한 식별자를 통해 리소스를 지정**해야 한다.

예를들어 게시글을 삭제할 때 정확한 게시글 ID값이 아닌 last라는 구조로 좀 더 유연하게 서버에서 처리하도록 구현했다면?

DELETE /posts/last

그럴듯한 로직으로 보이나, 이런 경우 DELETE를 여러번 보내면 매번 마지막 게시글을 삭제하기 때문에 매번 서버의 상태가 변하게 된다.

즉, 멱등성을 가지지 않는 것이다. 이런 경우 멱등성을 가지지 않는 POST를 쓰는게 스펙상으로 맞다.

**POST의 멱등**

POST 메서드는 멱등을 만족하지 않는다.

POST는 서버로 데이터를 전송하여 새로운 자원을 생성하는 역할을 한다. 따라서 요청을 여러번 보내는 경우 매번 새로운 자원이 생겨나는 것이며, 이는 서버의 상태가 변경되는 것을 의미한다.

**복구 메커니즘에 따져야 하는 멱등성**

클라이언트가 서버에게 HTTP 메세지를 전송하였는데, TIMEOUT 과 같은 문제들로 인해 정상적인 응답을 전달받지 못했다고 가정해보자.

정상적인 응답을 받지 못했다면 다시 요청하면 그만이라고 생각하지만, 여기에 **HTTP의 멱등성의 유무**가 들어가게 된다.

일반적으로 GET이나 DELETE 같은 메서드들은 여러 번 호출하여도 응답 결과는 변함이 없기 때문에, 통신 장애 시 똑같은 요청을 재전송하도록 설계해도 문제는 없을 것읻.

하지만 POST 와 같은 멱등하지 않게 설계된 메서드들은 똑같은 요청을 다시 전송할 경우 문제 발생 가능성이 있다. 왜냐하면 통신 장애 이유가 서버 자체 문제일수도 있고 아니면 인터넷 선이 문제일수도 있기 때문이다.

![](https://velog.velcdn.com/images/sujipark2009/post/d1101018-f611-4e3c-94bc-9286f7d19b62/image.png)

만일 서버에서는 정상 처리했는데 응답 과정에서 네트워크 문제로 정상적인 응답을 받지 않았다면, POST를 재요청 해버리면 서버 입장에선 처리를 한 번 더 하게 되는 결과를 낳게된다.

만일 이것이 돈과 관련된 결제와 같은 서비스라면 결제가 중복으로 되는 큰 문제로 직결된다.

따라서 POST 요청 같은 경우 더 큰 문제가 발생할 수 있기 때문에 요청을 또 보내는 것이 아닌 다른 조치를 취할 수 있도록 설계하는 것이 적절할 것이다..

**PUT의 멱등**

PUT 메서드는 대상 리소스를 덮어씌워 변경하거나, 대상 리소스가 없다면 새로 추가한다.

그래서 만일 대상 리소슥 없다면 PUT이 POST와 같은 동작을 하게 되는데, 반면 POST는 매번 새로운 자원을 만드는 반면, PUT은 해당 자원이 이미 있다면 데이터만 덮어쓴다.

따라서 요청을 한번하든 여러번하든 결국 서버의 상태는 같아지니, PUT은 멱등하다

**멱등하다고 해서 결과가 항상 같은것은 아님**

GET의 멱등에서 본 것처럼 PUT도 예외 케이스가 있다.

PUT 요청을 보냈는데, 새로운 데이터를 생성한 경우 201(Created) 상태코드를 응답하며, 기존 데이터를 덮어쓴 경우 200(OK) 혹은 204(No content)를 응답하게 된다.

물론 다른 상태코드를 응답한다고 해서 멱등하지 않다는 것은 결코 아니며, 서버의 상태는 동일하므로 멱등성을 가진다고 할 수 있다.

**PATCH의 멱등**

PUT이 리소스 전체 교체라면, PATCH는 리소스의 부분적인 수정을 할 때 사용된다.

PATCH의 특이한 점은 기본적으로 멱등성을 가지지 않는 메서드인데, 그 구현을 PUT과 동일한 방식으로 할 경우 멱등성을 가지게 되는 특성을 가지고 있다ㅏ.

즉, PATCH는 멱등하게 설계할 수도 있고, 멱등하지 않도록 설계할 수도 있다는 말이다.

**PATCH의 멱등적인 설계**

PATCH 메서드에 수정할 리소스의 일부분만 담아서 보내는 경우에는 멱등성이 보장된다.

한번 요청을 보낸 후 같은 요청을 여러번 하더라도 변경된 같은 결과가 나오기 때문이다.

**PATCH의 멱등적이지 않은 설계**

PATCH의 또다른 특징으로는 HTTP 스펙상 구현 방법에 제한이 없다는 것이다.

그렇기 때문에 위처럼 꼭 데이터를 다른 데이터로 `대체`하도록 구성할 필요는 없다.

예를들어 PATCH의 동작을 `증가`를 통한 변경이라고 하면 상황이 달라진다.

![](https://velog.velcdn.com/images/sujipark2009/post/52c56769-1392-4a46-a35d-e2bd4aef2dde/image.png)

이런식으로 동일한 요청을 여러번 보내면, 매 요청마다 age가 1씩 증가하도록 PATCH api를 설계한다면 매번 age값이 달라질것이니 멱등성을 가지지 않는 것이다.

#### GET과 POST의 차이는 무엇인가요 ?

---

GET은 리소스를 조회

POST는 리소스를 생성. Request Body에 데이터를 넣어 보냄

PUT은 리소스 생성과 수정.

PATCH는 리소스 수정만 담당(일부 수정)

#### HTTP1.1 이후로 GET에도 Body에 데이터를 실을 수 있게 되었는데 그럼에도 왜 이런방식을 지양하는 것일까요?

---

여러가지가 있는데,

1. Restful Semantics

RESTful API 설계원칙에서는 GET 은 읽기 전용으로 사용하고, 데이터를 전송하거나 상태를 변경하는 요청에는 POST,PUT,PATCH 등을 사용하는 것이 일반적인 관행이다.

공식 문서에서 GET 요청에 본문을 포함할 수 있는 가능성을 배제하지 않았지만, 본문이 있을 경우 처리방법에 대한 구체적인 지침이 없다.

2. GET body를 지원하지 않는 클라이언트 존재

스프링에서도 GET에 body를 넣어보내면 @RequestBody에서 읽지 못한다

3. 캐싱

GET 요청은 캐시 서버에 의해 캐싱이 된다.
GET 요청의 body에 데이터가 있을 경우, 캐싱 시 문제가 발생한다.

캐시서버는 주로 URL과 헤더를 기반으로 캐시를 관리하기 때문이다.

캐시가 꼭 운영체제나 서버에만 있는 것이 아니라, 브라우저 자체도 하나의 소프트웨어라 캐시 공간을 가지고 있는데, 클라이언트가 서버에 한 번 요청했던 데이터에 대해 매 요청마다 다시 전송할 필요가 없도록 브라우저가 임시적으로 데이터를 보관하고 있는 장소이다.

즉, 캐싱이 가능한 HTTP 메서드는 빠르게 결과값을 받을 수 있다는 소리이다.

GET,POST,PATCH 메서드는 스펙 상 캐시가 가능하다.

하지만 실제로는 GET이나 HEAD정도만 캐시로 이용이 가능하고 POST,PATCH는 지원되지 않는게 일반적인데,

왜냐하면 브라우저의 캐시를 이용하려면 원본 데이터가 변경되지 않고 유지되어야 하는데, POST,PUT,DELETE,PATCH는 기본적으로 데이터 변경이 되는 메서드 이기 때문에 만일 호출로 인해 데이터가 변경되게 되면 원본 데이터 또한 변경되기에 캐시 데이터 불일치 문제가 생기기 때문이다.

반면 GET은 딱 URI만 키로 잡고 캐시하면 되서 간단하다.

#### HTTP 헤더의 구조에 대해 설명해 주세요

---

**General Header**

요청과 응답에 모두 사용.
통신 성격이나 연결 상태 설명.

Connection: keep-alive / Cache-control : no-cache/no-store/max-age=3600 등이 있다.

**Request Header**

클라이언트가 서버 요청 시 추가 정보 전달

Host : 요청의 대상 서버 호스트를 지정. www.example.com
User-Agent : 클라이언트 애플리케이션의 정보를 전달. Mozilla/5.0 ...
Accept : 클라이언트가 수락할 수 있는 콘텐츠 유형 지정. application/json, text/html 등

Authorization : 인증 정보를 포함. Bearer token , Basic Base64.. 등

**Response Header**

서버가 클라이언트에 추가 정보 전달

Server : 서버 소프트웨어 정보를 전달. Apache/2.4.41 (ubuntu)

Set-Cookie : 클라이언트에 쿠키 데이터를 설정. session_id=abc123; Path=/;HttpOnly.

Location : 클라이언트를 다른 URL로 리다이렉션. https://www.example.com/new-page.

**Entity Header**

요청이나 응답의 body에 대한 정보 설명

Content-Type : 본문의 콘텐츠 유형을 지정. application/json,text/html 등

Content-Length : 본문의 길이를 바이트 단위로 표시

Content-Encoding : 본문이 어떤 방식으로 인코딩되었는지 지정. gzip,deflate 등등

**Custom Header**

커스텀 정보 전달

### HTTP의 버전별 차이

#### HTTP 1.0과 1.1의 차이는?

---

**Persistent Connection**

![](https://velog.velcdn.com/images/sujipark2009/post/fe49c5c8-265c-4544-bf1e-effc5a8c1b49/image.png)

HTTP 1.0과 HTTP 1.1의 가장 큰 차이점은 지속성이다.
바로 Connection: keep-alive 속성이다.

HTTP 1.0에서는 요청하고 수신할 때마다 새로운 TCP 세션을 맺어야 한다.

반면,HTTP 1.1부터는 TCP세션을 한 번만 맺으면 여러 개의 요청을 보내고 응답을 수신할 수 있다.

결과적으로 TCP 세션을 처리하는 비용을 줄이고 응답속도를 개선할 수 있게 된다.

**Pipelining**

![](https://velog.velcdn.com/images/sujipark2009/post/e77d9bad-56c2-476a-8eec-06b4c94b5bf6/image.png)

HTTP 1.0에서는 한번에 하나의 요청을 보내고 응답이 도착해야 다음 요청을 보낼 수 있었다.

HTTP 1.1에서는 여러 요청을 동시에 보내서 요청과 응답의 대기 시간을 줄여 성능을 향상시켰다.

**Host 헤더 필드**

HTTP 1.0은 하나의 IP주소에 대해 하나의 웹 사이트만 운영할 수 있었다.

그래서 도메인을 여러 개 사용하려면 서버를 늘려야 했었다.

HTTP 1.1에서는 웹 서버에서 요청 Header에 Host를 전달받아 서버로 보내주는 가상 호스팅이 가능해졌다.

즉, 서버 1대가 여러 개의 Host를 담당할 수 있다.

**Cache-Control**

HTTP 1.0에선 Expires로 캐시 만료 시간을 설정하는 단순한 매커니즘이었다면

HTTP 1.1에서는 헤더를 추가하여 캐시 정책을 세밀화 하였다(no-cache/no-store/max-age=3600 등)

**HTTP Method**

HTTP 1.0 : GET,POST,HEAD
HTTP 1.1 : PUT,DELETE,PATCH 등 추가

#### HTTP 1.1의 단점을 알려주세요

---

HOL Blocking

헤더의 중복과 크기 문제

- http/1.1의 헤더에는 많은 메타정보들이 저장되어있다. 또한 해당 도메인에 설정된 Cookie 정보도 매 요청시 마다 헤더에 포함되어 전송되기 때문에 오히려 전송하려는 값 보다 헤더 값이 더 큰 경우가 있다.

지속 연결로 인한 리소스 소비

- 지속 커넥션 속에서 주고 받는 연속된 요청 데이터가 **중복된 헤더값**을 가지고 있는 경우가 많아 쓸데없이 메모리 자원을 낭비

#### HOL Blocking에 대해 설명해 주세요

---

Head of Line Blocking

여러 HTTP 요청을 했을 때, 서버가 순차적으로 처리하여 앞의 긴 요청 때문에
뒤의 요청들이 지연 처리되는 현상

원인 : 하나의 TCP 연결에서 하나의 요청-응답만 처리 가능

파이프라이닝을 통해 여러 요청을 보내는 것은 가능하지만, 요청을 처리하려면 이전 응답이 도착해야 한다.

파이프 라이닝은 혁신적인 기술이지만, 보낸 요청 순서대로 응답을 받아야 하는 규칙 부분에서 문제가 생기게 된다.

마치 FIFO 처럼 생각하면 되는데, 문제는 요청하는 데이터의 크기는 제각각 이므로 첫번째 요청한 데이터가 용량이 큰 데이터라면, 두번째 세번째 데이터가 아무리 빨리 처리되어도, 우선순위 원칙에 따라 첫번째 데이터의 응답 속도가 늦어지면 후 순위에 있는 데이터 응답속도도 덩달아 늦어지게 되는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/f1f95bbd-bf4d-4177-93f0-084197299ec3/image.png)

첫번째 http request에서는 하나의 요청당 응답을 받아야 다음 요청을 보내는 오래된 방법으로 time의 길이를 보면 오래걸렸었다.

그래서 pipelining을 통해 동시 요청을 통해 time을 감소시켰지만, 문제는 **첫번째 요청에 대한 응답이 오래걸릴 경우** 그 뒤의 응답도 같이 늦게 되서 결과적으로 총 time이 길어지게 되는 비효율적인 상황이 발생하게 되는 것이다.

이 문제는 HTTP/2에서 해결되는데..

#### HTTP/1.1과 HTTP/2의 차이점은 무엇인가요?

---

HTTP/2.0은 HTTP/1.1 버전의 성능 향상에 초점을 맞춘 프로토콜이다.

HTTP/1.1 까지는 한번에 하나의 파일만 전송이 가능했다. 비록 파이프라이닝 기술이 있었지만, 여러 파일을 전송할 경우 선행하는 파일의 전송이 늦어지면 HOLB(Head of Line Blocking)이 발생하였다.

따라서 HTTP/2.0에서는 이 문제를 해결하기 위해 **여러 파일을 한번에 병렬로 전송**한다.

![](https://velog.velcdn.com/images/sujipark2009/post/a2400094-1c63-4628-9c11-bd8f0e3b140f/image.png)

그래서 일반적으로 HTTP/2.0을 사용만 해도 웹 응답 속도가 HTTP/1.1에 비해 15~50%가 향상된다고 한다.

**binary framing**

1.1과 2.0의 주요한 차이점은 HTTP 메세지가 1.1에서는 text로 전송되었던 것과 달리, 2.0에서는 **binary frame**으로 인코딩되어 전송된다는 점이다.

> 기존 text방식으로 HTTP 메세지를 보내는 방식은, 본문은 압축이 되지만 헤더는 압축이 되지 않으며 헤더 중복값이 있다는 문제 때문에 HTTP 2.0에서는 바이너리로 변경되었다.

또한 HTTP 헤더에 대해서 이야기 할 때 헤더와 바디를 \r이나 \n과 같은 개행 문자로 구분한다고 했었는데, 2.0부터는 헤더와 바디가 `layer`로 구분된다.

이로인해 데이터 파싱 및 전송 속도가 증가하였고 오류 발생 가능성이 줄어들었다.

![](https://velog.velcdn.com/images/sujipark2009/post/a037c27d-95b2-4fb4-b171-e558567f107d/image.png)

**Stream과 Frame 단위**

1.1에서는 HTTP 요청과 응답이 텍스트 Message 단위로 구성되어 있었다.
2.0으로 오면서 Message라는 단위 외에 Frame,Stream이라는 단위가 추가되었다.

`Frame` : 2.0에서의 통신의 최소 단위이며, Header 혹은 Data가 들어있다.

`Message` : 1.1과 마찬가지로 요청 혹은 응답의 단위이며 다수의 Frame으로 이루어진 배열 라인

`Stream` : 연결된 Connection 내에서 양방향으로 Message를 주고받는 하나의 흐름

즉, 2.0은 HTTP 요청을 여러개의 Frame들로 나누고, 이 frame들이 모여 요청/응답 Message가 되고, 그리고 Message는 특정 Stream에 속하게 되고, 여러개의 Stream은 하나의 Connection에 속하게되는 구조이다.

![](https://velog.velcdn.com/images/sujipark2009/post/43e3e39a-7101-4ef5-854f-7f14bc63d815/image.png)

이 처럼 **프레임** 단위로 이루어진 요청과 응답 **메세지**는 하나의 **스트림**을 통해 이루어지며, 이러한 스트림들이 하나의 **커넥션** 내에서 병렬적으로 처리된다.

하나의 커넥션에서 여러개의 스트림이 동시에 열리니 속도가 빠를 수 밖에 없다.

**Multiplexing**

![](https://velog.velcdn.com/images/sujipark2009/post/7249d6b2-693b-4095-b5f7-105763bee63f/image.png)

하나의 TCP 연결에서 동시에 여러 요청과 응답 주고받기 가능

각 스트림에 고유 식별자와 우선순위/종속성 존재.

각 메세지는 하나의 논리적 HTTP 요청 또는 응답.

![](https://velog.velcdn.com/images/sujipark2009/post/6e686dce-2baf-4b18-bb8f-c8b53e07cc75/image.png)

프레임을 전달받은 쪽에서는 프레임 헤더의 스트림 식별자를 통해 프레임 재조립.

1.1의 HOL Blocking 해결.

![](https://velog.velcdn.com/images/sujipark2009/post/e4da75c2-82c6-4964-8683-047a8b4a171a/image.png)

바로 위에서 frame-message-stream-connection에서 봤듯이 HTTP 헤더 메세지를 바이너리 형태의 프레임으로 나누고 **하나의 커넥션으로 동시에 여러개의 메세지 스트림을 응답 순서에 상관없이 주고받는 것**을 **멀티플렉싱**이라고 한다.

HTTP/1.1의 Connection keep-alive,pipelining,Head of Line Blocking을 개선했다.

latency만 줄여주는게 아니라 결국 네트워크를 효율적으로 사용할 수 있게 하고 그 결과 네트워크 비용을 줄여준다.

특히 클라우드 시스템을 이용한다면 비용과 직결된다.

**HTTP 1.1 통신 과정**

HTTP/1.1에서는 한 TCP 커넥션을 통해 요청을 보냈을 때, 그에 대한 응답이 도착하고 나서야 같은 TCP 커넥션으로 다시 요청을 보낼 수 있다.

따라서 웹브라우저들은 회전 지연을 줄이기 위해 여러개의 TCP 커넥션을 만들어 동시에 여러 개의 요청을 보내는 방법을 사용하였다.

그러나 그렇다고 TCP 커넥션을 무한정 만들 수는 없기에, 한 페이지에 보내야 할 요청이 수십개에서 수백개에 달하는 요즘 시대에는 한계가 있었다.

**HTTP 2.0 통신 과정**

반면 2.0에서는 **하나의 커넥션에 여러 개의 스트림이 동시에 요청/응답 한다.**

1.1은 요청과 응답이 메시지라는 단위로 구분되어 있었지만, 2.0부터는 Stream을 통해 요청과 응답이 묶일 수 있어 다수 개의 요청을 병렬적으로 처리가 가능해졌다.

따라서 응답 프레임들은 요청 순서에 상관없이 먼저 완료된 순서대로 클라이언트에 전달이 가능하다.

**Server push**

2.0에서는 클라이언트의 요청에 대해 미래에 필요할 것 같은 리소스를 똑똑하게 미리 보낼 수 있다.

예를들어 클라이언트로부터 HTML문서를 요청하는 하나의 HTTP 메세지를 받은 서버는 그 HTML 문서가 링크하여 사용하고 있는 이미지,CSS파일,JS 파일 등의 리소스를 스스로 파악하여 클라이언트에게 미리 push해서 미리 브라우저의 캐시에 가져다 놓는다.

즉, 서버는 요청하지도 않은 리소스를 미리 보내어 가까운 미래에 특정 개체가 필요할때 바로 사용 되도록 성능 향상을 이끌어 내는 것이다.

그래서 클라이언트가 HTML 문서를 파싱해서 필요한 리소스를 다시 요청하여 발생하게 되는 트래픽와 회전지연을 줄여준다는 장점이 있다.

**Stream Prioritization**

1.1에서 파이프라이닝 이라는 기술이 있었지만, 우선 순위 문제 때문에 HOLB가 발생하여 사장되었다고 했다.

2.0에서는 **리소스간 의존관계(우선순위)를 설정**하여 이런 문제를 해결하였다.

HTTP 메세지가 개별 바이너리 프레임으로 분할되고, 여러 프레임을 멀티플렉싱 할 수 있게 되면서 요청과 응답이 동시에 이루어져 비약적인 속도 향상이 되었다.

하지만 하나의 연결에 여러 요청과 응답이 뒤섞여 버려 패킷 순서가 엉망 진창이 되었다.

따라서 스트림들의 우선순위를 지정할 필요가 생겼는데, 클라이언트는 **우선순위 지정 트리**를 사용하여 스트림에 식별자를 설정함으로써 해결하였다.

각각의 스트림은 1~256까지의 가중치를 갖는다.
하나의 스트림은 다른 스트림에게 명확한 의존성을 갖는다.

![](https://velog.velcdn.com/images/sujipark2009/post/82bef57c-ef7f-424b-bd44-a6d5207d110a/image.png)

![](https://velog.velcdn.com/images/sujipark2009/post/cff0fa05-51e4-4e40-ad5b-374ac190005f/image.png)

클라이언트는 서버에게 스트림을 보낼때, 각 요청 자원에 가중치 우선순위를 지정하고 보낸다.

그렇게 요청받은 서버는 우선순위가 높은 응답이 클라이언트에 우선적으로 전달될 수 있도록 대역폭을 설정한다.

응답받은 각 프레임에는 이것이 어떤 스트림인지에 대한 고유한 식별자가 있어 클라이언트는 여러개의 스트림을 interleaving을 통해 서로 끼워놓는 식으로 조립한다.

**Header Data Compression**

1.1에서 헤더는 아무런 압축 없이 그대로 전송되었다. 이를 개선하기 위해 2.0에서는 **HTTP 메시지의 헤더를 압축하여 전송**한다.

1.1에서는 연속적으로 요청되는 HTTP 메시지들에게서 헤더값이 중복되는 부분이 많아 역시 메모리가 낭비되었는데, 2.0에서는 이전 Message의 **헤더의 내용 중 중복되는 필드를 재전송하지 않도록**하여 데이터를 절약할 수 있게 되었다.

![](https://velog.velcdn.com/images/sujipark2009/post/8fbd034b-b4bc-4531-83ee-7ecf266c8723/image.png)

만일 메세지 헤더에 중복값이 존재하는 경우, Static / Dynamic Header Table 개념을 사용하여 중복 헤더를 검출하고, 중복된 헤더는 index 값만 전송하고 중복되지 않은 Header 정보의 값은 호프만 인코딩 기법을 사용하는 HPACK 압축 방식으로 인코딩 처리하여 전송하여 데이터 전송 효율을 높였다.

https://http2.tistory.com/1 << 허프만 인코딩 간략하게 설명

**HTTP 2.0 문제점**

**여전한 RTT(Round Trip Time)**

아무리 혁신적으로 개선되었다 하더라도, 1.1이나 2.0은 여전히 `TCP`를 사용하기 때문에 Handshake의 RTT로 인한 지연시간(latency)이 발생한다.

결국 **원초적으로 TCP로 통신하는게 문제**인 것이다.

**TCP 자체의 HOL Blcoking**

2.0에서 1.1의 파이프라이닝 문제를 멀티플렉싱을 통해 해결했다고 하였다.

하지만 기본적으로 TCP는 패킷이 유실되거나 오류가 있을 때 재전송하는데, 이 재전송 과정에서 패킷의 지연이 발생하면 결국 HOLB문제가 발생한다.

TCP/IP 4계층을 보면, 애플리케이션 계층에서 HTTP HOL Blocking을 해결하였다 하더라도, 전송계층에서의 TCP HOL Blocking을 해결한건 아니기 때문이다.

![](https://velog.velcdn.com/images/sujipark2009/post/2b6e079e-253c-4955-829f-8e65dfaeb757/image.png)

### HTTP/3.0의 주요 특징에 대해 설명해 주세요.

2.0의 등장과 함께 기존의 프로토콜 데이터 체계를 프레임과 스트림 개념으로 재구축한 결과 기존 보다 혁신적으로 성능이 향상되게 되었다.

하지만 여전히 HTTP는 TCP 기반 위에서 동작되기 때문에, TCP자체의 핸드쉐이크 과정에서 발생하는 지연시간과, 기본적으로 TCP는 패킷이 유실되거나 오류가 있을 때 재전송을 하는데 이 재전송하는 패킷에 지연이 발생하면 결국 **HOL Blocking** 문제가 발생되었다.

즉, 2.0은 Application 계층의 HTTP에서 HOLB는 해결하였으나, Transport계층에서의 TCP HOLB를 해결한건 아니기 때무니다.

**애초에 TCP로 인터넷 통신을 하는 것**이 발목을 잡은 것이다.

그래서.. 구글이 새로운 UDP기반의 `QUIC 프로토콜`을 고안하게 된다.

그리고 이 새로운 QUIC프로토콜이 TCP/IP 4계층에도 동작시키기 위해 설계된 것이 바로 `HTTP 3.0`이다.

즉, HTTP/1.1과 HTTP/2.0은 TCP를 전송에 사용하지만 HTTP/3.0은 UDP를 사용한다고 보면 된다.

**QUIC 프로토콜**

3.0의 가장 큰 특징은 기존의 1.1,2.0과는 다르게 `UDP` 기반의 프로토콜인 QUIC(Quick UDP Internet Connections)을 사용하여 통신하는 프로토콜이라는 점이다.

말 그대로 **UDP를 사용하여 빠르게 인터넷 연결**을 하는 새로운 프로토콜이다.

![](https://velog.velcdn.com/images/sujipark2009/post/6f1f8761-174d-439e-8d08-a8481297b632/image.png)

3.0의 계층 형태는 약간 특이한데..

왜냐하면 QUIC는 TCP + TLS + HTTP의 기능을 모두 구현한 프로토콜이기 때문이다.

TCP 프로토콜의 무결성 보장 알고리즘과 SSL이 이식됨으로써 높은 성능과 동시에 신뢰성을 충족시켰다고 보면 된다. 그래서 계층 위치도 약간 비스듬하게 걸쳐있게 표현된 것이다.

쉽게 말하면, Application 계층의 3.0은 QUIC 를 동작시키기 위해 있는 것이라고 보면 되고, QUIC는 UDP를 기반으로 만들어졌기에 Transport 계층의 UDP위에서 동작한다고 보면 된다.

**어째서 TCP가 아닌 UDP인가**

**TCP는 구조상 한계로 개선해도 여전히 느리다**

TCP가 만들어지던 시절에는.. 클라이언트와 서버가 동시 다발적으로 여러 개 파일의 데이터 패킷을 교환할 것이라고 상상하지 못했었다.

그래서 모바일 기기와 같이 네트워크 환경을 바꿔가면서 서버와 클라이언트가 소통할 수 있을 것이라고 생각하지 못했다. 그 때문에 와이파이를 바꾸면 다시 새로운 커넥션을 맺어야 되서 끊김 현상이 일어나는 것이다.

또한 TCP를 사용한 통신에서는 패킷은 신뢰성을 위해 무조건 순서대로 처리되어야 한다.

패킷이 처리되는 순서 또한 정해져있으므로 이전에 받은 패킷을 파싱하기 전 까지는 다음 패킷을 처리할수도 없다. 만일 중간에 패킷이 손실되어 수신측이 패킷을 제대로 받지 못했으면 다시 보내야 한다.

이렇게 패킷이 중간에 유실되거나 수신 측의 패킷 파싱 속도가 느리다면 통신에 병목이 발생하게 되는데, 이러한 현상을 HOL Blocking이라고 부른다

이 HOLB는 TCP 설계도 상 어쩔수없이 발생하는 문제이기 때문에, 1.1뿐만 아니라 2.0도 가지고 있는 아주 고질적인 문제였다.

**UDP는 신뢰성이 없는게 아니라 탑재를 안했을 뿐이다**

UDP는 기능이 거의 없어서 빠르지만 대신에 신뢰성이 낮기 때문에, 인터넷 통신에선 조금 느리더라도 신뢰성이 높은 TCP를 사용한다고 했었다.

UDP는 User Datagram Protocol이라는 이름에서처럼 데이터그램 방식을 사용하는 프로토콜이기에 패킷의 목적지만 정해져있다면 중간 경로는 신경쓰지 않기 때문에 핸드쉐이크 과정이 필요없다.

결론적으로 UDP는 TCP가 신뢰성을 얻기 위해 내제된 과정을 거치지 않기 때문에 속도가 더 빠를 수 밖에 없다는 것인데, 그렇다면 UDP를 사용하게 되면 빠르지만 신뢰성과 패킷의 무결성을 보증할 수 없다는 뜻인데 이걸 인터넷 통신에 사용해도 되는 것인가?

이 부분은 오해인것이, **UDP는 신뢰성이 없는게 아니라 탑재를 안했을 뿐**이라고 한다.

UDP의 진짜 장점은 **커스터마이징이 가능**하다는 점이다.

![](https://velog.velcdn.com/images/sujipark2009/post/89b0614b-ff5c-4958-99e6-8866df99c61f/image.png)

UDP자체는 헤더에 들은게 없어서 신뢰성이 낮고 제어기능도 없지만, 이후 개발자가 어플리케이션에서 구현을 어떻게 하느냐에 따라 TCP와 비슷한 수준의 기능을 가질 수도 있다는 말이다.

**HTTP/3.0 개선점**

**연결 시 latency 감소**

기존 TCP+TLS에서는 TLS 연결을 위한 핸드쉐이크와 TCP를 위한 핸드쉐이크가 각각 발생했다.

그래서 TCP연결을 생성하기 위해 기본적으로 1RTT가 필요하고, 여기에 TLS를 이용한 암호화 통신까지 한다면 총 3RTT가 필요하게 된다.

QUIC에서는 이를 한단계로 줄였다.

UDP 위에서 동작하는 QUIC는 통신을 시작할 때 3 Way Handshake 과정을 거치지 않아도 되기 때문에 1RTT만 소요된다. 그 이유는 **연결 설정에 필요한 정보와 함께 데이터도 보내버리기 때문**이다.

QUIC 내에 아예 TLS 인증서를 내포하고 있기 때문에, 최초의 연결 설정에서 필요한 인증 정보와 데이터를 함께 전송한다.
그래서 클라이언트가 서버에 어떤 신호를 한번 주고, 서버도 거기에 응답하기만 하면 바로 본 통신을 시작할 수 있다는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/127ce17f-94ab-48b7-b176-0fc380e19858/image.png)

그리고 한번 연결에 성공했다면 서버는 그 설정을 캐싱해놓고 있다가, 다음 연결 때 캐시를 불러와 바로 연결을 하기 때문에 추가적인 핸드쉐이크 없이 0RTT마나으로 바로 통신을 시작할 수도 있다는 장점도 있다.

**HOLB 문제 해결**

1.1같은 경우 파이프라인 기술을 통해 병렬적으로 리소스를 빠르게 얻도록 하려고 하였지만, 만일 첫번째 요청에 병목이 생기면 나머지 요청이 빨리 처리되었음에도 불구하고 딜레이가 되는 현상이 있었다.

예를들어 3개의 이미지 a,b,c를 받는다고 가정한다면 첫번째 a를 받는 과정에서 오래걸리게 된다면 나머지 b,c가 아무리 빨리 처리되더라도 결과적으로 늦게 받게 된다.

그래서 이를 극복하기 위해 2.0에서는 리소스들을 하나의 커넥션에서 병렬적으로 보내도록 개선하였다.

**TCP의 HOLB**

이처럼 HTTP 레이어의 HOLB는 해결됐지만, 문제는 TCP 레이어의 HOLB 문제가 여전히 잔존해 있었던 것이다.

2.0을 사용하는 일반적인 브라우저는 TCP 연결 한개로 수십,수백의 스트림 데이터를 병렬 전송을 한다. 그런데 만일 두 엔드포인트 사이 네트워크 어딘가에서 하나의 패킷이 빠지거나 없어진다면, 없어진 패킷을 다시 전송하고 목적지를 찾는 동안 전체 TCP연결이 중단되게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/4685dc5a-fd10-43ef-bf35-33140789a7b6/image.png)

즉, 2.0에서 스트림에서 여러가지 프레임들이 뒤섞여서 이동하게 되는데, 만일 어느 하나의 프레임에 문제가 생기면 상관없는 그 뒤의 프레임까지 영향이 가게 된다.

따라서 결국은 HTTP의 HOLB처럼 스트림 내 패킷들은 전체가 지연이 되게 된다.

**독립 스트림으로 HOLB 단축**

그래서 TCP를 버리고 QUIC로 구축해서 **아예 스트림 자체를 독립적으로 여러개로 나누어서** 처리하도록 하였고 이를 독립 스트림이라고 한다.

QUIC 연결을 통해 두 가지 다른 스트림을 설정했을 때, 이들을 독립적으로 다루므로 만약 특정 스트림에서 HOLB가 발생하더라도 다른 스트림에도 영향을 미치지 않는다.

![](https://velog.velcdn.com/images/sujipark2009/post/9c017e40-2eaa-4362-888c-bd2f802012a9/image.png)

**패킷 손실 감지에 걸리는 시간 단축**

HOLB에 이어 QUIC는 흐름 제어하는 시간까지 단축하였다.

QUIC도 TCP와 마찬가지로 전송하는 패킷에 대한 흐름 제어를 해야한다. QUIC는 기본적으로 TCP와 유사한 방법으로 패킷 손실을 탐지하지만 여기에 몇 가지 알고리즘 개선사항을 추가하였다.

예를들어 2.0에서는 하나의 스트림에 A,B,C 패킷 프레임들이 비순서대로 전달될 때, 만일 3번째 프레임에서 패킷 손실이 일어나면, 패킷 B만 중지되어야 하지만 전혀 연관없는 A와 C도 모두 막혀 대기를 해야된다.

![](https://velog.velcdn.com/images/sujipark2009/post/fc5e5451-771b-45db-8915-a9266bf04a00/image.png)

이러한 문제를 해결하기 위해 QUIC는 헤더에 패킷의 전송 순서를 나타내는 별도의 패킷 번호 공간을 부여했다.

![](https://velog.velcdn.com/images/sujipark2009/post/588d30c5-1d80-4d42-9f52-92dfe821f5fb/image.png)

이를 이용해 QUIC는 패킷 번호를 파악해 개별 파일을 구분하여 중간에 패킷 로스가 발생해도 해당 파일의 스트림만 정지가 되도록 할 수 있다.

하나의 스트림에서 문제가 발생한다고 해도 다른 스트림은 지킬 수 있게 되어 이런 문제에서 자유로워졌다.

**더욱 향상된 멀티플렉싱**

**보안을 더욱 강화**

기본적으로 QUIC내에 TLS가 포함되어있기 때문에 TCP와 달리 **헤더 영역도 같이 암호화**된다.

![](https://velog.velcdn.com/images/sujipark2009/post/b373a0c3-c81d-435a-b764-0f26d4318502/image.png)

**네트워크가 변경 되어도 연결이 유지**

TCP의 경우 클라이언트와 서버가 서로를 구분하기 위해서는 (클라이언트 IP,클라이언트 PORT,서버 IP,서버 PORT)이렇게 4가지가 필요하다.

그래서 클라이언트의 IP가 바뀌는 상황이 오면 연결이 끊어져 버린다.

휴대폰을 들고 와이파이존에서 LTE데이터를 사용하게 됐을 때 동영상 끊김과 같이 일시적 지연이 일어나는 이유는 클라이언트 IP가 이때 바뀌기 때문이다. 그래서 다시 연결을 생성하기 위해 결국 핸드쉐이크 과정을 다시 거쳐야한다는 것이고, 이 과정에서 다시 지연시간이 발생하게 되는 것이다.

**Connection ID**

반면 QUIC는 Connection ID를 사용하여 서버와 연결을 생성한다.

Connection ID는 각 연결은 연결 식별자나 연결 ID를 가지므로 이를 통해 연결을 식별한다

![](https://velog.velcdn.com/images/sujipark2009/post/4b585c33-9d92-4cee-8296-58e8db4f1788/image.png)

Connection ID는 랜덤한 값일 뿐, 클라이언트의 IP와는 무관한 데이터이기 때문에 클라이언트의 IP가 변경되더라도 기존의 연결을 계속 유지할 수 있다.

그래서 새로 연결을 생성할 때 거쳐야하는 핸드쉐이크 과정을 생략할 수 있다.

하지만 같은 Connection ID만 사용한다면, 해커가 네트워크를 통해 사용자를 추적하여 보안 문제가 일어날 수도 있을 것이다. 그래서 QUIC는 새 네트워크가 사용될 때마다 Connection ID를 변경한다.

뭔가 이상하지만,

내부적으로 클라이언트와 서버가 모두 연결을 위해 무작위로 생성한 Connection ID에 대해 인지하고 있고, 네트워크가 바뀔때 Connection ID를 바꾸더라도 이게 이전 Connection ID와 동일하다고 인지하여 연결을 유지하는 것이다.

#### QUIC에서 UDP를 선택한 이유는 무엇일까요 ?

---

TCP 헤더는 신뢰성을 확보하지만, 지연을 줄이기 힘든 구조이다.

UDP는 가벼워서 커스마이징이 용이하며, 연결 설정 과정에서 필요한 정보 + 데이터를 함께 보내버리기 때문에 TCP Latency를 줄이면서 신뢰성 확보가 가능하다.

#### QUIC는 3way handshaking 없이 어떻게 연결을 설정하나요?

---

O-RTT 또는 1-RTT 연결을 한다.

초기 연결설정의 경우 1-RTT설정인데,

클라이언트는 서버에게 initial 패킷을 전송하는데, 여기에는

클라이언트가 생성한 Connection ID, QUIC 버전, 암호화 알고리즘 정보 등이 포함되어있다.

서버는 클라이언트의 initial 패킷을 받고 자신의 Connection ID,암호화 키, 암호화 알고리즘 정보 등을 포함한 initial 패킷을 클라이언트에게 전송한다.

클라이언트와 서버는 각각의 initial 패킷을 기반으로 암호화 키를 생성한다

특징으로는, TLS Handshake와 연결 설정을 동시에 처리한다는 것이다.

0-RTT 연결 설정의 경우,

QUIC는 이전 연결 정보를 재사용하여 0-RTT 연결 설정을 제공한다.

클라이언트가 이전에 서버와 연결했다면, 클라이언트는 서버로부터 받은 암호화 키 및 연결 정보를 저장하고 재사용

클라이언트는 이전에 받은 연결 정보를 사용하여 서버에게 0-RTT 패킷을 전송
여기에는 이전 연결에서 사용한 Connection ID,암호화 키,암호화 알고리즘 정보 등이 포함되어있다.

패킷을 받은 서버는 저장된 연결 정보를 기반으로 클라이언트와 바로 암호화된 통신을 시작하게된다.

참고로, QUIC는 TLS 1.3방식을 사용하는데

initial 패킷을 교환 시 각자의 공개키를 주고받게 된다.

이때, 공개키는 각자의 비밀키를 통해 수학적 계산을 통해 생성하게되고

**Diffie-Hellman** 키 교환 방식에 따라 클라이언트와 서버는 각자의 비밀키와 상대방의 공개키를 조합하여 동일한 값을 계산하게된다.

간단하게 과정을 보면,

클라이언트의 키 쌍 : (a,g^a)

- a: 클라이언트의 비밀키(랜덤생성)
- g^a : 클라이언트의 공개 키(수학적 계산을 통해 생성)

서버의 키 쌍 : (b,g^b)

- b : 서버의 비밀키
- g^b : 서버의 공개 키

여기서 g는 양측이 합의한 공통 기반 값..이라는데 이건 TLS1.3스펙에서 미리 정해진 값이라고도 한다.. 그리고 큰 소수 p를 정한다고 함

어쨌든 클라이언트와 서버는 각자의 공개키를 상대방에게 전송하는데 비밀키는 절대 네트워크를 통해 전송하지 않는다.

이제 각자 서로의 공개키를 받으면 공유 비밀키를 계산하는데,

클라이언트 측

Shared Key = (g^b)^a mod p = g^(ab) mod p 를

서버 측

Shared Key = (g^a)^b mod p = g^(ab) mod p

Shard Key 값은 클라이언트와 서버가 계산한 값이 동일하며, 이 값이 Shared Secret Key가 된다.

이것을 바로 세션키로 사용하지 않고 해시함수(ex: sha-256)를 사용하여 세션키를 더 안전하고 고유하게 만든다고 함

SHA-256은 단방향 해시함수로.. 256비트의 고정된 문자열로 뱉어내는데 256bit는 1800경^4 가 될만큼 큰 수라고 한다.

여기서 새롭게 알게된 사실은, HTTPS 통신에서 SSL인증서를 사용해서 나는 SSL이 적용되는줄 알았는데 TLS가 적용된다고 한다.

SSL에서 보안성과 효율성을 개선한게 TLS이고, RSA방식(비대칭키)를 사용하지 않는다고 함..
