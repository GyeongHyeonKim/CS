어플리케이션 계층에서 중요했던건, `HTTP`,`DNS` 였다.

App이라는 것은, OS가 제공하는 서비스를 사용하는 것이고 그 중 `TCP`,`UDP` 라는 것이 사용자 계층에 제공이 된다.

이것을 통해 다른 사용자 프로세스에게 정보를 보낼 수 있다.

`Transport` 계층은 어플리케이션이 전달하고자 하는 정보를 받아서 반대쪽 컴퓨터의 프로세스에게 전달하는것을 도와준다.

어플리케이션 계층에서 만들어진 데이터의 단위는 `Message`로,
HTTP Request,Response 처럼 사용자가 전달하고자 하는 것이다.

이 메시지가 전송계층의 `Segment` 라고 불리는 전송단위 내부로 들어가게 된다.

`Segment`는 메타데이터를 담은 헤더와 메시지를 담는 데이터 부분으로 구분이 된다.

또 이런 Segment가 3계층으로 내려가면 3계층 단위인 `패킷`을 구성하는 데이터 부분으로 들어가게 된다.

**개념적으로 TCP는 `Reliable`,`In-order Delivery`를 가능하게 해준다.**

`Reliable` 이라는 것은, 내가 보내는 메시지가 하나도 유실되거나 메시지가 수정되지 않고 전달된다는 것이고

`In-order` 라는 것은, 뒤죽박죽 섞이지 않고 순서대로 전달된다는 것이다.

참고로 패킷은 출발지부터 도착지까지 무수히 많은 라우터를 거쳐가는데, 이때 모든 패킷이 같은 경로로 가는게 아니다.

어떤 패킷은 빠르게, 어떤건 느리게 갈 수 있다.

패킷이 전달되는 도중에 만나는 라우터의 큐가 꽉찬 정도에 따라 달라지기 때문이다.

또한 `flow control`,`congestion control`을 제공하는데

`flow control`은 보내는 사람이 조절하는 속도이다.
얼마만큼 빠르게 / 느리게 보내야하는지에 대한 것이다.

이것은 상대방이 받아들일 수 있는 속도가 어느정도인가에 따라 달라진다.(상대방의 버퍼가 꽉 차있으면 보내봤자 의미없기 때문에)

`congestion control`은 현재 네트워크 상태를 파악해서 네트워크가 받아들일 수 있게 속도를 조절하는 것이라고 생각하면된다.

반면, **UDP는 아무것도 안해서 `unreliable`,`unordered delivery` **이다.

#### 멀티플렉싱과 디멀티플렉싱에 대해 설명해주세요.

---

**멀티플렉싱(MUX, Multiplexing)**

- 여러 개의 데이터 스트림을 하나의 통신 채널로 합쳐 전송하는 과정이다.

- 통신 채널의 대역폭을 효율적으로 활용 가능하다.

방식으로는,

1. **주파수 분할 멀티플렉싱(FDM, Frequency Division Multiplexing)**

각 데이터 스트림을 서로 다른 주파수 대역에 할당하여 동시에 전송하는 방식

2. **시간 분할 멀티플렉싱(TDM, Time Division Multiplexing)**

각 데이터 스트림을 일정한 시간 간격으로 분할하여 순차적으로 전송하는 방식

3. **코드 분할 멀티플렉싱(CDM, Code Division Multiplexing)**

각 데이터 스트림에 고유한 코드를 할당하여 동시에 전송하는 방식

**디멀티플렉싱(DEMUX, Demultiplexing)**

- 멀티플렉싱된 데이터 스트림을 수신하여 원래의 여러 개의 데이터 스트림으로 분리하는 과정

마찬가지로 3가지 방식이 있는데

1. **주파수 분할 DEMUX**

수신한 데이터 스트림에서 각 주파수 대역을 분리하여 원래의 데이터 스트림으로 복원

2. **시간 분할 DEMUX**

수신한 데이터 스트림에서 시간 간격에 따라 데이터를 추출하여 원래의 데이터 스트림으로 복원

3. **코드 분할 DEMUX**

수신한 데이터 스트림에서 각 데이터 스트림에서 고유한 코드를 사용하여 원래의 데이터 스트림으로 복원

주로 CDMA(Code Division Multiple Access)기술에 사용됨

각 데이터 스트림이 고유한 코드로 인코딩되기 때문에 각각을 쉽게 구분할 수 있다.

#### 배경지식

전송계층이 제공하는 가장 기본적인 기능인 `MUX`,`DEMUX`를 알아보자.

별게 아니라, 하나의 컴퓨터에 여러 프로세스가 있을것이고 각자의 소켓이 있을텐데 그것들이 나가는 통로이다.

여러개의 프로세스가 각자 정보를 가지고 하나의 통로(이더넷 / Wifi)로 나가는게 MUX이고 하나에서 온 것이 여러개로 나눠지는게 DEMUX이다.

전송계층은 소켓 인터페이스를 직접적으로 다루는 계층이니까.. MUX는 `sender` 측에서 이루어지고 DEMUX는 `receiver` 측에서 이루어진다.

MUX는 단순한데, 어디서 오던지 한 통로로만 나가면 된다.

하지만 DEMUX는 단순하지않다. 스트림을 분할한 뒤에 어느 소켓으로 보낼것인가에 대한 결정을 해야하기 때문이다.

이것은 바로 `Port Number` 를 가지고 판단하게된다.

이 Port Number는 전송계층의 헤더의 한 부분에 존재하게 되는데,
헤더에 Source Port 번호와 Dest Port 번호가 존재한다.

먼저, UDP가 DEMUX를 어떻게 하는지 살펴보면

![](https://velog.velcdn.com/images/sujipark2009/post/812d0d93-c20c-4888-bbaa-b80d0c317bff/image.png)

단순히 포트 번호만 보고 DEMUX가 이루어진다.
같은 포트번호면 같은 소켓으로 들어간다.

가령, 그림에서 오른쪽에 source port : 6428 / dest port : 5775 일 것이다.

그러나, TCP는 다른데 TCP의 경우 (source ip,source port,dest ip,dest port)이 4가지를 가지고 DEMUX를 한다.

![](https://velog.velcdn.com/images/sujipark2009/post/74e07f9e-7b84-40ae-9fee-af0321f44f54/image.png)

(source ip,source port) = (A,9157)인 세그먼트가 현재 (dest ip,dest port) = (B,80)으로 가는 상황이다.

C에서 출발한 세그먼트 (source ip,source port) = (C,9157) 또한 (B,80)으로 가고 있다.

둘 다 80번 포트로 가지만, 이 요청은 Source IP가 다르기 때문에 서로 다른 TCP요청으로 처리되고 결국 다른 소켓에서 처리하게 된다.

포트는 같으나 이걸 처리하는 소켓이 다르다는 것이다.

이건 앞전에 정리했었던, 한 포트에 여러 소켓이 생성될 수 있는것과 같은 원리인데

서버 입장에서 80번 포트에 `리스닝 소켓`을 열고있고 거기에 클라이언트가 TCP 연결을 시도하면 3way handshaking과정에서 새로운 `연결 소켓`이 할당이 된다.

이 `연결소켓` 은, 위에서 살펴본 4가지 정보(4-tuple)을 통해 식별이 되기에 저렇게 각자 다른 소켓으로 연결이 되는 것이다.

...

아까 UDP가 아무런 기능을 제공해주지 않는다고 했지만 MUX,DEMUX 정도는 제공해주고 있던 것이다.

그런데 어떤 계층에서 특정 기능을 수행하기 위해서는, 그 기능을 수행하기 위한 정보가필요한데 그 정보가 헤더에 적히게 된다.

UDP에게 MUX,DEMUX를 위한 정보는 source port와 dest port였다.

UDP는 아무런 기능이 없기때문에 가볍지만, reliable한 서비스는 이루어지지 않는다.

주로 DNS에 UDP를 사용하는데,

DNS는 사실 본격적으로 데이터를 주고받기 전 사이트를 찾아가는 과정인데 여기를 TCP로 하게되면 3-way handshaking부터 오버헤드가 발생하므로 UDP로 처리하는것이 맞는 것 같다.

사실 유실되서 오류가 생겨도 바로 새로고침해서 또 요청하면 그만일거니까..

UDP의 헤더를 살펴보자.

![](https://velog.velcdn.com/images/sujipark2009/post/4a6bba22-8074-4d40-8127-a81a2d2f2ae0/image.png)

(source port,dest port,length,checksum,data) 사실 별거 없다.

진짜 중요한 부분은 바로 DATA 부분이고 이게 바로 내가 전달하고자 하는 메시지 자체이다.

Header는 사용자 입장에서 봤을 때 아무 쓸모없는 정보이다. 일종의 overhead로, 작으면 작을수록 좋다.

결국 헤더에는 정말 필요한 Meta data만 들어가게 된다.

UDP는 필드가 4개뿐이네? => 별 기능을 수행하지 않겠구나 하는 생각이든다.

포트번호는 우선 DEMUX할 때 사용하고, `Checksum` 은 정보가 중간에 변형이 있었는지 없었는지 파악할 수 있게 해준다.

UDP는 receiver측에서 checksum을 보고 에러가 있었다면 올려보내지 않고 버리게 된다.

정리하면, UDP가 하는일은 MUX,DEMUX, Error Detection 정도가 있다.

...

TCP가 제공하는 Reliable Data Transfer을 이해하기 위한 빌드업을 해보자.

사용자 관점에서보면 TCP는, TCP소켓을 열어서 메시지를 보내는데 내가 전달하는 메시지는 무조건 전달된다!! 는 환상을 제공해준다.

실제 underline network는 unreliable한데.. 그런 환상을 심어주는게 바로 TCP다.

전송 에러,유실 이 2가지를 극복하면 reliable한 환상을 줄 수 있게되므로 이 2가지를 극복해야한다.

Reliable Data Transfer(RDT)라는 프로토콜을 디자인해보자.

단순하게 sender는 패킷을 보내고 receiver가 그것을 받았다는 100% 확신이 있을때에만 다음 패킷을 보낼것이다.
(실제 TCP는 하나씩 보내는게 아니라 여러개를 한번에 보내긴 하겠지만..)

**RDT 1.0** : underline이 reliable하다. (패킷 유실 없고 에러도 없고)

이 경우, 보내는 족족 도착할 것이니 특별히 할 일이 없다.

그냥 사용자로부터 데이터를 받으면 패킷으로 만들어서 보내면 끝이다.

**RDT 2.0** : 이제는 underline network가 패킷에러가 발생할 수 있다고 해보자.(패킷 유실은 없음)

sender가 패킷을 보내는데 에러가 발생한다?

친구들과 통화를 한다고 해보자. 친구와 통화를 하고 끊는 이 과정에 우리가 인지하지 못하는 패킷에러를 극복하는 메커니즘이 숨어있다.

바로 통화중에 **"어..어..어?..어!!" 이런식으로 `Feedback`을 주는 것이다.**

결국 패킷에러가 있을때에는, Feedback(Acknowledge)가 필요하다.

이러한 피드백이 가능하기 위해서는, `Error Detection`이 중요하다.

receiver가 패킷을 받고 해석이 가능한 경우 `ACK`, 불가능한경우 `NAK`를 보낸다.

이런 `Error Detection`을 바로 `checksum` 에서 하는 것이다.

이 ACK,NAK에 따라서 재전송 유무를 결정하게 된다.

결론적으로, 패킷에러가 발생하는 상황에서는 3가지가 필요한데

1. **Error Detection** => checksum을 사용

2. **Feedback** => ACK,NAK를 사용해서 잘 받았는지 못 받았는지 여부

3. **Feedback 결과에 따른 Retransmission 여부**

아직까지도 완벽하지는 않다.

만약 ACK,NAK 이 피드백 자체가 에러가 발생한다면 어떻게 할 것인가?
..
ACK인데 NAK가 온 경우라던지 혹은 그 반대의 경우..

실제로는 잘 받았는데 피드백이 오다가 끊겨서 `sender` 입장에서는 받았는지 못 받았는지 모르는 상황이 있을 수 있다.

이럴때 방법은 ?

- **무조건 재전송하기**

그런데 이렇게 하면, 제대로 받았는데도 또 보내는 경우도 있기에 `receiver` 입장에서는 들어온 패킷이 기존것과 같은 것인지 다른 것인지를 알 수 없다.

그래서 그걸 판단할 근거가 필요한데, 그것이 바로 `Sequence Number` 이다.

모든 패킷에 `SEQ` 가 붙어있어서, receiver는 "아~ 이거 재전송한거네~" 하고 알 수 있다.

이미 받아들인 패킷이면 무시하고, 아니면 받아들인다.

그럼 SEQ를 어떻게 표현할까?

우리 목적은, 아까 말했듯이 헤더를 최소한으로 만드는거였다.

=> 가장 최소의 SEQ는 0,1의 2가지만 있으면 된다(1bit)

아~ Reliable transfer를 위해서는 무언가 `state`를 기억하고 있어야하네.. 라는 생각이든다.

여기서 더 발전하면 ACK만 사용해서도 구현할 수 있다.

NAK를 보내지않고 무조건 ACK를 보내는데 ACK에도 SEQ를 달아서 보내는 방법이 있다.

이 SEQ는 내가 마지막으로 받은 SEQ를 보내면 되는데 Sender의 입장에서는 이 SEQ를 보고 똑바로 받았는지 안받았는지를 확인할 수 있다.

...

### TCP와 UDP의 차이점에 대해 설명해 주세요.

---

**TCP(Transmission Control Protocol)**

연결지향, 신뢰성을 보장하는 데이터 전송 프로토콜

**장점**

- 연결 지향성 : 데이터 전송 전후에 연결 설정 및 해제

- 데이터 전송의 신뢰성
- 패킷 손실이 발생하면 재전송
- 순서가 뒤바뀐 패킷을 재정렬
- 흐름제어 및 혼잡제어로 전송 속도 조절

**단점**

- 전송속도와 오버헤드

- 신뢰성있는 데이터 전송을 위해 헤더에 추가정보를 포함

- 연결 설정 및 해제과정, 흐름 제어 등의 메커니즘이 발생하는 오버헤드

**UDP(User Datagram Protocol)**

비연결성, 비신뢰성 데이터 전송 프로토콜

- 연결없이 데이터를 전송하는 **비연결형 프로토콜**

- 비신뢰성 있는 데이터 전송을 제공 => 패킷 손실이 발생하거나 순서가 뒤바뀌어도 재전송이나 정렬 과정이 없음

**장점**

- 최소한의 헤더 정보와 오버헤드로 데이터를 전송하여 전송 속도가 빠름
- 실시간 서비스나 빠른 속도가 필요한 애플리케이션에서 선호

- 실시간 서비스, 스트리밍, 온라인 게임, VoIP 등 빠른 전송속도와 낮은 지연시간이 중요한 서비스에서 사용한다.

### 흐름제어 / 혼잡제어 / 오류제어에 대해 설명해주세요.

---

패킷 에러가 발생하는 경우, Error Detection,feedback,retransmission,sequence number 이 4가지가 사용이 된다.

패킷 유실의 경우에는 timeout을 사용하여 응답이 없을 경우 재전송을 하게 되는데,

아~까 위에서 살펴본 RDT프로토콜은 성능이 매우 안좋다.

왜냐하면 하나씩 하나씩 보내고 응답을 받고 보내고 이러니까..

근데 실제로는 여러개를 한번에 보내고 응답을 받아야 한다.

매번 전송한 패킷에 대한 응답을 받아야 다음 패킷을 전송하는 방식을 **Stop and Wait** 방식이라 하고

지금부터 여러개를 던지는 방식인 **`Go-back-N`,`Selective Repeat`** 을 알아보자.

**Go-Back-N**

가장 중요한건, 이제는 한꺼번에 많은 패킷을 쏟아부을 것이라는 것.

그럼 한번에 얼마나 쏟아부을지 기준이 있어야 하는데, 그게바로 `window` 이다.

0 1 2 3 4 5 6 7 8 9 10 11 12 ... 이렇게 있고

window size가 4라면, [0,1,2,3] 패킷을 한번에 보내는 것이다.

여기서 ACK의 특징은 `Cumulative ACK` 라는 것이다. 뭔가 쌓는다는 느낌.

ACK 11의 의미는, "나 10번까지 완벽하게 받았으니 11번을 달라" 는 뜻이다.

[0,1,2,3] 각 패킷은 `Timer`를 가지고 있는데

만약 ACK를 받기전에 0번 패킷의 Timer가 터지게되면, **Window 안에 있는 모든 패킷을 재전송하게 된다.**

Go-Back-N의 특징은, **receiver가 멍청하다는 것이다!**

receiver는 자기가 받아야 할 Sequence Number만 기다리고 있다.

0번 SEQ가 오면 ACK 0을 보내고 지금부터는 무조건 SEQ 1번을 기다린다.

이제 sender 가 1,2,3... 이렇게 보낼건데 만약 1번이 느려터져서 2번 3번이 먼저 도착하게된다면?

receiver는 지금 1번을 기다리는데 2번이 먼저왔다? **그럼 2번을 버리고 ACK 0을 다시 보내게 된다.**

그제서야 1번이 오면 ACK 1을 보내고 이제 2번만을 바라보며 기다리게 된다.

근데 2번은 이미 버렸으니.. 2번 패킷이 `Timeout`이 날 것이고 나머지 패킷이 싹 다 재전송 될 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/249da05c-66e6-49d6-a338-a9c30b84840f/image.png)

그림을 보면, sender가 0,1,2,3을 한꺼번에 보냈다.

receiver가 0번 잘 받고 ACK 0 날리고, 1번 잘 받고 ACK 1날리고

2번이 Loss된 상태에서 3번 패킷이 도착하니 receiver는 3번을 버리고 ACK 1을 보낸다.

여기서 sender는 [0,1,2,3] 에서 ACK 0 이 왔으니, 윈도우를 한칸 이동해서 [1,2,3,4] 가 되고 4번 패킷을 보내게 된다.

또 ACK 1이 오면 [2,3,4,5] 로 옮기고 5번 패킷을 보낸다.

그런데 지금 receiver는 2번 패킷만 기다리고 있으니.. 4번,5번을 다 버리고 ACK 1을 보내게 된다.

근데 1번은 이미 윈도우 밖에 있고 윈도우를 옮기며 1번의 `Timer`는 제거했으니 sender는 아무 영향을 받지 않는다.

그러다가 2번패킷에서 Timeout이 터지면, 현재 윈도우 안에있는 [2,3,4,5] 패킷을 다시 보내게 된다.

[2,3,4,5] 가 가게되면 ACK 2,ACK 3,ACK 4,ACK 5,... 이런식으로 오겠지?

좀 더 큰 그림을 그려보면, 만약에 `sender`와 `receiver` 사이에 아무 loss가 없고 평화롭다고 가정하면.. 윈도우는 쭉 진행되어서 오른쪽으로 나아갈 것이다.

근데 loss가 터지면, 그것을 기준으로 다시 돌아와서 또 보내야하기 때문에 `go-back-N` 이라고 불리는 것이다.

윈도우는 단순히 한번에 보내는 양을 의미하기도 하지만, 윈도우 안에 있는 패킷들은 버퍼안에 저장하고 있어야 하는 것들이다.

왜냐면, 윈도우 안에 있는것들은 `sender` 입장에서 아직 `receiver` 가 받았는지 안 받았는지 확신하지 못하는 것들이다.

윈도우 밖에 나간거는 받았는지 확신할 수 있어서 빠진것들임

**Selective repeat**

이 go-back-N 방식에서 마음에 안드는점은.. 유실된건 6번인데 6번때문에 [6,7,8,9] 전체를 싹 다 보내야 한다는 것이다.

실제 윈도우 사이즈는.. 엄청 크겠지? 근데 하나 유실되었다고 해서 전체를 다 보내는건 말이 안된다.

그래서 이것을 개선한 것이 `selective repeat` 이다.

벌써 이름에서 유실된것만 재전송한다는 느낌에 엉덩이가 들썩거린다.

그러기 위해서는, ACK의 의미가 `Cumulative ACK` 면 안된다.

ACK 11의 의미는, "11번을 잘 받았다!!" 라고 해석해야한다.

예를들어, `receiver` 가 2번 패킷을 기다리고 있으나 3번이 들어왔다면, 2번을 채울 떄 까지 3번을 버퍼에 저장해야한다.

3번을 받았으면 ACK 3을 받았다고 날려줘야한다.

마찬가지로 윈도우 사이즈가 4라고 해보자.

![](https://velog.velcdn.com/images/sujipark2009/post/a7b2abb9-33fb-4e92-a3f5-d1e5f9034fa5/image.png)

`sender` 가 한꺼번에 [0,1,2,3] 을 보냈다.

지금 보면, `receiver` 에게 0번과 1번은 도착했는데 2번이 유실되고 3번이 온 상황이다.

그럼 3을 버퍼에 따로 저장하고 ACK 3을 보내게 되는 것이다.

만약 go-back-N이었으면, 3을 버리고 ACK 1을 보냈을 것이다.

`sender`의 입장에서는 [0,1,2,3] 에서 ACK 0을 받으니 [1,2,3,4] 로 윈도우가 옮겨가며 4번 패킷을 보내고

또 ACK 1을 받으면 [2,3,4,5]로 옮겨가며 5번 패킷을 보낸다.

그리고 ACK 3이 왔으면, 3번 패킷의 `Timer` 를 제거한다.
이렇게 있다가 2번 패킷의 `Timer` 가 터지면 2번만 재전송하게 된다.

그럼 2번을 기다리던 `receiver` 는 버퍼에 2번이 들어오게 되고, 이것을 `receiver` 의 Application layer에 올려주면서 ACK 2를 응답으로 보내게 된다.

이제 `sender` 는 2번을 받았으니 또 [3,4,5,6] 으로 윈도우를 옮긴다.

지금 유실된 패킷이 2번패킷인데, 재전송 된 패킷 또한 2번이다.
즉, **유실된 패킷만 보낸다**는 것이 핵심이다.

근데, **실제로 이것을 사용하는가?** 는 그렇지 않다.

왜냐하면 `Selective repeat` 은 각 패킷에 `Timer` 를 달아야 하고, 실제 윈도우 사이즈는 엄청 클 것이기 때문에, 각 패킷 모두에게 `Timer` 를 다는건 말이 안된다.

그래서 실제로는 윈도우를 대표하는 `Timer` 를 하나 두고, ACK도 Cumulative ACK 방식을 사용한다고 하는데..

그리고 사실 이 Go-back-N과 Selective repeat이 바로 **TCP 흐름 제어 및 오류제어** 기법이다.

**흐름 제어(Flow Control)**

송신 측과 수신 측 간의 데이터 전송 속도를 조절하여 수신 측의 처리 능력을 초과하지 않게 하는 기법

**Stop and wait**

매번 전송한 패킷에 대한 응답을 받아야만 다음 패킷을 전송

**슬라이딩 윈도우**

![](https://velog.velcdn.com/images/sujipark2009/post/7b7d1552-5d3e-4d38-b057-174135e68b02/image.png)

수신측에서 설정한 윈도우 크기만큼 송신측에서 패킷 각각에 대한 확인 응답 없이 세그먼트를 전송

- 최초 수신자의 window size만큼 패킷을 전송. => window size는 헤더에 존재

- 수신자는 ACK를 보내면서 윈도우를 옆으로 옮김 => 송신자는 바뀐 윈도우 위치 확인

- 송신자가 바뀐 윈도우만큼 세그먼트 전송

여기에 go-back-N과 Selective repeat이 속한다.

참고로 흐름제어에는 이 둘을 섞어서 사용한다고 한다..

![](https://velog.velcdn.com/images/sujipark2009/post/071156cb-5bde-4ec4-aa1c-e3977f92744a/image.png)

헤더에 어떤 정보가 있는지를 살펴보면,

1. source port,dest port => 각각 2바이트. 즉, 포트번호의 범위가(0~65535)

2. sequence number
3. ACK number
4. flag
5. checksum
6. receive window(지금 나의 receive window에 얼마만큼 있는지 알려주기 위해 존재)

A는 client, b는 echo server(A의 메시지를 그대로 COPY해서 보내는 서버)라고 해보자.

`C` 라는 Character를 보낸다고 하면,

TCP에서 사용하는 `SEQ` 번호는 DATA부분의 바이트 중 가장 첫번째의 순서번호이다.

예를들어 보내려는 데이터가 100B라고 한다면

이 중 일부(0~9)를 DATA로 내렸다고 한다면, 그때 SEQ 번호는 가장 앞 번호인 `0` 부터 시작하고,

그 다음 10개를 또 자르면 SEQ 번호는 10이 되는 것이다.

그리고 TCP에서 사용하는 ACK는 `Cumulative ACK` 이다.

![](https://velog.velcdn.com/images/sujipark2009/post/a4c1934a-698b-4a0a-9145-de3bab8ba0ec/image.png)

A에서 SEQ=42,ACK=79,C를 B에게 보냈다면

B의 입장에서는 42번 패킷인 C를 받았으니 이걸 어플리케이션 계층으로 올리고, 42번까지 받았으니 43번을 달라는 의미인 ACK=43을 피드백으로 보낸다.

또, B가 보낼 데이터의 SEQ는 79여야 하는데, 왜냐하면 A가 보낸 ACK=79라는건 A가 78번까지 받았고 79번을 필요로 한다는 의미이기 때문이다.

즉, SEQ=79,ACK=43,C를 응답으로 보내게 되는 것이다.

A와 B사이에서 패킷이 유실이 된다면, 그것은 `Timer`를 통해 감지한다고 했다.

`Timer` 가 터지기 전에 Feedback이 오면 OK이고 아니면 유실된 것이다.

그렇다면, `Timer`의 시간을 몇으로 설정해야할까?

`Timer` 를 작게하면 Recovery는 빠른 대신에 네트워크에 Overhead를 줄 수 있고.. 크게하면 그 반대가 되는데 어떻게 적당한 수를 정해야할까?

`Segment` 가 갔다가 응답이 돌아오는 시간을 `RTT(Rount Trip Time)` 이라고 하는데

RTT보다 시간이 더 걸리면 유실이고, 덜 걸리면 OK라고 생각하면 되지 않나? 라는 생각에서 출발해보자.

A -> B로 가는데 모든 세그먼트에 대해 RTT가 고정이 되어있다면 좋겠으나 그렇지 않다.

매번 지나가는 경로가 다를거고 혹시나 같은 경로를 지나가더라도 라우터의 `Queing delay` 때문에 RTT가 매번 다를 수 밖에 없다.

그래서 RTT를 통해 `Timeout` 을 정하기가 쉽지가 않다.

그래서 대표할 수 있는 RTT를 찾아야 하는데 그게바로 `Estimated RTT` 이다.
대충 이전까지의 값을 보정한 가중평균을 계산한 RTT값을 사용한다.

근데..

![](https://velog.velcdn.com/images/sujipark2009/post/039a3cde-bbfb-421e-b019-463eac660163/image.png)

이렇게 편차가 있기 때문에

![](https://velog.velcdn.com/images/sujipark2009/post/e27a2432-3595-47d1-87a9-7d5500a52862/image.png)

Margin을 더한 저런 외국어를 사용해서 정한다고 한다.

아~ 그렇구나 하고 넘어가자.

**TCP의 reliable data transfer**

![](https://velog.velcdn.com/images/sujipark2009/post/edeaccea-2731-46db-aff6-03cc67b0ab5c/image.png)

대충 왼쪽에서는, A가 B에게 92~99번 데이터를 담은 세그먼트를 보냈고 B가 응답으로 ACK 100을 보냈는데 그게 유실된 상황이다.

A에서는 timer의 timeout이 생겨서 재전송을 하게 된다.

오른쪽에서는 데이터를 더 많이 보낸다.

92~99, 100~ 119까지 보낸다.

B는 잘받아서 ACK 100,ACK 120을 보낸다.

근데 이 ACK들이 도착하기 전에 A의 타이머가 터져서 재전송하는 상황이다.

B는 120번을 기다리는데 다시 92~99가 날아오니까 무시하고 ACK 120을 보내게 된다.
A는 ACK 120이 날아오니까, "아 그럼 119번까지는 받았네?" 하고 Send buffer를 싹 비우고 timer를 제거하게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/ca121aac-0141-4ce1-b54a-a97277170ac9/image.png)

앞의 ACK 100 이 유실되었지만 두번째 응답인 ACK 120이 A에게 전송되어서 92~99에 대한 ACK가 오지 않았지만, "119까지 받았구나!" 인지하고 A는 전송을 완료했다고 생각하게 되는 상황이다.

근데 이렇게 하다보니까.. TCP가 더 똑똑해지면 좋겠다는 생각이 든다.

데이터를 받을때마다 ACK를 보낼 필요가 있을까?

어차피 한꺼번에 날아올건데 마지막꺼에 대한 응답만 보내면 되지않을까?

그래서 `Delayed ACK` 를 하라고 TCP에서 권장하고 있다.

우리는 `Timer` 가 터져야만 세그먼트의 유실을 인지하는데, 그 시간이 너무 오래걸린다는 것이다.

`Timer` 가 터지기 전에 패킷 유실을 판단하는 방법은 없을까?

A가 세그먼트 100개를 한꺼번에 보낸다고 생각해보자.(0~99번)

근데 10번째 세그먼트만 유실되었다고 생각해보자.

원래는 `Timer`가 터져야만 유실을 알 수 있는데 , 이떻게 더 빠르게 인지할 수 있을까?

10이 유실되었다면, 응답으로 ACK 1,2,3,4,5,6,7,8,9,10,10,10,...,10,10 이런 응답이 오겠지?

그래서 receiver buffer에는 10빼고 나머지 11,12,13.. 이런것들로 꽉 차있을 것이다.

그래서 TCP에서는 ACK 10을 받고, 10,10,10 3개를 연속해서 받으면 **유실되었다고 판단해도 좋다** 고 한다.

이게 바로 `Fast Retransmit` 이라 불리는 메커니즘이다.

원래는 타이머가 터질 때까지 가만히있는데, 3연속 같은 ACK가 오면 유실되었다고 판단하면 된다.

사실 꼭 필요한 기능은 아니지만, 더 빠르고 효율적으로 동작하도록 하기 위한 최적화 방법이라고 함.

ACK 10을 받고 10,10,10이 오면 재전송하는거니까 총 10이 4번 오는것이다.

**Flow control**

TCP에서 가장 중요한 기능 3가지는,

- Reliable Data Transfer

- Flow control

- Congestion control

인데, flow control은 너무 간단하다.

A와 B가 데이터를 주고받는데, 각자 자기 자신이 보내는 데이터의 속도를 조절할 수 있다는 것이다.

내 마음대로 조절할 수도 있지만, 받는쪽의 버퍼를 고려하여 보낼 수 있다.

A,B 둘 다 TCP Connection을 맺으면, 각자의 send buffer, recv buffer가 생기게 된다.

recv buffer는 순서에 맞게 데이터를 넣기 위해서 존재한다.

소켓에서 read() 시스템 콜 API를 통해 recv buffer를 읽어서 Application layer로 올리게 된다.

만약, recv buffer의 빈 공간에 조금밖에 없으면 sender가 아무리 많이 보내도 의미가 없다.

receiver가 받을 수 있는 만큼 보내야 의미가 있는 것이다.

이것이 바로 `Flow control` 이다.

흐름제어는, `receiver-driven` 이라고 할 수 있는데
receiver가 빈 공간이 얼마나 있다고 알려줘야 sender가 보낼 수 있기 때문이다.

이 정보는 TCP 헤더의 `recv buffer size` 라는 공간에 정보가 담겨서 가게 된다.

내가 얼마만큼 빈 공간이 있는지 알려주게된다.

flow control은 이렇게 직관적이고 간단하지만 매우 중요한 기능이다.

**Q. flow control은 보내는 속도를 조절하는 것인가 / 양을 조절하는 것인가 **

속도는 100Mbps 이런식으로 표현되는데, 이 말 자체가 초마다 보내는 양을 의미하는 것이다.

보내는 양이 많다는게 바로 속도가 빠르다는 것이다. 그러니까 같은 말이라는 것

마이너한 이슈가 있는데..

만약 Application layer에서 recv buffer를 안읽고 있다고 해보자
그래서 빈 공간이 없다면 헤더에 빈 공간이 0이라고 해서 보내질 것이다.

그럼 sender는 빈 공간이 없으니까 보내지 말아야하는데.. 이런 상황에서

sender(A)는 안보내고있다가 대체 언제 보내야할까?

B의 recv가 비었는지 아닌지 A는 어떻게 알 수 있을까..

이런 `corner case`가 존재한다.

실제 이런 문제를 해결하는 방법은, 만약 응답이 왔는데 빈 공간이 0이라면 A는 가만히 있는게 아니라 주기적으로 segment를 보내는데 segment의 DATA부분은 1B이거나 빈 상태로 B에게 보내게 된다.

주기적으로 보내야 B가 그거에 대한 ACK를 보낼거니까 비었는지 아닌지 확인할 수 있는 것이다.

**TCP 3way handshake**

참고로 handshake란.. 주고받기 라는 의미로

정보기술과 전기통신 및 관련분야에서 채널에 대한 정상적인 통신이 시작되기 전에 두 개의 실체 간에 확립된 통신 채널의 변수를 동적으로 설정하는 자동화된 협상 과정... 이라고한다.

채널의 물리적인 확립이 잇따르며, 정상적인 정보 전송 이전에 이루어짐.

위에서 흐름제어할때 이야기한 recv buffer같은것의 생성작업은 TCP Connection을 생성한 이후에 진행하게 되는데

Connection을 맺기위한 작업을 보자.

![](https://velog.velcdn.com/images/sujipark2009/post/ac74d548-220d-45a9-be04-4b1928eb63b9/image.png)

1. A -> B에게 헤더의 flag 부분으 SYN을 1로 바꿔서 전송한다.
   이때, DATA는 빈 상태이고 A의 SEQ #를 보내게 된다.
   SYN의 역할은, 나의 SEQ #을 알려주는 역할 + TCP Connection을 열고싶다는 의사표현이다.

A가 B에게 SYNbit=1,Seq=x 를 보냈다고 해보자.

2. B -> A에게 마찬가지로 SYN/ACK를 보내고 자신의 SEQ #와 A의 SEQ에 대한 ACK #을 보내게 된다.

B는 A에게 SYNbit=1, Seq=y
ACKbit=1, ACK=x+1 을 보내게 된다.

3. A -> B에게 ACKbit=1, ACK=y+1을 보내게 되고, 이 마지막 단계에서는 A는 데이터를 포함해서 전송할 수 있다.

이렇게 3번의 과정이 이루어진 이후에야 서로의 버퍼가 생성이 된다.
근데, 2번만 하면 충분하지 않을까? 라는 생각이 들 수 있다.

굳이 3번을 하는 이유는, 클라이언트와 서버 입장에서 생각해보자.

2-way를 했다면, 클라이언트 입장에서 "야~호" 를 했는데 반응이 온 것이고 서버 입장에서는 "야~호" 를 했는데 클라이언트에게서 응답이 없는 것이다.

그래서 서버 입장에서는 클라이언트가 받았는지 아닌지 확인할 수가 없다.

기억할 점은, 3번째 클라이언트의 ACK에는 데이터를 담을 수 있다는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/42e3e692-c322-4b62-9f72-2e3ee2040eb7/image.png)

이 그림에서 HTTP Request 안에는 ACK가 담겨있으면서 데이터가 같이 포함되어서 가는 것이다.

커넥션을 끊는것을 확인해보자.

![](https://velog.velcdn.com/images/sujipark2009/post/2d520b8c-c26b-4b0a-956c-9c7532389668/image.png)

1. A -> B : FIN

이는 A가 보낼 데이터는 다 보냈으니 연결 끊겠다!! 라고 하는 의사표현이다.

2. B -> A : ACK

OK

3. B -> A : FIN

클라이언트가 FIN을 보냈다고 해서 바로 끊는것이 아니라, 기존에 보내던 데이터를 다 보내면 그제서야 B는 FIN을 보내게 된다.

4. ACK

근데 왜 마지막에 Timed wait을 할까?

뭔가 `corner case` 가 있기 때문이다.

B에게서 FIN이 왔다는건, B가 보낼 데이터를 다 보냈다는 의미인데.. 왜 기다릴까?

만약 A가 마지막에 보내는 ACK가 유실되었다고 해보자
그럼 서버는 FIN을 보냈는데 ACK가 안와서 timeout이 되었으니 다시 보내게 된다.

근데 A가 이미 Closed를 해버렸다면 B는 보내봤자 timeout만 받게 된다.

그래서 A가 timed wait을 하고 A가 보낸 ACK가 만약 유실되었더라도 B가 다시 FIN을 보내고 ACK를 받을 수 있도록 하기 위함이다.

**Congestion control**

A와 B사이에 Network라는 무형의 Infra가 존재한다.

A가 B에게 보내는 데이터의 양은 B의 recv + 네트워크의 상태에 따라 좌우된다.

그럼 (Network의 한계,recv의 한계) 이 둘 중에 A는 어디에 맞춰서 데이터를 보내야할까?

recv는 10만큼 받을 수 있고, Network는 20만큼 처리할 수 있다면 recv에 맞춰야 한다.

반대라면 Network에 맞추고.

그래서 둘의 상태중에 더 나쁜쪽에 맞춰서 보내야한다.

우리는 recv의 상태는 알 수 있다(흐름제어를 통해).
그런데, Network의 상태는 우리가 알 수 있을까? 가 의문이다.

네트워크에는 주인이 없는 public한 영역이다.
이런 공용 Resource에 많은 컴퓨터들이 연결된 상태인데, 각 컴퓨터는 매 순간마다 데이터를 빨리 보내고 빨리 받기를 원한다.

그래서 모든 컴퓨터가 많은 데이터를 보내려 할 것이고 그래서 Network가 막히게 된다.

그럼 어떻게 해야할까?

TCP의 관점에서 보면, Network가 막히는 경우 TCP는 이 상태를 더 악화시키는 행동을 한다.

네트워크가 막히면 패킷이 잘 안가니까 TCP는 재전송을 하게 되고, 실제 보낼 데이터가 10MB였다면 이게 잘 안가니까.. 이걸 또 보내게 된다.

그래서 네트워크 상태가 계속 악화될 수 밖에 없다.
그래서 TCP라는 것은 네트워크가 막히면 무너질 수 밖에 없는 구조이다.

그래서 TCP가 제대로 돌아가려면 네트워크가 막히면 안된다.

안막히려면? 데이터를 마구잡이로 보내면 안되고 속도를 조절해야만한다.

핵심은, **TCP는 네트워크가 막히면 안되기 때문에 상태가 안좋으면 자기자신의 속도를 줄이게된다는 것**.

네트워크가 안좋아지면 데이터를 줄이고.. 반대면 올리고.. 까지는 OK
근데 네트워크의 상태를 어떻게 알 건데? 라는 의문이 존재한다.

크게 2가지 접근방식이 있다.

1. **Network-assisted Congestion control**

- 네트워크에서 나에게 정보를 준다.
- 라우터들이 각자의 큐나 현재 상태를 나에게 알려준다

- 꿈같은 이야기다.. 라우터는 바빠요

2. **End-to-End congestion control**

- 이게 실제 방식.
- 네트워크에 연결된 여러 호스트들이 네트워크 상태를 알아서 유추해서 줄이고 늘리고 하자.

- 근데 너무 무책임하다.. 뭘로 유추할까?

- 그게 바로 TCP의 SEQ,ACK 이런 정보.
- ACK가 안온다거나 느리게 온다..는 것은 뭔가 문제가 있다는 것
- 그래서 아주 정확하지는 않다.

결국에는 send buffer의 윈도우 사이즈를 늘리고 줄여가면서 보내야 한다.

다시 보면,

TCP는 네트워크로부터 직접적인 피드백은 없지만 상대편의 피드백은 있기 때문에 그것으로부터 네트워크 상태를 추론한다고 했다.

처음부터 막 보내면 터질 수 있으니까.. 조금씩 조금씩 보내야한다.

TCP는 3가지 `Phase` 로 이루어지는데

`Slow Start`

- 조금씩 보내면서 시작하는 것.

- 근데 조금씩 보내다보면 문제점은 ?
- 패킷을 1개..2개..3개.. 이런식으로 보낸다고 치자
- 근데 네트워크가 사실 지금 100,000개의 패킷을 처리가능하다고 하면 1개씩 보내서 언제 저 지점에 닿을까?

- 그래서 1개,2개,4개,8개,.. 이런식으로 증가시켜가는 과정을 `Slow start` 라고 한다.

- 사실 증가하는 속도는 `Exponential` 해서 전혀 느리지 않는데.. 네이밍이 그렇다.

- 증가시키다가 어느지점(Threshold)부터는 주의해야한다.
- 그 지점 이후에는 linear하게 증가시켜 나간다.

- 그 지점이 바로 `additive increase` 단계이다.
- 늘리긴 늘리는데 linear하게 늘리는 것.

- 늘린다는 건 결국 전송하는 window의 size를 늘려나간다는 것이다.

- 패킷 loss를 탐지하게 되면 window size를 절반으로 줄이는데, 이것을 `Multiplicative decrease` 라고 한다.

왜 늘릴때는 linear하게 늘리다가 줄일때는 반토막을 낼까?

네트워크는 공유자원이고 막힐때는 모든 사람이 동시에 발을 빼야한다.

고속도로가 막히는데 1대 빼봤자 별 차이 없으니 모든 사람이 동시에 빠져야 한다고 생각하면 된다.

근데 지금까지 이야기한건 조금 개념적이긴 한데..

1개,2개,4개,.. 이렇게 `개` 라는 개념이 좀 막연하다.

이것은 **`MSS(Maximum Segment Size)`** 를 의미한다.

MSS는 500B로 한 세그먼트는 최대 500B를 가질 수 있다.

TCP Connection이 만들어지면, 버퍼가 2개 만들어지고(sender,recv), 실제로 데이터를 보내는 양은 window에 의해 결정되는데 window라는 것은 ACK를 받지않고 한번에 보낼 수 있는 size이다.

실제 1MSS,2MSS,4MSS,... 이런식으로 보내게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/20cdb84c-57f6-49f2-afc6-521d39590083/image.png)

저렇게 왔다갔다 하면서 보내게 된다.

대략적으로,

rate(전송속도) = CongestionWindowSize / RTT로 정의가 되는데, RTT는 그렇게 많은 변화가 없고, 실제는 `CongestionWindowSize`가 많이 변화가 된다.

CongestionWindowSize는 네트워크 상태에 따라서 결정이 되는데, 네트워크가 혼잡하면 작아져서 전송속도가 느려지고 한가하면 커지게 되므로 전송속도가 빨라지게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/42eed2d3-ea5a-4a23-b2ff-81b5209ab060/image.png)

**TCP Tahoe vs TCP Reno**

![](https://velog.velcdn.com/images/sujipark2009/post/af0150b2-056a-46da-b2c3-02f706802080/image.png)

x축은 시간이고, y축은 잘못되어있는데.. congestion window size이다.

Tahoe를 보면 window 사이즈를 증가시켜 나가다가 threshold를 넘으면 하나씩 증가하게 된다.

그리고 패킷 유실이 탐지되면 threshold를 packet loss가 탐지된 지점의 절반으로 설정하고 다시 처음부터 시작한다.

Reno 라는것도 있는데

TCP에서 패킷 유실을 `Timer` 를 통해 감지했었다.
근데 더 정확하게 말하면, Time out이 발생했을 때 패킷 유실이라고 탐지했었다.

그리고 3 duplicate ACK를 받으면 패킷 유실이라고 말했었다(Fast retransmit)

근데 위의 2가지 유실상황에서 네트워크 상황이 서로 같을까?

1. Timeout일때 네트워크 상황

- 그 패킷도 안가고 다른 패킷도 안가고있는 상황
- 이 경우, 네트워크 상태가 안좋으므로 처음부터 Slow start

2. 3 duplicate ack를 받은 상황

- 다 잘 가는데 하나만 문제가 생긴 것
- 네트워크는 잘 운용되고 있음
- 이 경우에 대한 설계가 TCP Reno이다.
- 처음부터 Slow start를 할 필요는 없고, threshold부터 시작하도록 하자는 것

**첫 Threshold는 어떻게 잡아야 할까?**

답이 없다. Slow start해보고 터지는 순간의 절반으로 잡으면 된다.

지금까지의 배경지식을 가지고 다시 질문을 정리해보자.

#### TCP 헤더에 대해서 설명해주세요.

---

![](https://velog.velcdn.com/images/sujipark2009/post/363118dd-71cd-4db8-aeaf-6d9db06d8cd6/image.png)

**속성**

헤더는 TCP 패킷의 구성요소로, 패킷의 제어 정보를 포함

일반적으로 최소 20바이트의 크기를 가지며, 최대 60바이트까지 확장

**주요 필드**

Source port(16bit) : 송신자의 포트 번호. 수신자가 이를 받아서 답장을 보낼때 사용

Destination port(16bit) : 수신자의 포트번호. 송신자가 보내는 목적지.

Sequence Number(32bit) : 전송되는 데이터의 순서 번호. 수신자가 재조립할 때 사용

Acknowledgement Number(32bit) : 수신자가 다음에 기대하는 데이터의 SEQ 번호. ACK 플래그가 설정된 경우에만 유효

Data Offset(4bit) : TCP 헤더의 길이를 32bit 워드단위로 나타냄. 헤더와 데이터 부분을 구분하는데 사용

Flags (6bit) : TCP 연결의 제어를 위한 다양한 플래그들 포함.
주요 플래그로는 `URG`,`ACK`,`PSH`,`RST`,`SYN`,`FIN`.
해당 위치의 bit가 1이면 해당 패킷의 플래그가 설정된 것

Window size(16bit) : 수신자의 수신 버퍼 크기를 나타냄. 송신자가 전송 속도 조절 => 흐름제어에 사용

Checksum(16bit) : TCP 헤더와 데이터에 대한 오류검사. 수신자는 체크섬으로 패킷의 오류를 감지

Urgent Pointer(16bit) : URG 플래그가 설정된 경우에만 유효. 긴급 데이터의 위치

Options(가변길이) : 선택적인 TCP 옵션을 포함. 옵션은 MSS(Maximum Segement Size), 윈도우 스케일,타임스탬프 등이 있음

#### MTU란 무엇인가요?

---

**MTU(Maximum Transmission Unit)**

네트워크 상에서 한 번에 전송할 수 있는 최대 데이터 단위

**성질**

- 각 네트워크 계층과 링크 계층에서 사용되는 프로토콜과 매체에 따라 다르게 설정

- 데이터를 효율적으로 전송하기 위해 사용.
- 데이터가 나눠지지 않고 한 번에 전송되는 최대 크기를 결정.
- 전송 중인 데이터의 크기가 MTU를 초과하면, 데이터는 여러 개의 작은 패킷으로 나눠져 전송

**예시**

이더넷에서의 기본 MTU 값은 1500B로 설정

이더넷 프레임의 페이로드(데이터) 부분의 크기가 최대 1500B를 초과하지 않아야 한다.

페이로드 크기가 1500B를 넘어갈 경우, 데이터는 더 작은 크기의 여러 패킷으로 분할

**MTU 디스커버리(MTU Discovery)**

MTU가 크면, 네트워크 상의 다른 장비와 호환성 문제가 생기고 MTU가 작으면 데이터가 많이 분할되어 전송 효율이 낮다.

이런 상황을 조율하는 과정을 말한다.

#### HTTP는 왜 TCP를 사용하나요?

---

가장 중요한 것은 신뢰성과 순서 보장이다.

이러한 특성들은 웹 페이지와 리소스의 정확한 전송을 위해 필요한 요소이다.

HTTP/3.0에서는 QUIC를 사용한다.

**신뢰성**

패킷 손실 시 자동으로 재전송 요청 => 데이터 무결성 유지

**순서 보장**

TCP는 패킷의 순서를 제어하여 수신자가 재조립이 가능하다.

**흐름제어/혼잡제어**

#### QUIC는 왜 생겼을까요?

---

TCP/UDP는 OS레벨에서 구현되어있다.(소켓 기반이기에)

QUIC는 Application layer에서 구현되어 쉽게 사용할 수 있도록 디자인되어있다.

#### 본인이 새로운 통신 프로토콜을 TCP나 UDP를 사용해서 구현한다고 하면, 어떤 기준으로 프로토콜을 선택하시겠어요?

---

**기준**

신뢰성의 필요성 / 순서 보장 / 흐름 제어 및 혼잡 제어 / 연결 설정의 오버헤드 /
보안 요구사항

UDP의 경우 커스텀이 자유롭다.

#### Checksum이 무엇인가요?

---

**정의**

전달된 값이 변경되었는지 검사하는 값으로, 무결성을 보장하기 위한 것이다.

**성질**

간단하고 계산이 빠르게 널리 사용된다는 장점이 있으나, 강력한 오류 검출 기능을 제공하지는 않는다.

더 복잡한 오류 검출 및 수정 기법으로는 CRC(Cylic Redundancy Check),햄밍코드,리드-솔로몬 코드가 있다.

**작동원리**

- 송신 측에서 데이터를 비트 또는 바이트 단위로 분할

- 송신 측은 분할된 데이터를 사용하여 체크섬 값을 계산

이때, 가장 간단한 방법은 분할된 데이터를 모두 더하고 결과를 특정 비트수로 표현하는 것이다.

다양한 체크섬 알고리즘이 존재한다..

- 송신 측은 계산된 체크섬 값을 데이터 블록 또는 패킷에 첨부한다.

- 수신 측에서는 동일한 체크섬 알고리즘을 사용하여 체크섬 값을 계산한다.

- 첨부된 체크섬 값과 비교
  계산된 체크섬 값과 첨부된 체크섬 값이 일치하면, 데이터 전송이 정상적으로 이루어졌다고 판단.

그렇지 않으면, 오류가 발생한 것으로 간주하고, 재전송을 요청하거나 오류 처리를 수행

#### TCP와 UDP중 어느 프로토콜이 Checksum을 수행할까요?

---

TCP와 UDP 모두 헤더에 Checksum필드가 포함되어있다.

#### 그렇다면, checksum을 통해 오류를 정정할 수 있나요?

---

- 검출은 가능하지만, 정정은 불가능하다.
- 오류가 발견되면, 일반적으로 송신 측에 재전송을 요청하거나 오류 처리를 수행

- 오류를 자동으로 정정하는 기능을 제공하는 것은 FEC(Forward Error Correction)기법 (햄밍코드,리드-솔로몬 코드 등)

#### TCP가 신뢰성을 보장하는 방법에 대해 설명해주세요.

---

**순서 보장**

각 패킷에 일련번호(SEQ)를 할당하여 수신측에서는 이 번호를 기반으로 패킷을 재조립한다.

**오류 검출**

TCP헤더에서는 Checksum 필드가 포함되어있어 패킷의 무결성을 검증하고, 오류가 발견되면 패킷 재전송을 요청한다.

**재전송 메커니즘**

수신 측에서는 정상적으로 받은 패킷에 대해 ACK를 송신측에 보내어 패킷이 성공적으로 도착했음을 알린다.

송신 측에서 ACK를 받지 못하거나 일정 시간내에 받지 못하면 패킷을 재전송한다.

**흐름 제어**

수신 측이 처리할 수 있는 양만 전달

**혼잡 제어**

네트워크 혼잡 상황에서도 신뢰성을 보장

### 3-way handshake에 대해 설명해주세요.

---

TCP 통신을 이용하여 데이터를 전송하기 위해 네트워크 연결을 설정하는 과정

- 양쪽 모두 데이터를 전송할 준비가 되었다는 것을 보장.

- 정확한 전송을 보장하기 위해 세션을 수립

![](https://velog.velcdn.com/images/sujipark2009/post/5e6b0857-5d49-49e6-9c42-e03d85b4432b/image.png)

1. 클라이언트는 서버에 접속을 요청하는 SYN 패킷을 보냄

SYN/ACK 응답을 기다리는 SYN_SENT 상태

2. 서버는 SYN요청을 받고 클라이언트에게 요청을 수락한다는 ACK와 SYN flag가 설정된 패킷을 발송

- SYN_RECEIVED 상태
- 서버는 Listen 상태로 포트 서비스가 가능한 상태여야 함

3. 클라이언트는 서버에게 ACK를 보냄

- 클라이언트 상태가 ESTABLISHED
- 서버가 받으면 연결이 이루어지고 데이터가 오가게 됨 => 서버상태가 ESTABLISHED

#### ACK,SYN 같은 정보는 어떻게 전달하는 것일까요?

---

TCP Header의 Flags 필드에 각각의 비트를 조절

#### 초기 Sequence Number인 ISN을 0부터 시작하지 않고 난수를 생성해서 설정하는 이유?

---

- Connection을 맺을 때 사용하는 포트(Port)는 유한 범위 내에서 사용하고 시간이 지남에 따라 재사용하게 된다.

이에따라 두 통신 호스트가 과거에 사용된 포트 번호 쌍을 사용하는 가능성이 존재한다.

연결이 종료된 후, 시간이 지나 동일한 클라이언트와 서버가 동일한 포트번호로 다시 연결을 시도하는 경우, 만약 새로운 연결의 ISN도 0이라면 이전 연결의 지연된 패킷이 현재 연결의 패킷으로 오인될 가능성이 있다.

- 서버 측에서는 패킷의 SYN을 보고 패킷을 구분한다.
  난수가 아닌 순차적인 Number가 전송된다면 이전의 Connection으로부터 오는 패킷으로 인식할 수 있음

이런 문제가 발생할 가능성을 줄이기 위해서 난수로 ISN(Initial Sequence Number)을 설정

#### 두 호스트가 동시에 연결을 시도하면, 연결이 가능한가요?

---

`Simultaneous Open`

호스트가 동시에 서로에게 SYN 패킷을 보내면서 연결을 시도

**과정**

- 호스트 A와 B가 독립적으로 서로에게 SYN패킷을 보냄
- 각 호스트가 상대방의 SYN을 받으면, SYN/ACK 패킷을 보내고 상대방의 초기 시퀀스 번호를 확인

각 호스트가 상대방의 연결 요청을 인정하고, 이를 다시 확인하겠다는 것을 나타냄

- 각 호스트는 상대방의 SYN/ACK 패킷을 받고 이를 ACK패킷으로 확인

- 동시 열기는 기본적으로 TCP의 일반적인 3-way handshaking와 같은 순서로 진행되지만, 두 호스트가 동시에 시작

- 동시에 서버와 클라이언트 역할을 수행하려는 peer-to-peer 애플리케이션에서 사용

#### SYN Flooding에 대해 설명해 주세요.

---

일종의 DoS(Denial of Service)공격

TCP의 3-way handshake 연결 과정을 악용하여 서버의 자원을 고갈시키는 방법

**방법**

- 공격자가 대량의 SYN패킷을 서버에 보냄
  이 SYN패킷들은 소스IP주소가 조작된 가짜 주소를 가지고 있음

- 서버는 SYN/ACK 패킷을 가짜 주소로 보냄
  그리고 ACK응답을 기다리지만, ACK응답은 오지 않는ㄷ

- 서버는 이러한 반 완료된 연결을 일정 시간동안 기억하고 있어야 함
- 공격이 반복되면, 새로운 연결요청을 처리할 수 있는 서버의 능력이 점차 감소하게된다.

**예방**

SYN cookies,라우터에서의 패킷 필터링,더 빠른 연결 만료시간

https://brunch.co.kr/@alden/5 참고..

### 4-way handshakek에 대해 설명해주세요.

#### 패킷이 4-way handshake 목적인지 어떻게 파악할 수 있을까요?

---

TCP Header의 Flags 중 FIN이 1인 경우

#### 빨리 끊어야 할 경우엔,(즉, 4-way handshake를 할 여유가 없다면) 어떻게 종료할 수 있을까요?

---

`RST` 플래그를 사용하여 비정상적인 상황에서 연결을 강제 종료 가능

- RST(=RESET) 플래그가 설정된 TCP 패킷을 받으면, 수신 측은 즉시 해당 TCP연결을 종료하고 관련된 모든 자원을 해제

상대방에게 어떤 추가적인 응답 없이 연결을 즉시 닫는 것을 의미.

- 강제적인 연결 종료는 네트워크의 다른 부분에서 예기치 않은 문제를 일으킬 수 있음

#### 4-way handshake 과정에서 중간에 한쪽 네트워크가 강제로 종료된다면, 반대쪽은 이를 어떻게 인식할 수 있을까요?

---

- 만약 한 쪽이 강제로 종료되면, 종료된 쪽은 더이상 ACK 패킷을 전송하지 않음

- ACK를 기다리는 측은 설정된 타임아웃 시간동안 ACK를 받지 못하면 패킷이 손실되었다고 판단

그리고 해당 패킷을 재전송한다

- 재전송된 패킷에 대해서도 ACK를 받지 못하면, 해당 연결이 끊어졌다고 판단한다

#### 왜 종료 후에 바로 끝나지 않고, TIMED_WAIT 상태로 대기하는 것일까요?

---

- 패킷의 손실이 발생하거나 통신자 간 연결이 제대로 해제되지 않을 수 있음

- Server에서 FIN 플래그를 전송하기 전에 전송한 패킷이 Routing 지연이나 패킷 유실로 인한 재전송 등으로 인해 FIN 패킷보다 늦게 도착하는 상황

Client는 Server로부터 FIN 플래그를 수신하더라도 일정시간동안 세션을 남겨놓고 잉여 패킷을 기다림

- TIME_WAIT 상태동안에는 해당 소켓의 주소를 다른 소켓에게 할당하는 것을 막는다

- Server는 FIN에 대한 ACK를 받지 못하면, 제대로 가지 않은 것으로 알고 다시 FIN을 보낸다.

Client는 FIN에 대한 ACK를 보냈을 때 기다리는 동안 FIN이 또 오면 연결이 제대로 해제되지 않은 것을 알 수 있음

**예시**

Client가 데이터 전송을 마쳤다고 하더라도, Server는 아직 보낼 데이터가 남아 있을 수도 있기 때문

#### 오류 제어기법(Error Control)

---

데이터 통신 과정에서 발생할 수 있는 오류를 검출하고, 필요한 경우 오류를 복구하는 메커니즘

**오류 검출방식**에는 Checksum,CRC(Cylic Redudancy Check)등이 있으며,

이는 오류가 발견되면 재전송 요청을 하거나 오류 처리 절차를 따른다

**오류 정정방식**은,

발생한 오류를 자동으로 복구하는 기법으로,

햄밍코드,리드-솔로몬 코드등의 FEC(Forward Error Correction)방식이 사용된다.

- 이는 오류 검출뿐만 아니라 오류 정정까지 가능한 방식이다.
