#### 분산 데이터베이스란 왜 필요하고, 어떻게 구축하나요?

---

**확장성**

- 단일 머신이 처리할 수 있는 데이터 양이나 트래픽의 한계를 넘어서는 경우

데이터와 처리를 여러 머신으로 분산

**내구성 및 가용성**

- 하나의 머신에 문제가 생겨도 다른 머신에서 데이터에 접근할 수 있도록 하는 것

**지연시간**

- 사용자가 전 세계에 분산되어 있을 경우

데이터를 사용자에게 가까운 곳에 위치한 서버에 저장함으로써 지연 시간을 줄일 수 있음

**방법**

샤딩, 레플리케이션, 파티셔닝

#### 파티셔닝이 무엇인가요?

---

- 파티션 키라고 불리는 특정 열(들)에 기반하여 테이블을 분할

**물리적으로 여러 테이블로 분산**하여 저장되지만, 사용자는 마치 **하나의 테이블에 접근하는 것과 같이 사용**할 수 있다는 점이 특징이다.

**특징**

- 대용량 테이블 또는 인덱스에 적용

- 성능 향상

- 관리를 간소화

- 데이터 접근을 최적화

**종류**

- 범위 파티셔닝(Range Partitioning)

파티션 키의 연속적인 범위에 따라 데이터를 분할

예시 - 날짜 범위에 따라 주문 테이블을 분할

- 리스트 파티셔닝(List Partitioning)

파티션 키의 명시적인 값에 따라 데이터를 분할

예시 - 지역별로 고객 테이블을 분할

- 해시 파티셔닝(Hash Partitioning)

파티션 키에 해시 함수를 적용하여 데이터를 분할

데이터를 모든 파티션에 고르게 분산하는데 유용

- 복합 파티셔닝(Composite Partitioning)

두 가지 파티셔닝 방법을 결합

예시 - 범위 파티셔닝을 먼저 적용하고, 각 범위 파티션 내에서 해시 파티셔닝을 적용

#### 파티셔닝을 하면 데이터베이스 성능이 향상되는 이유는 무엇인가요?

---

- 쿼리 성능 향상

특정 파티션에만 해당하는 쿼리는 해당 파티션만을 대상으로 실행

전체 테이블에 대한 스캔 없이 결과를 반환. 이를 **파티션 프루닝**이라고 함

- 데이터 관리 용이성

데이터의 관리를 용이하게 함

해당 파티션을 전체 삭제하면 빠르고 효율적으로 데이터를 삭제 - 행 단위로 데이터를 삭제하는 것보다 훨씬 빠름

- 데이터 로드 성능 향상

병렬 처리를 통해 파티션별로 데이터를 동시에 로드

- 고가용성

독립적으로 복구될 수 있음

하나의 파티션에 문제가 발생하더라도 다른 파티션에는 영향을 미치지 않음

#### 샤딩이 무엇인가요?

---

- 큰 데이터베이스를 여러 개의 작은 부분(샤드)으로 분할하는 과정

**동일한 스키마**를 가지고 있는 여러대의 데이터베이스 서버들에 데이터를 **작은 단위로 나누어 분산 저장**하는 기법이다.

**샤드**

- 독립적인 데이터베이스

- 자체적인 컴퓨팅과 스토리지 리소스를 가짐

- 각각이 하나의 서버 또는 노드에 위치할 수 있음

**특징**

- 데이터베이스의 확장성 문제를 해결하기 위한 전략 중 하나

대용량 데이터를 다루는 데 특히 유용

**장점**

`확장성`

수평 확장(Horizontal Scaling)으로 확장

추가적인 서버를 활용하여 데이터베이스를 확장

수직 확장보다 훨씬 비용 효율적

`각 샤드는 독립적으로 동작`

- 성능개선

하나의 샤드에서 발생하는 부하가 다른 샤드로 확산되지 않음

쿼리 응답 시간을 개선 / 전체적인 DB 성능 향상

- 고가용성

하나의 샤드가 실패하더라도 다른 샤드는 계속해서 서비스를 제공

**단점**

관리 복잡성 증가, 샤딩 키 선택의 어려움, 데이터 재분배의 어려움

#### 파티셔닝과 샤딩의 차이는 무엇인가요?

---

**공통점**

- 대용량의 데이터를 관리하고 처리하는 방법

**차이점**

`파티셔닝`

일반적으로 하나의 DB 내에서 이루어짐

데이터 관리와 쿼리 성능 향상에 초점

`샤딩`

여러 서버 또는 클러스터에 걸쳐 데이터를 분산시키는 것

데이터베이스의 확장성에 초점

#### RDBMS, NoSQL에서의 클러스터링/레플리케이션 방식에 대해 설명해 주세요

**RDBMS**

`클러스터링`

- 여러 서버가 하나의 데이터베이스를 공유하도록 구성하는 방법

**여러 개의 DB를 수평적인 구조로 구축하는 방식**이다.

클러스터링은 분산 환경을 구성하여 Single Point of Failure와 같은 문제를 해결할 수 있는 **Fail Over 시스템을 구축하기 위해**서 사용된다.

클러스터링은 **동기 방식으로 노드들 간의 데이터를 동기화**하는데,

![](https://velog.velcdn.com/images/sujipark2009/post/70aa2e52-4201-4d0e-bf41-b00aa90bfdcc/image.png)

1. 1개의 노드에 쓰기 트랜잭션이 수행되고 COMMIT을 실행한다.

2. 실제 디스크에 내용을 쓰기 전에 다른 노드로 데이터 복제를 요청한다.

3. 다른 노드에서 복제 요청을 수락했다는 신호를 보내고, 디스크에 쓰기를 시작한다.

4. 다른 노드로부터 신호를 받으면 실제 디스크에 데이터를 저장한다.

클러스터링은 DB들 간의 데이터 무결성 검사를 하는 동기방식으로 데이터를 동기화한다. 이러한 구조에 의해 클러스터링 방식은 다음의 장단점을 가진다.

**장점**

노드들 간의 데이터를 동기화하여 항상 일관성있는 데이터를 얻을 수 있다

1개의 노드가 죽어도 다른 노드가 살아있어 시스템을 계속 장애없이 운영할 수 있다.

**단점**

여러 노드들 간의 데이터를 동기화하는 시간이 필요하므로, Replication에 비해 쓰기 성능이 떨어진다

장애가 전파된 경우 처리가 까다로우며, 데이터 동기화에 의해 스케일링에 한계가 있다.

클러스터링을 구현하는 방법으로 Active-Active와 Active-StandBy가 있다.

Active-Active는 클러스터를 항상 가동하여 가용가능한 상태로 두는 구성 방식이고, Active-Standby는 일부 클러스터는 가동하고 일부 클러스터는 대기 상태로 구성하는 방식이다.

**특징**

- 데이터베이스의 가용성과 성능을 향상시키는 방법 중 하나

- 클러스터 내의 모든 노드는 동일한 데이터를 공유

- 각 노드는 동일한 데이터에 대해 독립적으로 작업을 수행

`레플리케이션`

- 데이터베이스의 데이터를 여러 위치에 복제하는 프로세스

- 데이터의 가용성을 향상

- 서버 장애 시에 데이터 손실을 방지

- 분산 쿼리 성능을 향상시키는 데 사용

- RDBMS에서는 주로 마스터-슬레이브 레플리케이션이 사용

마스터에서 변경이 발생하면 이 변경사항이 슬레이브에 복제

**여러 개의 DB를 권한에 따라 수직적인 구조(Master-Slave)로 구축하는 방식**이다.

레플리케이션에서 Master Node는 쓰기 작업만을 처리하며, Slave Node는 읽기 작업만을 처리한다.

레플리케이션은 **비동기 방식으로 노드들 간의 데이터를 동기화**하는데,

![](https://velog.velcdn.com/images/sujipark2009/post/c147d6d0-48ac-4a57-9b06-2656f5e41850/image.png)

1. Master 노드에 쓰기 트랜잭션이 수행된다.

2. Master 노드는 데이터를 저장하고 트랜잭션에 대한 로그를 파일에 기록한다(BIN LOG)

3. Slave 노드의 IO Thread는 Master 노드의 로그 파일(BIN LOG)를 파일(Replay log)에 복사한다.

4. Slave 노드의 SQL Thread는 파일(Replay Log)을 한 줄씩 읽으며 데이터를 저장한다.

레플리케이션은 Master와 Slave간의 데이터 무결성 검사(데이터가 일치하는지)를 하지 않는 비동기 방식으로 데이터를 동기화한다. 이러한 구조에 의해 레플리케이션 방식은 다음과 같은 장단점을 가지고 있다.

**장점**

DB 요청의 60~80%정도가 읽기 작업이기 때문에, Replication 만으로도 충분히 성능을 높일 수 있다.

비동기 방식으로 운영되어 지연 시간이 거의 없다

**단점**

노드들 간의 데이터 동기화가 보장되지 않아 일관성있는 데이터를 얻지 못할 수 있다.

Master 노드가 다운되면 복구 및 대처가 까다롭다.

**NoSQL**

`클러스터링`

- 데이터를 여러 노드에 분산시키는 방법

- 데이터의 가용성과 내구성을 향상

- 높은 병렬성으로 인해 성능이 향상

- NoSQL 데이터베이스는 일반적으로 클러스터링을 지원

각 노드는 독립적으로 작업을 수행

데이터는 노드 간에 분산되어 저장

`레플리케이션`

- 데이터를 여러 노드에 복제하는 방법

- 데이터의 가용성을 향상, 서버 장애 시 데이터 손실을 방지

- NoSQL 데이터베이스에서는 일반적으로 데이터가 여러 노드에 복제

다수의 복제본 중 하나가 손실되더라도 데이터는 여전히 사용 가능

#### 이러한 분산 환경에선, 트랜잭션을 어떻게 관리할 수 있을까요?

---

- 분산 시스템에서 트랜잭션이란

여러 노드에 걸쳐 실행되는 트랜잭션

**관리방법**

2단계 커밋(2-Phase Commit,2PC)

- 트랜잭션 처리를 두 단계로 분할

준비 단계 - 모든 참여 노드가 트랜잭션을 커밋할 준비가 되었는지 확인
커밋 단계 - 실제로 트랜잭션을 커밋하거나 롤백

**특징**

- 모든 노드가 준비되었을 때만 트랜잭션이 커밋

- 어느 노드라도 준비되지 않았다면 전체 트랜잭션이 롤백

3단계 커밋(3-Phase Commmit,3PC)

- 2PC의 단점을 해결하기 위해 설계

- 트랜잭션 처리를 세 단계로 분할

준비 단계 - 노드가 트랜잭션을 커밋할 준비가 되었는지 확인
준비 완료 단계 - 모든 노드가 준비를 완료했는지 확인
커밋 단계 - 실제로 트랜잭션을 커밋하거나 롤백

- 네트워크 장애가 발생한 경우에도 안정적인 트랜잭션 처리를 보장

#### 샤딩 방식은 무엇인가요? 만약 본인이 DB를 분산해서 관리해야 한다면, 레플리케이션 방식과 샤딩 방식 중 어떤 것을 사용할 것 같나요?

---

`레플리케이션`

- 데이터베이스의 복사본을 여러 서버에 분산시키는 방식

- 읽기 성능을 향상시키지만, 쓰기 성능에는 영향을 주지 않음

`샤딩`

- 각 샤드를 다른 서버에서 관리함으로써 읽기 및 쓰기 성능을 모두 향상

- 데이터의 일관성을 유지하는 데 더 복잡하고, 쿼리 최적화와 같은 추가적인 고려사항이 필요

#### 마스터,슬레이브 데이터 동기화전 까지의 데이터 정합성을 지키는 방법은 무엇이 있을까요?

---

- 일반적으로 마스터가 데이터의 기본 소스이며, 슬레이브는 이를 복제하거나 미러링

**동기 복제**

- 모든 변경사항이 마스터에서 슬레이브로 즉시 전송

슬레이브가 변경사항을 적용한 후에만 마스터가 트랜잭션을 완료

- 네트워크 지연 또는 슬레이브의 처리 지연으로 인해 전체 시스템의 성능에 영향

**비동기 복제**

- 마스터가 트랜잭션을 즉시 완료

슬레이브로 비동기적으로 전송

- 전체 시스템의 성능이 향상

- 슬레이브의 데이터가 항상 최신 상태가 아님

- 네트워크 문제나 슬레이브의 고장으로 인해 데이터 손실이 발생

**준 동기 복제**

- 동기와 비동기 복제의 중간 접근 방식

- 마스터는 변경사항을 슬레이브에 전송

최소한 하나 이상의 슬레이브가 변경사항을 확인하면 트랜잭션을 완료

- 데이터의 정합성이 어느정도 보장되면서도 성능에 미치는 영향을 줄일 수 있음

**트랜잭션 로그 전달**

- 마스터 DB에서 트랜잭션이 발생하면, 해당 트랜잭션에 대한 로그가 생성

트랜잭션 로그를 슬레이브 DB에 전달

슬레이브는 이 로그를 바탕으로 데이터를 업데이트

**체크섬**

- 데이터 집합에 대한 간단한 계산
- 마스터와 슬레이브 사이의 정합성 체크

#### 다중 트랜잭션 상황에서의 Deadlock 상황과, 이를 해결하기 위한 방법에 대해 설명해 주세요.

---

- 데이터베이스에서는 트랜잭션들이 서로가 잠그고 있는 리소스를 기다리는 상황에서 발생할 수 있음

- 발생 조건

**상호 배제(Mutual Exclusion)**

- 자원은 한 번에 하나의 트랜잭션만 사용할 수 있어야 한다.

**점유와 대기(Hold and Wait)**

- 트랜잭션은 이미 필요한 자원을 가지고 있으면서 다른 트랜잭션이 가지고 있는 자원을 기다릴 수 있어야 한다

**비선점(No Preemption)**

- 트랜잭션이 이미 잠근 자원을 강제로 뺏을 수 없어야 한다

**환형 대기(Circular Wait)**

- 트랜잭션들이 서로가 가진 자원을 순환적으로 기다리는 상황이 발생해야 한다.

해결 방법

- 예방

모든 자원을 한 번에 요청하도록 트랜잭션을 설계하면 점유와 대기 조건을 제거

- 회피

시스템이 트랜잭션에게 자원을 할당할 때, Deadlock의 발생 가능성을 검사하고 이를 피하는 방법

Banker's Algorithm

- 탐지 및 복구

시스템이 주기적으로 Deadlock을 탐지하고 발견된 Deadlock을 해결하는 방법

- 탐지한 후에는 일반적으로 하나 이상의 트랜잭션을 중단(abort)하거나 롤백(rollback)하여 자원을 해제하고 Deadlock을 해결

#### 트랜잭션이 무엇인가요?

---

- 데이터베이스에서 하나의 작업 단위를 구성하는 연산 집합

- 데이터베이스의 일관성과 무결성을 보장하는 데 사용

#### ACID 원칙이 무엇인가요?

---

- 트랜잭션 처리에 있어서 데이터의 일관성과 무결성을 보장하기 위한 원칙

**원자성(Atomicity)**

- 작업들은 모두 하나의 원자적인 단위로 처리되어야 함

모든 작업이 완료되거나 모든 작업이 취소되어야 함

하나의 작업이 실패하면 이전 작업이나 이후 작업이 영향을 받지 않아야 함

**일관성(Consistency)**

- 트랜잭션 실행 전과 후의 데이터베이스의 일관성이 유지되어야 함

- 트랜잭션 실행 전의 상태에서 유효한 제약 조건은 트랜잭션 실행 후에도 만족되어야 함

**고립성(Isolation)**

- 트랜잭션 실행 도중 다른 트랜잭션의 작업이 끼어들지 않도록 보장해야 함

**지속성(Durability)**

- 트랜잭션이 성공적으로 완료된 후에는 그 결과가 영구적으로 데이터베이스에 저장되어야 함

- 시스템 장애나 중단이 발생해도 트랜잭션 결과는 보존되어야 함

#### Commit과 Rollback이 무엇인가요?

---

**Commit**

- 데이터베이스 트랜잭션 연산이 성공적으로 완료되었음을 알리는 연산

Commit이 호출되면 트랜잭션 중에 수행된 모든 변경 사항이 데이터베이스에 영구적으로 적용

수행된 변경 사항을 취소할 수 없음

**Rollback**

- 트랜잭션이 실패하거나 문제가 발생한 경우 사용되는 연산

Rollback이 호출되면 트랜잭션 도중에 수행된 모든 변경 사항이 취소

데이터베이스는 트랜잭션이 시작되기 이전의 상태로 되돌아감

#### 읽기에는 트랜잭션을 걸지 않아도 될까요?

---

- DB의 동시성 요구사항과 일관성 보장 필요성에 따라 달라짐

**필요없는 경우**

- 데이터 일관성이 중요하지 않은 경우

일시적 불일치가 허용되는 경우 / 성능이 우선시일 때

- 읽기전용 DB

쓰기가 없는 경우

- 주기적인 스냅샷

주기적인 백업이나 복제된 DB를 읽는 경우

**필요한 경우**

- 읽기 일관성이 필요한 경우

읽기 작업 중 데이터 변경이나 삭제가 발생하지 않도록 보장해야 할 때

Repetable Read / Serializable

금융 시스템의 경우

- 복합 읽기 작업

여러 읽기 작업을 묶어서 동일한 스냅샷을 기준으로 읽어야 하는 경우

**Read-Only 트랜잭션**

- 읽기 작업에 대해서는 보통 READ-ONLY 트랜잭션을 사용

- Shared Lock을 사용하여 데이터베이스의 성능에 영향을 미치지 않음

#### 읽기 작업이 다른 트랜잭션에 영향을 주는 경우를 말해주세요

---

**Dirty Read**

- 하나의 트랜잭션이 아직 커밋되지 않은 변경내용을 다른 트랜잭션이 읽을 때 발생

하나의 트랜잭션이 데이터를 변경하고 있지만, 아직 커밋되지 않은 상태에서 다른 트랜잭션이 해당 데이터를 읽으면 변경되지 않은 원래 데이터가 아닌 변경 중인 데이터가 출력될 수 있음

**Non-Repetable Read**

- 하나의 트랜잭션이 동일한 쿼리를 두 번 실행했을 때, 결과가 다른 경우

트랜잭션 A가 데이터를 읽은 후, 트랜잭션 B가 데이터를 변경하고 커밋했을 때 다시 트랜잭션 A가 동일한 데이터를 읽으면, 이전에 읽었을 때와 값이 다를 수 있음

#### Durability를 DBMS가 어떻게 보장하나요?

---

**Write Ahead Logging(WAL)**

- 데이터베이스에서 발생하는 변경 사항은 먼저 로그 파일에 기록한 후, 실제 데이터베이스에 반영

**버퍼 관리(Buffer Management)**

- 버퍼라는 공간을 두어 데이터를 빠르게 읽고 쓸 수 있음

- 버퍼(Buffer)는 데이터베이스에서 읽은 데이터나 쓴 데이터를 일시적으로 저장하는 메모리 공간

디스크와 메모리 간의 속도 차이를 극복하기 위해 사용

디스크에 직접 접근하지 않고 버퍼에 있는 데이터를 사용하여 작업을 수행

- Flushing

데이터베이스에서는 버퍼에 있는 데이터를 주기적으로 디스크에 저장

이를 `디스크에 내리기(Flushing to Disk)` 라고 함

**Checkpoint**

- 일정 시간마다 Checkpoint를 수행하여 데이터베이스 상태를 로그 파일에 저장

장애 발생 시, 로그 파일을 사용하여 데이터베이스를 복구

**Redo Log**

- 데이터베이스에서 변경된 데이터를 다시 적용할 수 있도록 로그 파일에 저장

장애 발생 시, Redo Log를 사용하여 데이터베이스를 복구

Redo Log란 **DB 장애발생시 복구에 사용되는 Log**

더 정확하게 설명하자면, MySQL 장애 시 Buffer Pool에 저장되어있던 데이터의 유실을 방지(데이터 복구)하기 위해 사용된다

Redo Log에 앞서, InnoDB Buffer Pool을 이해해야한다.

Buffer Pool은 InnoDB 엔진이 Table Caching 및 Index Data Caching을 위해 이용하는 메모리 공간이다. 다시 말해, Buffer Pool 크기(메모리 공간)가 클수록 캐싱되는 데이터의 양이 늘어나기 때문에 Disk에 접근하는 횟수가 줄어들고, 이것은 DB의 성능 향상으로 이어진다.

하지만, Buffer Pool은 메모리 공간이기 때문에 MySQL 장애 발생시 Buffer Pool에 있는 내용은 사라지게 된다. 이것은 ACID를 보장할 수 없게 되고, 다시 해석하면 장애를 복구하더라도 데이터는 복구될 수 없다는 것을 의미한다

Redo Log에 기록할 때는, **데이터 변경**이 있을때이다.

> DML,DDL,TCL 작업 등 DATA 변경이 일어나는 모든 것을 기록한다.

**Redo Log File**이란?

방금까지 이야기한 부분은 메모리 영역인 Redo Log Buffer에 저장되는 부분을 말한 것이다. Redo Log Buffer또한 메모리영역이니 장애가 발생한다면 사라질 수 있다.

그래서 Redo Log File이 필요한 것이다.

Log Buffer는 메모리 영역이라고 했고, 메모리 영역이라는 것은 용량이 제한적이라는 뜻이다. 용량이 제한적이기 때문에 Checkpoint 이벤트 발생시점에 Redo Log Buffer에 있던 데이터들을 Disk에 File로 저장하게 된다. 이 파일을 **Redo Log File**이라고 한다.

Redo Log File은 두 개의 파일로 구성되는데, 하나의 파일이 가득차면 **Log Switch**가 발생하며 다른 파일에 쓰게된다. **Log Switch**가 발생할 때마다 Checkpoint 이벤트도 발생하는데, 이때 InnoDB Buffer Pool Cache에 있던 데이터들이 백그라운드 스레드에 의해 디스크에 기록된다.

> Checkpoint 이벤트가 발생하기 전 장애가 발생한다면 Buffer Pool에 있던 데이터들은 유실되지만 마지막 Checkpoint가 수행된 시점(=Log switch)까지의 데이터가 Redo Log File로 남아있기 때문에 이 파일을 사용하여 데이터를 복구할 수 있다.

**Undo Log**

- 트랜잭션을 취소할 때 사용되는 로그 파일

트랜잭션이 롤백되는 경우 Undo Log를 사용하여 데이터베이스를 이전 상태로 되돌림

실행 취소 로그 레코드의 집합으로, 트랜잭션 실행 후 **Rollback** 시 **Undo Log**를 참조해 이전 데이터로 복구할 수 있도록 로깅 해놓은 영역이다.

Undo Log도 Redo Log와 마찬가지로 Log Buffer에 기록된다. Undo Records 영역에 기록되는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/828fecf4-748a-40af-b161-e2983322f8b0/image.png)

Redo Log가 트랜잭션 커밋과 Checkpoint시 디스크에 기록 되지만, Undo Log는 Checkpoint시 디스크에 기록된다.

### 트랜잭션 격리 레벨에 대해 설명해 주세요

---

- 데이터베이스에서 동시에 실행되는 여러 트랜잭션들이 서로 얼마나 영향을 미칠 수 있는지를 결정

- 특정 트랜잭션이 다른 트랜잭션에서 수행한 변경 사항을 어느 시점에서 `보게`될 지를 결정

**격리레벨**

**`Read UNCOMMITTED`**

- 한 트랜잭션이 다른 트랜잭션에서 아직 커밋되지 않은 변경 사항을 볼 수 있음

- 성능이 가장 좋음

- 데이터 무결성이 중요하지 않은 환경에서 사용

로그 분석, 실시간 통계

**문제점**

- Dirty Read

신뢰할 수 없는 데이터 / 롤백되면 읽었던 데이터가 유효하지 않음

- Non-Repetable Read

한 트랜잭션 내에서 같은 데이터를 두 번 읽었을 때 다른 결과를 반환

- Phantom Read

한 트랜잭션에서 동일한 쿼리를 두 번 실행했을 때, 다른 트랜잭션이 새로운 데이터를 삽입하거나 삭제하여 결과가 달라짐

**`READ COMMITTED`**

- 한 트랜잭션이 다른 트랜잭션에서 이미 커밋된 변경 사항만 볼 수 있음

- Dirty Read 방지 / 대부분의 RDBMS의 기본 격리 수준

**문제점**

- Non-Repetable Read / Phantom Read 발생

**`REPETABLE READ`**

- 한 트랜잭션 내에서 같은 데이터를 여러 번 읽을 때 일관된 결과를 얻을 수 있음

트랜잭션이 시작될 때의 데이터 상태를 계속해서 유지

**문제점**

Phantom Read 발생

**`SERIALIZABLE`**

- 가장 엄격한 격리 레벨로, 트랜잭션들이 순차적으로 실행되도록 함

**문제점**

- 성능 하락 / 동시성 처리 능력 크게 하락

- 금융 거래 시스템에서 사용

#### 트랜잭션의 각 수준에서 발생할 수 있는 문제에 대해 말해보세요

---

- READ UNCOMMITTED

Dirty Read / Non-Repetable Read / Phantom Read

- READ COMMITTED

Non-Repetable Read / Phantom Read

- REPETABLE READ

Phantom Read

- SERIALIZABLE

동시성을 제한하므로 성능에 영향을 미칠 수 있음

#### 모든 DBMS가 4개의 레벨을 구현하고 있나요? 그렇지 않다면 그 이유가 무엇인가요?

---

- 그렇지 않음

각 DBMS의 설계 및 성능 최적화에 따른 차이 때문

- 각 트랜잭션 격리 레벨을 구현하는 것은 복잡하고 비용이 많이 드는 작업

DBMS 개발자들은 종종 가장 일반적으로 사용되는 격리 레벨만 구현

다른 격리 레벨은 덜 엄격한 레벨로 대체하거나 무시

- 높은 격리 레벨을 지원하면 동시성이 감소하고 성능이 저하

고성능을 제공하는 데 초점을 맞추고, 이를 위해 일부 격리 레벨을 희생

**예시**

MySQL의 InnoDB 스토리지 엔진

- 4가지 격리 레벨을 모두 지원

REPETABLE READ를 기본 격리레벨로 설정

PostgreSQL

- 기본적으로 READ COMMITTED 격리 레벨을 사용

- SERIALIZABLE 레벨도 지원

#### 만약 MySQL을 사용하고 있다면 Undo 영역과 Redo 영역에 대해 설명해 주세요

---

- 트랜잭션 관리와 데이터 복구를 위해 중요한 컴포넌트

**Undo 영역**

- 트랜잭션이 롤백되는 경우 데이터를 이전 상태로 복원하기 위해 사용

- 데이터베이스의 이전 상태에 대한 정보가 저장

- 트랜잭션이 실패하거나 사용자에 의해 중단되는 경우 Undo 영역의 데이터를 사용하여 데이터베이스의 상태를 트랜잭션 시작 이전의 상태로 롤백

- 일관된 읽기(Consistent Read)를 제공하기 위해 Undo 영역 사용

- 트랜잭션이 진행 중일 때 다른 트랜잭션에 의해 변경된 데이터를 보여주지 않도록 함

**Redo 영역**

- 시스템 오류나 충돌 등으로 데이터베이스의 일관성이 깨진 경우, 이를 복구하기 위해 사용

`Redo 로그`

- 데이터베이스의 모든 변경 사항을 포함

데이터베이스가 정상적인 상태로 복구될 수 있게 함

- 트랜잭션이 커밋되는 시점에 디스크에 쓰임

시스템이 갑작스럽게 중단되더라도 커밋된 트랜잭션의 내용은 유실되지 않음

..

Undo / Redo Log는 MySQL의 InnoDB 스토리지 엔진에서 트랜잭션의 ACID 속성을 보장하는 데 핵심적인 역할을 한다.

트랜잭션이 완전하고 안전하게 처리되도록 보장

#### DB Locking에 대해 설명해 주세요

---

- 데이터나 리소스에 대해 독점적인 접근 권한을 설정하는 메커니즘

- 무결성 보장

트랜잭션이 데이터를 수정하는 동안, 다른 트랜잭션이 동일 데이터를 읽거나 수정하지 못하도록 한다

- 동시성 관리

여러 트랜잭션이 동시에 데이터에 접근할 때, 충돌 방지

- Deadlock 예방

서로 다른 트랜잭션이 무한 대기를 하지 않도록 설계

#### 공유락과 베타 락의 차이는 무엇인가요?

---

- Lock 범위에 따라 분류

**공유락(Shared Lock)**

- 읽기 작업에 사용

- 여러 트랜잭션이 동시에 읽을 수 있지만, 수정 불가

- SELECT 쿼리에서 다른 트랜잭션이 데이터 수정 못하게 보장

- `s-lock` 으로도 불리며 `select ... for share` 로 락을 획득할 수 있다
- 다양한 트랜잭션에서 공유락을 가질 수 있으나, 공유락이 걸려있는 행에 대해 배타락을 가질 수 없다.

- 공유락에 걸리게 되면 해당 조회가 커밋이 될 때까지 어떠한 트랜잭션에서도 해당 행에 대해 쓰기 작업과 배타락을 가질 수 없다

**배타락(Exclusive Lock)**

- 데이터 수정에 사용

- 다른 트랜잭션이 읽기/쓰기 불가

- UPDATE,DELETE와 같은 쓰기 작업

- `x-lock`으로도 불리며, `select...for update`로 락을 획득할 수 있다.
- 배타락을 가지게 되면 다른 트랜잭션에서는 공유락, 배타락을 얻는게 불가능하다.
- 즉, 쓰기 작업과 공유락 조회는 불가능하다.

- 하지만 단순히 데이터를 `select` 하는 것이라면 읽기가 가능하다.

**Optimistic Lock/Pessimistic Lock에 대해 설명해 주세요**

- Lock 지속 시간에 따른 분류

**Optimistic Lock**

- 잠금을 하지 않고 트랜잭션 종료 시 데이터 충돌 여부 확인

버전 번호를 비교하여 충돌 여부 판단

동시성 성능이 높음

단, 충돌 발생 시 트랜잭션 재실행 필요

충돌 가능성이 낮고 읽기 작업이 많은 시스템에서 사용

**Pessimistic Lock**

- 데이터 접근 시마다 잠금 설정하여 충돌 방지

잠금은 트랜잭션 종료 시까지 유지

- 충돌 가능성을 완전 차단

- 동시성 성능 저하

- 충돌 가능성이 높고 무결성이 중요한 시스템에 사용

...

**트랜잭션의 격리 수준(Transaction Isolation Level)**

트랜잭션의 격리 수준이란, **여러 트랜잭션이 동시에 처리될 때 특정 트랜잭션이 다른 트랜잭션에서 변경하거나 조회하는 데이터를 볼 수 있게 허용할지 여부를 결정하는 것**이다.

`SERIALIZABLE`

가장 엄격한 격리 수준으로, 이름 그대로 트랜잭션을 순차적으로 진행시킨다.

**여러 트랜잭션이 동일한 레코드에 동시 접근할 수 없으므로**, 어떠한 데이터 부정합 문제도 발생하지 않는다. 하지만 **트랜잭션이 순차적으로 처리되어야 하므로 동시 처리 성능이 매우 떨어진다**

MySQL에서 SELECT FOR SHARE/UPDATE는 대상 레코드에 각각 읽기/쓰기 잠금을 거는 것이다.

하지만 순수한 SELECT 작업은 아무런 레코드 잠금 없이 실행되는데, 잠금 없는 일관된 읽기란 순수한 SELECT 문을 통한 잠금 없는 읽기를 의미하는 것이다.

하지만, SERIALIZABLE 격리 수준에서는 **순수한 SELECT 작업에서도 대상 레코드에 넥스트 키 락을 읽기 잠금(공유락,Shared Lock)으로 건다**.

따라서 한 트랜잭션에서 넥스트 키 락이 걸린 레코드를 다른 트랜잭션에서는 절대 추가/수정/삭제 할 수 없다.

SERIALIZABLE은 가장 안전하지만, 가장 성능이 떨어지므로 극단적으로 안전한 작업이 필요한 경우가 아니라면 사용해서는 안된다.

`REPETABLE READ`

일반적인 RDBMS는 **변경 전의 레코드를 언두 공간에 백업**해둔다. 그러면 **변경 전/후 데이터가 모두 존재**하므로, 동일한 레코드에 대해 여러 버전의 데이터가 존재한다고 하여 이를 `MVCC(Multi-Version Concurrency Control)` 라고 부른다.

MVCC를 통해 트랜잭션이 롤백된 경우에 데이터를 복원할 수 있을 뿐만 아니라, 서로 다른 트랜잭션 간에 접근할 수 있는 데이터를 세밀하게 제어할 수 있다.

각각의 트랜잭션은 순차 증가하는 고유한 트랜잭션 번호가 존재하며, 백업 레코드에는 어느 트랜잭션에 의해 백업되었는지 **트랜잭션 번호를 함께 저장**한다.

그리고 해당 데이터가 불필요하다고 판단하는 시점에 주기적으로 백그라운드 스레드를 통해 삭제한다.

REPETABLE READ는 MVCC를 이용해 **한 트랜잭션 내에서 동일한 결과를 보장하지만, 새로운 레코드가 추가되는 경우에 부정합**이 생길 수 있다.

예를 들어보자.

![](https://velog.velcdn.com/images/sujipark2009/post/b6f0ef66-7dba-4295-a0fa-2e77895ad965/image.png)

트랜잭션을 시작하고 id >= 50 인 레코드를 조회하면 1건이 조회되는 상황이다.

![](https://velog.velcdn.com/images/sujipark2009/post/e21357ee-0654-4126-acb0-8cbcf6f58d2b/image.png)

이때 다른 사용자 A의 트랜잭션에서 id = 50인 레코드를 갱신하는 상황이라고 하자.
그러면 MVCC를 통해 기존 데이터는 변경되지만, 백업된 데이터가 언두 로그에 남게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/51b0fc11-4437-4ee1-aee6-93a2407d9f49/image.png)

사용자 B가 데이터를 조회했던 트랜잭션은 아직 종료되지 않은 상황에서, 사용자 B가 다시 한번 동일한 SELECT 문을 실행하면, **여전히 같은 결과**가 나오게 된다.

사용자 B의 트랜잭션(id = 10)은 사용자 A의 트랜잭션(12)이 시작하기 전에 이미 시작된 상태다.
이때 REPETABLE READ는 트랜잭션 번호를 참고하여 자신보다 먼저 실행된 트랜잭션의 데이터만을 조회한다.

만약 테이블에 자신보다 이후에 실행된 트랜잭션의 데이터가 존재한다면, **언두 로그**를 참조해서 데이터를 조회한다.

따라서 사용자 A의 트랜잭션이 시작되고 커밋까지 되었지만, 해당 트랜잭션(12)는 현재 트랜잭션(10)보다 나중에 실행되었기 때문에 조회 결과로 기존과 동일한 데이터를 얻게 된다. 즉, REPETABLE READ는 어떤 트랜잭션이 읽은 데이터를 다른 트랜잭션이 수정하더라도 동일한 결과를 반환할 것을 보장해준다.

REPETABLE READ는 새로운 레코드의 추가까지는 막지 않는다고 했는데, 따라서 SELECT로 **조회한 경우, 트랜잭션이 끝나기 전에 다른 트랜잭션에 의해 추가된 레코드가 발견**될 수 있는데, 이를 **유령 읽기(Phantom Read)** 라고 한다.

하지만 MVCC 덕분에 일반적인 조회에서 유령 읽기는 발생하지 않는다. 왜냐하면 자신보다 나중에 실행된 트랜잭션이 추가한 레코드는 무시하면 되기 때문이다.

![](https://velog.velcdn.com/images/sujipark2009/post/a51246be-4e71-4257-b417-4d037f501722/image.png)

그렇다면, **언제 유령 읽기가 발생하는 것일까?**

바로, 잠금이 사용되는 경우이다. MySQL은 다른 RDBMS와 다르게 특수한 갭 락이 존재하기 때문에, 동작이 다른 부분이 있으므로 일반적인 RDBMS 경우부터 보도록 하자.

![](https://velog.velcdn.com/images/sujipark2009/post/abe244ef-142d-471a-839b-2680893f9c39/image.png)

마찬가지로 사용자B가 먼저 데이터를 조회하는데, 이번에는 SELECT FOR UPDATE를 이용해 쓰기 잠금을 걸었다.

여기서 SELECT ... FOR UPDATE 구문은 `베타적 잠금(비관적 잠금, 쓰기 잠금)` 을 거는 것이다. 읽기 잠금을 걸려면 SELECT FOR SHARE 구문을 사용해야 한다.

락은 트랜잭션이 커밋 또는 롤백될 때 해제된다.

사용자A가 새로운 데이터를 INSERT하는 상황이라고 하면, 일반적인 DBMS에서는 갭락이 존재하지 않으므로, id=50인 레코드만 잠금이 걸린 상태이고, 사용자A의 요청은 잠금 없이 즉시 실행된다.

![](https://velog.velcdn.com/images/sujipark2009/post/8e3d5b9d-67a9-4471-8774-f5d9385c9a2a/image.png)

이때 사용자B가 동일한 쓰기 잠금 쿼리로 다시 한번 데이터를 조회하면, 이번에는 2건의 데이터가 조회된다.

동일한 트랜잭션 내에서도 새로운 레코드가 추가되는 경우에 조회 결과가 달라지는데, 이렇듯 다른 트랜잭션에서 수행한 작업에 의해 레코드가 보였다 안보였다 하는 현상을 `Phantom Read` 라고 한다.

이 경우에도 MVCC를 통해 해결될 것 같지만 두 번째 실행되는 SELECT FOR UPDATE 때문에 그럴 수 없다.
왜냐하면 잠금읽는 읽기는 데이터 조회가 **언두 로그가 아닌 테이블에서 수행되기 때문이다**. 잠금읽는 읽기는 테이블에 변경이 일어나지 않도록 테이블에 잠금을 걸고 테이블에서 데이터를 조회한다.

잠금이 없는 경우처럼 언두 로그를 바라보고 언두 로그를 잠그는 것은 불가능한데, 그 이유는 언두 로그가 append only 형태이므로 잠금 장치가 없기 때문이다.

따라서 SELECT FOR UPDATE나 SELECT FOR SHARE로 레코드를 조회하는 경우에는 **언두 영역의 데이터가 아니라 테이블의 레코드를 가져오게 되고, 이로인해 Phantom Read가 발생하는 것**이다.

하지만 MySQL에는 갭 락이 존재하기 때문에, 위의 상황에서 문제가 발생하지 않는다.

![](https://velog.velcdn.com/images/sujipark2009/post/7488a922-ea72-48c4-8e67-5fa90e244b79/image.png)

사용자B가 SELECT FOR UPDATE로 데이터를 조회한 경우에 MySQL은 id가 50인 레코드에는 레코드락, id가 50보다 큰 범위에는 갭 락으로 넥스트 키 락을 건다.
따라서 사용자 A가 id가 51인 member를 INSERT 시도한다면, B의 트랜잭션이 종료될 때 까지 기다리다가, 대기를 지나치게 오래 하면 락 타임아웃이 발생하게 된다.

따라서 **일반적으로 MySQL의 REPETABLE READ에서는 Phantom READ가 발생하지 않는다**.

MySQL에서 Phantom Read가 발생하는 거의 유일한 케이스는 다음과 같다.

![](https://velog.velcdn.com/images/sujipark2009/post/f87ae3c4-c716-4ff2-a879-887a23fdd9c7/image.png)

사용자 B는 트랜잭션을 시작하고, 잠금없는 SELECT 문으로 데이터를 조회하였다. 그리고 사용자 A는 INSERT 문을 사용해 데이터를 추가하였다.
이때, 잠금이 없으므로 바로 COMMIT 된다. 하지만 사용자 B가 SELECT FOR UPDATE로 조회를 했다면, 언두 로그가 아닌 테이블로부터 레코드를 조회하므로 Phantom Read가 발생한다.

`READ COMMITTED`

READ COMMITTED는 **커밋된 데이터만 조회**할 수 있다. READ COMMITTED는 REPETABLE READ에서 발생하는 `Phantom Read`에 더해 `Non-Repetable Read(반복 읽기 불가능)` 문제까지 발생한다.

![](https://velog.velcdn.com/images/sujipark2009/post/3b21fabf-7860-4fd7-b5bb-dff6f0134d02/image.png)

예를 들어, 사용자A가 트랜잭션을 시작하여 어떤 데이터를 변경하였고, 아직 커밋은 하지 않은 상태라고 하자.

그러면 테이블은 먼저 갱신되고, 언두 로그로 변경 전의 데이터가 백업되는데

![](https://velog.velcdn.com/images/sujipark2009/post/4b87dcc4-ac1b-46d9-a236-b499e59d7079/image.png)

이때, 사용자 B가 데이터를 조회하려고 하면, READ COMMITTED에서는 커밋된 데이터만 조회할 수 있으므로, REPETABLE READ와 마찬가지로 언두 로그에서 변경 전의 데이터를 찾아서 반환하게 된다.

최종적으로 사용자 A가 트랜잭션을 커밋하면 그때부터 다른 트랜잭션에서도 새롭게 변경된 값을 참조할 수 있는 것이다.

![](https://velog.velcdn.com/images/sujipark2009/post/d309b583-7ecb-462c-a9a8-38ef19097f69/image.png)

하지만 READ COMMITTED는 Non-Repetable Read 문제가 발생할 수 있다.
예를 들어 사용자B가 트랜잭션을 시작하고 name="MangKyu" 인 레코드를 조회했다고 하자.
해당 조건을 만족하는 레코드는 아직 존재하지 않으므로 아무 것도 반환되지 않는다.

그러다가 사용자 A가 UPDATE문을 수행하여 해당 조건을 만족하는 레코드가 생겼다고 하면, 사용자 A의 작업은 커밋까지 완료된 상태이다.

이때, 사용자 B가 다시 동일한 조건으로 레코드를 조회하면 어떻게 될까?
READ COMMITTED는 커밋된 데이터는 조회할 수 있도록 허용하므로 결과가 나오게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/e6fa57e5-fba5-4bb5-8297-5555c2be5258/image.png)

READ COMMITTED에서 반복 읽기를 수행하면 다른 트랜잭션의 커밋 여부에 따라 조회 결과가 달라질 수 있다.

따라서 이러한 데이터 부정합 문제를 Non-Repetable Read라고 한다.

`READ UNCOMMITTED`

READ UNCOMMITTED는 **커밋하지 않은 데이터 조차도 접근할 수 있는 격리 수준**이다.

READ UNCOMMITTED에서는 다른 트랜잭션의 작업이 커밋 또는 롤백되지 않아도 즉시 보이게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/69244e12-2986-46d0-818f-3d99bd0e6eb7/image.png)

이렇듯, 어떤 트랜잭션의 작업이 완료되지 않았는데도, 다른 트랜잭션에서 볼 수 있는 부정합 문제를 `Dirty Read` 라고 한다. Dirty Read는 데이터가 조회되었다가 사라지는 현상을 초래하므로 시스템에 상당한 혼란을 주게 된다.

![](https://velog.velcdn.com/images/sujipark2009/post/b959a971-d7ab-4455-b97e-fb61ba91f021/image.png)

위의 경우에서 사용자 A가 커밋이 아닌 롤백을 수행한다면,
사용자 B의 트랜잭션은 id=51인 데이터를 계속 처리하고 있을 텐데 다시 데이터를 조회하니 결과가 존재하지 않는 상황이 생긴다. 이러한 Dirty Read 상황은 시스템에 상당한 버그를 초래할 것이다.
